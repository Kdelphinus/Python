1. k겹 교차 검증(k_fold cross validation)
- 머신 러닝의 성능을 좀 더 정확히 검증할 수 있는 방법
- training set과 test set을 이용한 검증은 딱 그 데이터에 한해서만 잘 맞는 모델일 확률이 있다
- 즉, 실전에서 제 성능을 발휘하지 못할 수 있다
- 그것을 막아주기 위해 있는 검증이 교차 검증이고 그 중, 가장 대표적인 것이 k겹 교차 검증이다

    1.1 방법
    - k를 5라고 가정하고 m(데이터 개수)이 1000일 때
    - 데이터를 k만큼 나눈다 (설명의 편의를 위해 순서대로 1, 2, 3, 4, 5라고 임의로 이름 붙임)

    - 1번 데이터들을 test set으로, 나머지를 training set으로 사용 -> 성능이 80%라고 가정
    - 2번 데이터들을 test set으로, 나머지를 training set으로 사용 -> 성능이 70%라고 가정
    - 3번 데이터들을 test set으로, 나머지를 training set으로 사용 -> 성능이 85%라고 가정
    - 4번 데이터들을 test set으로, 나머지를 training set으로 사용 -> 성능이 85%라고 가정
    - 5번 데이터들을 test set으로, 나머지를 training set으로 사용 -> 성능이 90%라고 가정

    - 다섯번의 결과의 평균 성능(80%)을 모델의 성능으로 간주한다
    - 일반적으로 k를 5로 사용하기에 5겹 교차 검증이라고 부른다
    - k가 10이면 10겹 교차 검증, 20이면 20겹 교차 검증이다


2. 하이퍼 파라미터
- 학습을 하기 전에 미리 정해줘야 하는 변수나 파라미터들
- 예시) model = Lasso(alpha=0.01, max_iter=1000)에서 alpha와 max_iter가 하이퍼 파라미터
- 하이퍼 파라미터에 어떤 값을 넣어주냐에 따라 성능이 크게 변한다

    2.1 그리드 서치(Grid Search)
    - 좋은 하이퍼 파라미터를 고르는 방법 중 하나
    - 하이퍼 파라미터에 넣을 후보값들을 넣어 가장 좋은 하이퍼 파라미터를 구하는 방법
    - 후보값들을 예상하기 어려울 땐, 구글링을 통하여 sklearn의 default값과 비슷한 값들을 넣는 것이 좋다
    

