1. 결정 트리
- y/n으로 대답할 수 있는 질문 + 질문들을 답해나가며 분류
- 질문들의 답을 하면서 답을 찾아가는 방식
- leaf 노드들은 모두 y/n(꼭 예, 아니오는 아니여도 됨 / 생존, 사망도 가능)으로 대답할 수 있는 것들이
  나머지 노드들은 질문들이 들어있다

- 머신 러닝에서는 질문과 대답이 정해져 있지 않고 학습 데이터들을 보며 프로그램이 정해나감
- 데이터를 분류하는 방법이 직관적이고 쉽게 해석이 가능한 장점이 있다
- 즉, 어떤 속성이 중요하게 사용됐는지 알 수 있다


2. 지니 불순도(gini impurity)
- 데이터 셋 안에 서로 다른 분류들이 얼만큼 섞여있는지 나타내는 것
- 예시) 독감과 일반 감기의 데이터가 있을 때 
    - GI = 1 - (독감일 확률)^2 - (독감이 아닐 확률)^2

- 한 종류의 데이터만 있으면 0이다
- 절반씩 들어있으면 0.5가 나온다
- 지니 불순도가 작을수록 데이터 셋이 순수하고 클수록 데이터 셋이 불순하다


3. 결정 트리 만들기
    3.1 분류 노드 평가
    - 좋은 분류 노드는 최대한 많은 학습 데이터 예측을 맞춘다
    - 데이터 셋이 순수할수록(지니 불순도가 낮을수록) 더 좋다

    3.2 질문 노드 평가
    - 좋은 질문은 데이터를 잘 나눠서 아래 노드들이 분류하기 쉽게 만든다
    - 질문으로 나뉜 데이터 셋이 순수할수록(지니 불순도가 낮을수록) 더 좋다
    - 질문 노드의 지니 불순도는 사진 참고

    3.3 root 노드 고르기
    - 분류 노드와 질문 노드들 중 불순도가 가장 낮은 노드를 뽑으면 된다

    3.4 모든 노드 만들기
    - root 노드로 각자 분류된 데이터들만 고려하면 된다
    - 그 외에는 root 노드를 고르듯이 분류 노드와 질문 노드들 중 불순도가 가장 낮은 노드를 뽑으면 된다
    - 특정 높이까지 만들거나 모든 노드를 다 사용할 때까지 반복하면 된다

    3.5 속성이 숫자형일 때 질문 노드
    - 예를 들어 체온이 속성일 때, 연속된 두 데이터의 평균을 구한 뒤 질문을 만든다
    - 구한 질문들을 하나씩 지니 불순도를 확인하며 가장 작은 지니 불순도를 가진 질문을 고르면 된다


4. 속성 중요도(Feature Importance)
- 평균 지니 감소라고도 함
- 가장 중요하게 사용된 속성은 무엇인지 볼 수 있는 값
- 노드 중요도를 이용한다

    4.1 노드 중요도(Node Importance)
    - NI = (n/m) * GI - (n_left/m) * GI_left - (n_right/m) * GI_right
      (n: 노드까지 오는 데이터 수, GI: 노드 지니 불순도, m: 전체 학습 데이터 수, left/right: 각각 왼쪽과 오른쪽 노드)
    - 특정 노드 전후로 불순도가 얼마나 낮아졌는지를 확인하는 것