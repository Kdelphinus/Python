1. 추천 시스템
- 특정 사용자가 좋아해 할 만한 것들을 찾아주는 프로그램
- 대부분의 추천 시스템은 머신 러닝을 통해 만들어진다
- 머신 러닝 정의에 빗대어 정의하면
    - 어떤 추천을 할 때, 유저의 행동 패턴을 통해, 그 작업에 대한 추천 정확도가 향상되는 프로그램

- 유저와 상품의 관계를 표현한 데이터 사용
- 유저와 상호 작용이 없었던 상품에 대한 선호도 예측
- 선호도가 높게 예측되는 상품들을 유저에게 추천


    1.1 추천 시스템 데이터
        1.1.1 직접 데이터(Explicit data)
        - 유저가 직접적으로 상품에 대한 만족/선호도를 표시한 데이터
        - 유저 영화 평점 데이터 (1~5로 선호도 표시)
        - 유튜브 유저 좋아요/싫어요 데이터 (0, 1로 선호도 표시)
        - 유저 선호도를 정확하게 나타낸다


        1.1.2 간접 데이터(Implicit data)
        - 유저가 직접적으로 선호도를 표시하지 않았지만 유추할 수 있는 데이터
        - 유튜브 유저 영상 시청 데이터
        - 아마존 유저 구매 데이터
        - 데이터 형태는 똑같이 표현
        - 데이터를 수집하기 쉽다
        - 정확하고 적은 데이터보다 조금 부정확해도 많은 데이터로 학습하는게 더 정확할 수 있기에 간접 데이터도 사용함


2. 내용 기반 추천
- 상품의 속성, 즉 '어떤' 상품인지를 사용해서 추천
- 예시) 영화면 장르에 대한 속성 값(그 장르에 가까울수록 1, 아닐수록 0에 가까운 값, 예시일 뿐)도 함께 고려하는 것
- 한 사용자를 위해 추천 시스템을 만들면
    - 우선 사용자가 평점을 준 데이터만 추린다
    - 영화 속성 값(장르)을 입력 변수, 사용자가 평점을 준 값을 목표 변수로 머신 러닝을 학습시킨다
    - 그 뒤, 평점이 없는 영화들을 추천
    - 좋아요/싫어요만 나누어져 있으면 분류 알고리즘, 1~5사이의 평점이라면 회귀 알고리즘을 사용하면 된다


    2.1 장점
    - 상품을 추천할 때, 다른 유저 데이터가 필요하지 않다
    - 새롭게 출시한 상품이나, 인기가 없는 상품을 추천할 수 있다


    2.2 단점
    - 적합한 속성을 고르는 것이 어렵다
    - 고른 속성 값들이 주관적으로 선정될 수 있다
    - 유저가 준 데이터를 벗어나는 추천을 할 수 없다
    - 인기가 많은 상품들을 더 추천해 줄 수 없다


3. 협업 필터링
- 수많은 유저 데이터들이 협업해서 상품을 추천 (내용 기반 추천은 다른 유저 데이터의 영향을 받지 않았음)
- 비슷한 유저들을 찾아 추천하는 것이 대표적인 방법 중 하나(유저 기반 협업 필터링)


    3.1 비슷한 유저 정의하기
        3.1.1 유클리드 거리
        - 벡터 사이의 거리를 구하여 거리가 가까울수록 비슷한 유저로 정의한다


        3.1.2 코사인 유사도
        - 두 선 사이의 각을 코사인 함수에 넣어서 유사도를 구함
        - 데이터가 비슷할수록 ㅋ고, 다를수록 작다
        - cos(theta)를 구하는 식은 사진 참고


        3.1.3 데이터가 중간중간 비어있다면
            3.1.3.1 0으로 계산하기
            - 비어있는 값을 0으로 가정하고 계산
            - 그러나 평점을 주지 않았다는 이유로 싫어하는 영화로 계산되어 정확도가 많이 떨어짐

            3.1.3.2 유저 별 평균 평점으로 계산하기
            - 유저의 평균 평점으로 채워넣기
            - 이는 유저가 좋아하지도, 싫어하지도 않는다고 해석할 수 있다
            - 0으로 계산하는 것보단 합리적이다

            3.1.3.3 mean normalization으로 계산하기
            - 위 두 가지 방법을 합친 방법
            - 우선 빈 칸을 유저 별 평균 평점으로 채운 뒤, 모든 평점을 유저 평균 평점으로 빼준다
            - 이러면 평균 평점은 0이 된다
            - 유저가 평점을 주는 기준이 다른데 mean normalization을 이용하면 모두 비슷한 기준에서 다른 평점을 예측할 수 있다

        
        3.1.4 유클리드 거리와 코사인 유사도
        - 아령과 닭 가슴살을 각각 100개를 산 A, 아령과 닭 가슴살을 각각 1개씩 산 B, 맥주와 피자를 1개씩 산 C
        - 유클리드 거리로 구하면 B와 C가 더욱 가깝게 측정된다
        - 그러나 코사인 유사도로 구하면 A와 B가 방향이 비슷하여 더 유사하게 측정된다
            - 코사인 유사도는 거리와 크기를 고려하지 않기 때문

        - 또한 유클리드 거리는 작을수록 유사하고, 코사인 유사도는 클수록 유사하다

    
    3.2 상품 추천하기
    - 추천할 유저와 비슷한 유저들을 찾고 그 중, 추천할 영화를 평가한 유저들(이웃들)의 평점의 평균으로 예측한다


    3.3 상품 기반 협업 필터링
    - 3.1, 3.2가 유저 기반 협업 필터링이라면 상품을 기반으로 추천하는 상품 기반 협업 필터링도 있다
    - 유저 대신 평점을 예측할 영화와 비슷한 영화들을 선정하고 유저가 비슷한 영화에게 준 평점들의 평균으로 평점을 예측한다


    3.4 두 협업 필터링 비교
    - 이론상으론 유저와 상품 기반 협업 필터링은 큰 차이가 없다
    - 그러나 실전에서는 상품 기반 협업 필터링이 더 성능이 좋은 경우가 많다
        - 유저들이 상품보다 복잡하기 때문
    

    3.5 협업 필터링의 장단점
        3.5.1 장점
        - 속성을 찾거나 정할 필요가 없다
        - 좀 더 폭넓은 상품을 추천할 수 있다
            - 예시로 아령과 닭 가슴살을 연관지어 추천할 수 있다
        - 내용 기반 추천보다 성능이 더 좋게 나오는 경우가 많다

        3.5.2 단점
        - 데이터가 많아야 한다
            - 유저 한 명이 열심히 평점을 줘도 다른 사람들도 열심히 평점을 줘야 한다
            - 새로운 물건이나 유저에게 추천해 주기 힘들다
        - 인기가 많은 소수의 상품이 추천 시스템을 장악할 수 있다
        - 어떤 상품이 왜 추천됐는지 정확히 알기 힘들다

    
    3.6 어떤 방식을 사용해야 할까?
    - 선형 회귀, 다항 회귀, 유저 기반 협업 필터링, 상품 기반 협업 필터링을 각각 3개씩 뽑아 추천해도 되고
    - 여러 방식들 평점의 예측 평균 값을 구하여 추천하여도 된다


4. 행렬 인수분해
- 행렬을 다른 두 행령의 곱으로 나타내는 것
- 유저의 영화 평가에 대한 평점 = 유저의 취향(세타) @ 영화 속성(X)
- 행렬 인수분해를 통해 빈칸을 채울 수 있다
- 그러나 빈 값들이 있을 때, 행렬 인수분해는 어렵다

- 행렬 인수분해를 머신 러닝에 이용할 땐, 유저 취향 뿐만 아니라 영화속성도 머신러닝으로 학습하여 이용한다
    - 이것을 속성 학습이라고 한다
- 각 유저 취향과 영화 속성이 모든 유저 데이터를 사용해서 학습된다
    - 영화 속성은 모든 유저들을 통하여 학습되고 유저 취향은 이를 통해 예측되기 때문
    - 그렇기에 협업 필터링에 일종이라고 할 수 있다


    4.1 손실 함수
    - 유저 취향과 영화 속성을 통해 평점 예측 값을 구한다
    - 그 후, 실제 평점과 차이를 제곱하여 더한 값을 받는다
    - 이때, 평점이 없는 것은 건너 뛴다


    4.2 경사 하강법
    - 손실 함수를 줄여주는 방향으로 모든 세타 값들과 엑스 값들을 계속 바꿔준다
    - 행렬 인수분해 손실 함수는 변수가 세타와 엑스를 갖기에 밑으로 볼록하지 않고 여러 극소점을 가진다
    - 그러나 임의의 값보단 극소점이 항상 성능이 더 좋고, 많은 경우는 최소점이 아니라 극소점이여도 성능이 충분히 나오기에 경사 하강법을 사용


    4.3 정규화
    - 모든 세타와 X값들을 제곱해서 더해준 것을 손실 함수에 더한다(L2 정규화)


    4.4 결과 해석
    - 각 데이터는 경사 하강이 진행되며 의미를 잃어버리고 결과값에만 맞는 방향으로 이동한다
    - 그렇기에 처음 시작할 때, 각 데이터에 의미를 부여하지 않고 작은 임의의 값들로 초기화한다
    - 어떤 속성을 쓸지는 정하지 않지만, 몇 개를 쓸지는 정해야 한다
        - 교차 검증과 그리드 서치를 사용해서 성능이 가장 좋은 개수로 정한다

- 행렬 인수분해가 좋다고 이것만 사용하지 않는다
- 여러 방식을 섞어서 사용하는 것이 키포인트