{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Natural Language Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Intro\n",
    "1. Bag-of-Words\n",
    "2. Topic Modeling\n",
    "3. Word Embedding\n",
    "4. RNNs with Attention\n",
    "5. Preprocessing\n",
    "6. Transformer\n",
    "7. Tokenization\n",
    "8. Byte-Pair Encoding\n",
    "9. BERT\n",
    "10. GPT\n",
    "11. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **0. Intro**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **0.1 NLP란?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP(Natural Language Processing)란 자연어를 컴퓨터와 같은 기계를 이용해서 묘사하도록 연구하는 인공지능 분야입니다. 이는 다시 NLU(Natural Language Understanding)과 NLG(Natural Language Generation)으로 나뉩니다. \n",
    "\n",
    "NLU는 문장이나 문단이 주어졌을 때, 이를 이해하고 질의응답이 가능하도록 만드는 분야입니다. NLG는 자동 번역 등 자연스럽게 말이 이어지도록 생성하는 과정입니다. 현재 NLU는 어느 정도 연구가 진행되었다고 여겨지고 NLG에 대한 연구가 더 활발하게 이루어지고 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **0.2 NLP Applications**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP를 사용하는 분야는 많이 있습니다. 이를 하나씩 살펴보겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) Text Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spam detection, sentiment analysis 등 받은 자연어들로 분류하는 분야입니다. 스팸 메일을 분류하거나 평점을 가지고 긍부정을 나누는 등에 사용됩니다. \n",
    "\n",
    "![text_classification](_image/text_classification.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) QA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QA(Question Answering)는 말 그대로 질문과 context(위키 등 웹페이지들)가 input으로 주어졌을 때, output으로 답을 내보내는 것입니다. 대표적으로 search engine 등이 있습니다. 밑에서 구글을 보면 질문에 대해 위키에 답을 진하게 표현한 것을 볼 수 있습니다.\n",
    "\n",
    "![QA](_image/QA.PNG)\n",
    "\n",
    "이때 답을 찾는 방법은 크게 세 가지가 있습니다.\n",
    "\n",
    "1. Context 내에서 뽑아냄(위 이미지가 그 예시)\n",
    "2. 직접 문장을 생성하여 출력\n",
    "3. 객관식(Multi-Choice)를 사용하여 출력\n",
    "\n",
    "2번 같은 경우는 context가 주어지지 않고 질문만 주어지는 common sense reasoning입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) Macine Translation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Translation은 기존 언어(source language)를 번역할 언어(target language)로 바꿔주는 것입니다. 현재 연구, 실무 분야에서 가장 활발하게 진행되고 있습니다. 파파고, 구글 번역 등이 그 예시입니다.\n",
    "\n",
    "1. pair 사용(같은 의미, 다른 언어의 쌍)\n",
    "2. unsupervised learning(pair가 없이 학습)\n",
    "\n",
    "학습 방법은 위에 두 가지 방법이 있습니다. pair는 직관적이지만 하나하나 학습 데이터를 만들기 어렵고 데이터가 너무 커집니다. 그래서 최근 비지도 학습을 이용한 학습이 새로운 방법으로 나오고 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4) Chatbot**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chatbot은 자연어가 input으로 주어졌을 때, 대화가 이어지도록 output이 이어서 주어지는 프로그램입니다. 대화가 계속 이어지기 때문에 맥락을 잘 보는 것이 필요합니다. 그렇기에 직전 한 문장만 input으로 받지 않고 어느 정도 문단을 같이 가져옵니다. input을 template와 generation 중 어떤 것으로 받을지 선택할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5) Personal Assistant**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personal Assistant는 빅스비, 시리와 같이 특정 요청을 수행하는 것들을 말합니다. 아직은 노래 요청, 날씨 등 제한적인 사용만 가능하지만 점차 개발되어지고 있습니다. 음성으로 작동하기 때문에 특정 음성(하이 빅스비, 시리야 등)을 들어야 음성 모드로 들어가게 만들어서 여러 소음에 작동하지 않도록 하고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6) Text Summarization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Summarization은 말그대로 글들을 요약해주는 것입니다. 예를 들어 뉴스가 있다면 제목과 내용을 보고 요약해주는 것을 말합니다. \n",
    "\n",
    "![text_summarization](_image/text_summarization.PNG)\n",
    "\n",
    "요약하는 방식은 extractive와 generative로 나뉩니다. extractive는 주어진 내용들을 통해 요약을 해주는 반면 generative는 본문에 없는 말로도 요약할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **0.3 NLP 연구 필드**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP 분야는 ACL, EMNLP, NAACL 등 유력한 컨퍼런스들이 있습니다. (AI는 급변하는 분야이기에 저널을 잘 보지 않습니다.) 이를 더욱 세분화하여 분야를 나눌 수 있습니다.\n",
    "\n",
    "#### **Low-level parsing**\n",
    "- Tokenization, stemming(과거형이나 미래형을 기본형으로 바꾸는 것)\n",
    "\n",
    "#### **Word and pharse level**\n",
    "- Named entity recognition(NER), part-of-speech(POS) tagging, noun-phrase chunking, dependency parsing, coreference resolution $\\Rightarrow$ (언어학자가 만든 체계가 컴퓨터에게는 도움이 되지 않음이 확인되면서 연구가 사그라듬)\n",
    "- Semantic relation extraction\n",
    "\n",
    "#### **Sentence level**\n",
    "- Sentiment analysis, machine translation\n",
    "\n",
    "#### **Multi-sentence and paragraph level**\n",
    "- Entailment prediction, question answering, dialog systems, summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 외에도 text mining, information retrieval 등이 있습니다.(PDF 참고)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Bag-of-Words**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.1 Word Embedding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embedding이란 단어들을 embedding이란 과정을 거쳐 컴퓨터가 이해할 수 있는 숫자로 바꾸는 과정을 말합니다. 이러면 단어들은 벡터가 되는데 이 벡터를 embedding vector라고 합니다.\n",
    "\n",
    "|구분|Bag-of_Words|언어 모델|분포 가정|\n",
    "|:---:|:---:|:---:|:---:|\n",
    "|내용|어떤 단어가 많이 쓰였는가|단어가 어떤 순서로 쓰였는가|어떤 단어가 같이 쓰였는가|\n",
    "|대표 통계량|TF-IDF|-|PMI|\n",
    "|대표 모델|Deep Averaging Network|ELMO, GPT|Word2Vec|\n",
    "\n",
    "단어를 임베딩하여 나오는 벡터들은 어떤 가정을 따르냐에 따라서 위와 같이 구분됩니다. 이를 더 자세히 살펴보면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) 백 오브 워즈 가정**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "백 오브 워즈는 저자의 의도가 단어 사용 여부나 그 빈도에서 드러난다고 보는 과정입니다. 그렇기에 단어의 순서는 고려대상이 아닙니다. 순서에 상관없이 하나의 가방에 단어들을 모두 넣고 빈도수를 확인하는 것입니다. 이때 대표적으로 TF-IDF가 사용됩니다. \n",
    "\n",
    "#### **TF-IDF(Term Frequency-Inverse Document Frequency)**\n",
    "어떤 단어의 주제 예측 능력이 강할수록 가중치가 커지고 반대의 경우 작아집니다. w는 단어, N은 문서의 개수, TF(Term Frequency)는 단락에서의 빈도, DF(Document Frequency)는 문서에서의 빈도입니다. \n",
    "\n",
    "$$TF - IDF(w) = TF(w) \\times log(\\frac{N}{DF(w)})$$\n",
    "\n",
    "그렇기에 문서 전체에서 빈도가 높은 조사들은 가중치가 줄어들고 특정 문장에서 빈번하게 나오는 단어들은 가중치가 증가합니다. 이에 대해 뒤에서 더 자세히 알아보겠습니다.\n",
    "\n",
    "\n",
    "#### **Deep Averaging Network(lyyer et al. 2015)**\n",
    "문장에 속한 단어의 임베딩의 평균을 구해 문장의 임베딩을 만드는 방법입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) 언어 모델**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어의 등장 순서를 학습해 주어진 단어 시퀀스가 얼마나 자연스러운지 확률을 부여하는 방법입니다. 백 오브 워즈와 달리 등장 순서에 영향을 받기에 '나는 밥을 먹었다'와 '나는 먹었다 밥을'을 다른 문장으로 해석합니다. \n",
    "\n",
    "$$P(w_i) \\Rightarrow P(w_i|w_{i-1}, w_{i-2}, \\cdots, w_0)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) 분포 가정**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어의 의미를 주변 문맥을 통해 유추하는 방법입니다. 가까운 단어들을 통해 의미를 유추합니다.\n",
    "\n",
    "#### **PMI(Pointwise Mutual Information)**\n",
    "두 단어 A, B가 얼마나 자주 같이 등장하는지 정보를 수치화하여 유추합니다.\n",
    "\n",
    "$$ PMI(A, B) = log \\frac{P(A, B)}{P(A) \\times P(B)}$$\n",
    "\n",
    "#### **Word2Vec**\n",
    "특정 단어 주변의 문맥, 즉 분포 정보를 함축하며 벡터로 만들어 사용하는 방법입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.2 Bag-of-Words Representation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BoW는 문법과 어순은 무시하지만 다중성을 유지하면서 단어의 가방에 단어들을 집어넣습니다. 그리고 이를 고유한 단어의 vocabulary를 만들거나 각 단어들을 one-hot vector로 만들어 사용하게 됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.3 Naïve Bayes Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naïve Bayes Classifier은 Bayes' theorem을 이용하여 간단한 분류를 하는 classifier입니다. \n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)} \\; (\\text{Bayes'\\, theorem})$$\n",
    "\n",
    "이제 이를 이용해 Naïve Bayes Classifier을 유추해보겠습니다. 각 document d는 class c를 가지고 있습니다. P(c|d)가 d가 c에 속할 확률입니다. Bayes' theorem을 적용하면 아래와 같은 식이 나옵니다.\n",
    "\n",
    "$$P(c|d) = \\frac{P(d|c)P(c)}{P(d)}$$\n",
    "\n",
    "근데 여기서 분모는 항상 같기 때문에 분모를 제거해도 괜찮습니다. 그렇기에 아래와 같은 식이 나옵니다.\n",
    "\n",
    "$$P(c|d) = P(d|c)P(c)$$\n",
    "\n",
    "$d$는 $words w_1, w_2, \\cdots, w_n$로 이루어져 있습니다. 그렇기에 위의 식은 다시 쓰면 다음과 같습니다.\n",
    "\n",
    "$$P(d|c)P(c) = P(w_1, w_2, \\cdots, w_n|c)P(c)$$\n",
    "\n",
    "이때 우리가 관심이 있는 것은 $P(c|d) = P(c|w_1, w_2, \\cdots, w_n)$이다. 이제 여기에 chain rule까지 적용하면 다음과 같이 나옵니다. 이때 확률에 관한 chain rule은 다음과 같습니다.\n",
    "\n",
    "$$\\begin{aligned} P(X_4, X_3, X_2, X_1) &= P(X_4|X_3, X_2, x_1) \\cdot P(X_3, X_2, X_1) \\\\\n",
    "&= P(X_4|X_3, X_2, X_1) \\cdot P(X_3|X_2, X_1) \\cdot P(X_2, X_1) \\\\\n",
    "&= P(X_4|X_3, X_2, X_1) \\cdot P(X_3|X_2, X_1) \\cdot P(X_2|X_1) \\cdot P(X_1) \\end{aligned}$$\n",
    "\n",
    "$$P(c|d) = P(d|c)P(c) = P(c) \\prod_{w_i \\in W} P(w_i|c)$$\n",
    "\n",
    "예시를 통해 알아보겠습니다. 밑에처럼 주어진 document와 word, class가 있습니다.\n",
    "\n",
    "||No.|Document($d$)|Class($c$)|\n",
    "|:---:|:---:|:---:|:---:|\n",
    "|Training|1|me free lottery|Spam|\n",
    "||2|free get free you|Spam|\n",
    "||3|you free scholarship|Inbox|\n",
    "||4|free to contact me|Inbox|\n",
    "||5|you won award|Inbox|\n",
    "||6|you ticket loterry|Spam|\n",
    "|<span style=\"color:skyblue\">Test</span>|<span style=\"color:skyblue\">7</span>|<span style=\"color:skyblue\">you free loterry</span>|<span style=\"color:skyblue\">?</span>|\n",
    "\n",
    "위와 같이 샘플이 주어져 있고 7번의 문장이 spam인지 아닌지 확인해야 합니다. 우리가 구한 식을 이용하여 식을 세워보겠습니다.\n",
    "\n",
    "$$P(c_{spam}|d_7) = P(c_{spam})P(w_{you}|c_{spam})P(w_{free}|c_{spam})P(w_{lottery}|c_{spam})$$\n",
    "$$P(c_{Inbox}|d_7) = P(c_{Inbox})P(w_{you}|c_{Inbox})P(w_{free}|c_{Inbox})P(w_{lottery}|c_{Inbox})$$\n",
    "\n",
    "만약 $P(c_{spam}|d_7) > P(c_{inbox}|d_7)$이면 스팸이고 $P(c_{spam}|d_7) < P(c_{inbox}|d_7)$이면 inbox로 분류될 것이다. 각 단어의 개수와 클래스 개수를 통해 결과를 보면 다음과 같습니다. \n",
    "\n",
    "![spam_result](_image/spam_result.PNG)\n",
    "\n",
    "이제 결과를 통해 종합적으로 계산하면 다음과 같습니다.\n",
    "\n",
    "$$P(c_{spam}|d_7) \n",
    "= P(c_{spam})P(w_{you}|c_{spam})P(w_{free}|c_{spam})P(w_{lottery}|c_{spam})\n",
    "= \\frac{1}{2} \\times \\frac{2}{10} \\times \\frac{3}{10} \\times \\frac{2}{10} = \\frac{6}{1000}$$\n",
    "$$P(c_{Inbox}|d_7) \n",
    "= P(c_{Inbox})P(w_{you}|c_{Inbox})P(w_{free}|c_{Inbox})P(w_{lottery}|c_{Inbox})\n",
    "= \\frac{1}{2} \\times \\frac{2}{10} \\times \\frac{2}{10} \\times \\frac{0}{10} = 0$$\n",
    "\n",
    "그러므로 7번 문장은 spam입니다.\n",
    "\n",
    "||No.|Document($d$)|Class($c$)|\n",
    "|:---:|:---:|:---:|:---:|\n",
    "|Training|1|me free lottery|Spam|\n",
    "||2|free get free you|Spam|\n",
    "||3|you free scholarship|Inbox|\n",
    "||4|free to contact me|Inbox|\n",
    "||5|you won award|Inbox|\n",
    "||6|you ticket loterry|Spam|\n",
    "|<span style=\"color:skyblue\">Test</span>|<span style=\"color:skyblue\">7</span>|<span style=\"color:skyblue\">you free loterry</span>|<span style=\"color:red\">Spam</span>|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **실습1. Naïve Bayes Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) Requirements**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 필요한 라이브러리들을 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "# POS(Part of Speech) tagger\n",
    "from konlpy import tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train data와 test data를 준비하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "# training data. input text와 정답 label (긍정(1), 부정(0))으로 구성\n",
    "data['train'] = [{'text': \"정말 재미있습니다. 추천합니다.\"},\n",
    "                {'text': \"기대했던 것보단 별로였네요.\"},\n",
    "                {'text': \"지루해서 다시 보고 싶다는 생각이 안 드네요.\"},\n",
    "                {'text': \"완전 최고입니다 ! 다시 보고 싶습니다.\"},\n",
    "                {'text': \"연기도 연출도 다 만족스러웠습니다.\"},\n",
    "                {'text': \"연기가 좀 별로였습니다.\"},\n",
    "                {'text': \"연출도 좋았고 배우분들 연기도 최고입니다.\"},\n",
    "                {'text': \"기념일에 방문했는데 연기도 연출도 다 좋았습니다.\"},\n",
    "                {'text': \"전반적으로 지루했습니다. 저는 별로였네요.\"},\n",
    "                {'text': \"CG에 조금 더 신경 썼으면 좋겠습니다.\"}\n",
    "                ]\n",
    "# test data\n",
    "data['test'] = [{'text': \"최고입니다. 또 보고 싶네요.\"},\n",
    "                {'text': \"별로였습니다. 되도록 보지 마세요.\"},\n",
    "                {'text': \"다른 분들께 추천드릴 수 있을 만큼 연출도 연기도 만족했습니다.\"},\n",
    "                {'text': \"연기가 좀 더 개선되었으면 좋겠습니다.\"}\n",
    "                ]\n",
    "\n",
    "train_labels = [1, 0, 0, 1, 1, 0, 1, 1, 0, 0]\n",
    "test_labels = [1, 0, 1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KoNLPy에서 제공하는 [꼬꼬마(Kkma) 형태소 분석기](https://konlpy.org/en/v0.5.2/api/konlpy.tag/#module-konlpy.tag._kkma)를 이용하여 tokenize 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 분석기 선언\n",
    "morph_analyzer = tag.Kkma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization 함수 정의\n",
    "def tokenization(data, morph_analyzer):\n",
    "    \"\"\"tokenization \n",
    "\n",
    "    Args:\n",
    "        data (list): list of data examples.\n",
    "        morph_analyzer (konlpy.tag._kkma.Kkma): morphological analyzer.\n",
    "\n",
    "    Returns:\n",
    "        tokenized_data (list): list of tokenized data examples.\n",
    "    \"\"\"\n",
    "    tokenized_data = []\n",
    "    \n",
    "    for example in tqdm(data):\n",
    "        tokens = morph_analyzer.morphs(example['text'])\n",
    "        tokenized_data.append(tokens)\n",
    "    \n",
    "    return tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 15.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# tokenization 함수를 이용한 데이터 tokenization\n",
    "tokenized_data = {}\n",
    "\n",
    "tokenized_data['train'] = tokenization(data['train'], morph_analyzer)\n",
    "tokenized_data['test'] = tokenization(data['test'], morph_analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['정말', '재미있', '습니다', '.', '추천', '하', 'ㅂ니다', '.'],\n",
       " ['기대', '하', '었', '더', 'ㄴ', '것', '보다', 'ㄴ', '별', '로', '이', '었', '네요', '.'],\n",
       " ['지루', '하', '어서', '다시', '보', '고', '싶', '다는', '생각', '이', '안', '들', '네요', '.'],\n",
       " ['완전', '최고', '이', 'ㅂ니다', '!', '다시', '보', '고', '싶', '습니다', '.'],\n",
       " ['연기', '도', '연출', '도', '다', '만족', '스럽', '었', '습니다', '.'],\n",
       " ['연기', '가', '좀', '별', '로', '이', '었', '습니다', '.'],\n",
       " ['연출', '도', '좋', '았', '고', '배우', '분', '들', '연기', '도', '최고', '이', 'ㅂ니다', '.'],\n",
       " ['기념일',\n",
       "  '에',\n",
       "  '방문',\n",
       "  '하',\n",
       "  '었',\n",
       "  '는데',\n",
       "  '연기',\n",
       "  '도',\n",
       "  '연출',\n",
       "  '도',\n",
       "  '다',\n",
       "  '좋',\n",
       "  '았',\n",
       "  '습니다',\n",
       "  '.'],\n",
       " ['전반적',\n",
       "  '으로',\n",
       "  '지루',\n",
       "  '하',\n",
       "  '었',\n",
       "  '습니다',\n",
       "  '.',\n",
       "  '저',\n",
       "  '는',\n",
       "  '별',\n",
       "  '로',\n",
       "  '이',\n",
       "  '었',\n",
       "  '네요',\n",
       "  '.'],\n",
       " ['CG', '에', '조금', '더', '신경', '쓰', '었', '으면', '좋', '겠', '습니다', '.']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenized_data 확인\n",
    "tokenized_data['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 tokenization 결과를 이용해서 word to index dictionary를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:00<00:00, 55964.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# train data의 tokenization 결과에서 unique token만 남긴 set으로 변환\n",
    "tokens = [token for i in range(len(tokenized_data['train'])) for token in tokenized_data['train'][i]]\n",
    "unique_train_tokens = set(tokens)\n",
    "\n",
    "# Naïve Bayes Classifier의 input에 들어갈 word의 index를 반환해주는 dictionary를 생성\n",
    "word2index = defaultdict() # key: word, value: index of word\n",
    "idx = 0\n",
    "for token in tqdm(unique_train_tokens):\n",
    "    word2index[token] = idx\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) Model Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 Naïve Bayes Classifier 모델 클래스를 구현하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier():\n",
    "    def __init__(self, word2index, k=0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            word2index (dict): mapping a word to a pre-assigned index.\n",
    "            k (float, optional): constant for smoothing. Defaults to 0.1.\n",
    "        \"\"\"\n",
    "        self.k = k # for smoothing\n",
    "        self.word2index = word2index\n",
    "        self.priors = {} # Prior probability for each class, P(c)\n",
    "        self.likelihoods = {} # Likelihood for each token, P(d|c)\n",
    "    \n",
    "    def _set_priors(self, labels):\n",
    "        \"\"\"\n",
    "        Set prior probability for each class, P(c).\n",
    "        Count the number of each class and caculate P(c) for each class.\n",
    "        \"\"\"\n",
    "        # Count the number of each class\n",
    "        class_counts = defaultdict(int)\n",
    "        for label in tqdm(labels):\n",
    "            class_counts[label] += 1\n",
    "        \n",
    "        # For each class, calcuate P(c)\n",
    "        for label, count in class_counts.items():\n",
    "            self.priors[label] = class_counts[label] / len(labels)\n",
    "    \n",
    "    def _set_likelihoods(self, tokens, labels):\n",
    "        \"\"\"\n",
    "        Set likelihood for each token, P(d|c).\n",
    "        First, count the number of each class for each token.\n",
    "        Then, calculate P(d|c) for a given class and token.\n",
    "        \"\"\"\n",
    "        token_dists = {}\n",
    "        number_of_token_for_class = defaultdict(int)\n",
    "        \n",
    "        # Count the number of each class for each token\n",
    "        for i, label in enumerate(tqdm(labels)):\n",
    "            count = 0\n",
    "            for token in tokens[i]:\n",
    "                # 'token in self.word2index'부분은 안 들어가도 되지 않는가?\n",
    "                if token not in token_dists and token in self.word2index:\n",
    "                    token_dists[token] = {0:0, 1:0}\n",
    "                token_dists[token][label] += 1\n",
    "                count += 1\n",
    "            number_of_token_for_class[label] += count\n",
    "\n",
    "        for token, dist in tqdm(token_dists.items()):\n",
    "            if token not in self.likelihoods:\n",
    "                self.likelihoods[token] = {\n",
    "                    0: (token_dists[token][0] + self.k) / (number_of_token_for_class[0] + len(self.word2index) * self.k),\n",
    "                    1: (token_dists[token][1] + self.k) / (number_of_token_for_class[1] + len(self.word2index) * self.k),\n",
    "                }\n",
    "    \n",
    "    def train(self, input_tokens, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_tokens (list): list of tokenized train data.\n",
    "            labels (): train labels for each sentence/document.\n",
    "        \"\"\"\n",
    "        self._set_priors(labels)\n",
    "        self._set_likelihoods(input_tokens, labels)\n",
    "    \n",
    "    def inference(self, input_tokens):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_tokens (list): list of tokenized test data.\n",
    "        \"\"\"\n",
    "        log_prob_0 = 0.0\n",
    "        log_prob_1 = 0.0\n",
    "        \n",
    "        for token in input_tokens:\n",
    "            if token in self.likelihoods:\n",
    "                log_prob_0 += math.log(self.likelihoods[token][0])\n",
    "                log_prob_1 += math.log(self.likelihoods[token][1])\n",
    "        \n",
    "        log_prob_0 += math.log(self.priors[0])\n",
    "        log_prob_1 += math.log(self.priors[1])\n",
    "        \n",
    "        if log_prob_0 >= log_prob_1:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주어진 학습 데이터에 대해 문장 분류 모델을 학습시키겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 56/56 [00:00<00:00, 56258.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# 문장 분류 모델 선언 및 학습\n",
    "classifier = NaiveBayesClassifier(word2index)\n",
    "classifier.train(tokenized_data['train'], train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4) Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각각의 test 데이터에 대해 정답값을 예측하고 Accuracy를 구합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 4164.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# Test data inference\n",
    "preds = []\n",
    "for test_tokens in tqdm(tokenized_data['test']):\n",
    "    pred = classifier.inference(test_tokens)\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Accuracy 측정\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(test_labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Topic Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.1 Bag-of-Words Encoding of Text Documents**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저번 챕터에서 본 Bag-of-Words를 다시 보겠습니다. \"John likes movies. Mary likes too.\"와 \"John also likes football.\"이란 두 문장이 주어졌을 때 각각 bag-of-words vector는 다음과 같습니다.\n",
    "\n",
    "![4-2-1](_image/4-2-1.PNG)\n",
    "\n",
    "각 단어를 사전으로 만들고 나타난 빈도수를 저장합니다. 그렇기에 행렬은 (키워드 개수) x (document 개수)의 형태로 나타납니다. 이 행렬을 term-document matrix(TDM)이라고 합니다. 순서 정보는 무시되는 단점이 있지만 많이 사용되고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.2 Topic Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선 topic은 가상의 document의 백 오브 워즈 벡터입니다. 그리고 백 오브 워즈 벡터의 값들을 정규화하면 합이 1이 되는 확률분포로 나타낼 수 있습니다. 그렇기에 토픽은 키워드들의 확률분포이자 키워드들의 가중치 조합이라고 할 수 있습니다. \n",
    "\n",
    "![4-2-2](_image/4-2-2.PNG)\n",
    "\n",
    "위 그림을 보면 맨 윗줄은 topic이고 밑에 있는 단어들은 그 topic에 속한 단어들입니다. topic의 제목은 프로그램이 자동으로 정해지며 군집에 속한 단어의 개수가 많으면 topic과 관련된 document라고 추측할 수 있습니다. 그리고 이를 바탕으로 document도 topic에 대해 군집을 만들 수 있습니다. \n",
    "\n",
    "밑의 그림은 topic modeling의 전반적 동작을 표현한 것입니다.\n",
    "\n",
    "<img src = \"https://iq.opengenus.org/content/images/2020/01/1_taTOiaCpd_CzGugx_PticQ.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.3 Topic Modeling Algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 동작하는 과정들을 상세히 보겠습니다.\n",
    "\n",
    "먼저 input document들을 bag-of-words vector들로 만듭니다. 이를 열벡터로 합쳐서 단어의 개수 x 문서의 개수 크기의 행렬 $A$를 만듭니다. 그리고 주어진 topic의 개수만큼 열벡터를 임의로 만듭니다. 이를 단어의 개수 x 토픽의 개수 크기의 행렬 $W$라고 하겠습니다. 이제 A를 잘 표현하도록 W에 곱할 행렬 H를 찾습니다. $H$는 토픽의 개수 x 문서의 개수 크기의 행렬일 것입니다. 이를 통해 H를 찾았다면 이제 H를 고정하고 W를 학습합니다. 이를 반복하며 최적의 W와 H를 찾는 것입니다. 이를 통해 행렬 W는 행렬 A가 가진 패턴들 중 빈도가 높은 패턴들로 학습되고 그 패턴들을 topic으로 가져가게 됩니다. \n",
    "\n",
    "이때 loss는 프로베니우스 놈으로 구합니다. \n",
    "\n",
    "$$\\lVert x \\rVert_F = (x_1^F + x_2^F + \\cdots + x_n^F)^{\\frac{1}{f}}$$\n",
    "\n",
    "벡터의 크기를 구할 때 자주 봤던 식입니다. 이를 통해 각 문서별 loss를 구하고 이것이 최소화되도록 H 안에 각 요소들을 바꿔줍니다. 이때 우리는 대체로 F = 2인 2놈을 자주 사용합니다. 이를 식으로 나타내면 다음과 같습니다. 이때 n은 단어의 개수입니다.\n",
    "\n",
    "$$\\underset{W, H \\geq 0}{arg \\; min} \\lVert A - WH \\rVert_2 = (A_1^2 - (W_1 H_1)^2 + \\cdots + A_n^2 - (W_nH_n)^2)^{\\frac{1}{2}}$$\n",
    "\n",
    "이제 구해진 topic을 가지고 document를 분류합니다. 여러 topic들의 선형 결합으로 가장 잘 표현할 수 있는 document의 가중치를 찾고 가중치가 가장 높은 topic으로 분류합니다.\n",
    "\n",
    "밑의 그림은 이를 간단하게 표현한 것입니다.\n",
    "\n",
    "<img src = \"https://iq.opengenus.org/content/images/2020/01/1_2uj6t3gNv76SpHrWf5-z-A.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습1. 크롤링한 뉴스 데이터로 Topic Modeling하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 실습은 직접 크롤링한 뉴스 데이터에 대해서 topic modeling을 해보겠습니다. \n",
    "\n",
    "간단하게 전 과정을 살펴보면 먼저 네이버에서 뉴스 기사를 간단하게 크롤링합니다.  \n",
    "기본적인 전처리 이후, Term-Document Matrix를 만들고 이를 non-negative factorization을 이용해 행렬 분해 하여 topic modeling을 수행합니다.   \n",
    "\n",
    "그 후, t-distributed stochastic neighbor embedding(T-SNE) 기법을 통해 topic별 시각화를 진행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) Crawiling News**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링에 필요한 패키지 불러오기\n",
    "from bs4 import BeautifulSoup\n",
    "from newspaper import article\n",
    "from time import sleep, time\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime\n",
    "from multiprocessing import Pool\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 실습은 정적 페이지인 네이버 뉴스 신문 기사 웹페이지를 크롤링합니다. 정적 페이지와 HTML에 대해선 [자](https://ko.wikipedia.org/wiki/%EC%A0%95%EC%A0%81_%EC%9B%B9_%ED%8E%98%EC%9D%B4%EC%A7%80)[료](https://opentutorials.org/course/2039)들을 참고해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_news(query: str=None, crawl_num: int=1000, workers: int=4):\n",
    "    \"\"\"crawl_news 뉴스 기사 텍스트가 담긴 list를 반환합니다.\n",
    "\n",
    "    Args:\n",
    "        query (str, optional): 검색어. Defaults to None.\n",
    "        crawl_num (int, optional): 수집할 뉴스 기사의 개수. Defaults to 1000.\n",
    "        workers (int, optional): multi-processing 시, 사용할 thread의 개수. Defaults to 4.\n",
    "    \"\"\"\n",
    "    url = 'https://search.naver.com/search.naver?where=news&sm=tab_jum&query={}'\n",
    "    articleList = []\n",
    "    crawled_url = set()\n",
    "    keyboard_interrupt = False\n",
    "    t = time()\n",
    "    idx = 0\n",
    "    page = 1\n",
    "    \n",
    "    # 서버에 url 요청 결과를 선언\n",
    "    res = requests.get(url.format(query))\n",
    "    sleep(0.5)\n",
    "    # res를 parsing할 parser를 선언\n",
    "    bs = BeautifulSoup(res.text, 'html.parser')\n",
    "    \n",
    "    with Pool(workers) as p:\n",
    "        while idx < crawl_num:\n",
    "            table = bs.find('ul', {'class': 'list_news'})\n",
    "            li_list = table.find_all('li', {'id': re.compile('sp_nws.*')})\n",
    "            area_list = [li.find('div', {'class':'news_area'}) for li in li_list]\n",
    "            a_list = [area.find('a', {'class':'news_tit'}) for area in area_list]\n",
    "            \n",
    "            for n in a_list[:min(len(a_list), crawl_num - idx)]:\n",
    "                articleList.append(n.get('title'))\n",
    "                idx += 1\n",
    "            page += 1\n",
    "            \n",
    "            pages = bs.find('div', {'class':'sc_page_inner'})\n",
    "            next_page_url = [p for p in pages.find_all('a') if p.text == str(page)][0].get('href')\n",
    "            \n",
    "            req = requests.get('https://search.naver.com/search.naver' + next_page_url)\n",
    "            bs = BeautifulSoup(req.text, 'html.parser')\n",
    "    return articleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '구글'\n",
    "articleList = crawl_news(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"공정위 새해도 '플랫폼 갑질' 겨눈다…구글·카카오·쿠팡 사정권\",\n",
       " '[신간] 구글은 어떻게 디자인하는가',\n",
       " \"구글, 인터넷뉴스서비스사업자 등록할까…여야 '법안 추진' 논의\",\n",
       " '비트코인도 뚫는 ‘무한대 성능’… 구글 “2029년 상업용 출시”',\n",
       " \"구글·카카오 등 플랫폼기업 '갑질' 칼빼든다\",\n",
       " '[CES 2022] MS·구글·아마존·메타도 안 나온다… 韓 독무대 된 세계 최대 IT쇼',\n",
       " '거친 운전에 차멀미가...구글 완전 자율주행차 타보니 [김성민의 실밸 레이더]',\n",
       " \"구글, UDC 스마트폰 특허 출원.. 차기 '픽셀7' 탑재될까?\",\n",
       " '구글 트렌드로 본 경제 키워드…‘블루 이코노미’에 주목하라',\n",
       " \"'적중률 70%' 미라클레터 올해도 10대기술 예측…구글 AR안경·테슬라 로봇\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articleList[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 tagger를 이용해 한글 명사와 알파벳만 추출해서 tdm을 만들겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "# Okt 형태소 분석기 선언\n",
    "t = Okt()\n",
    "\n",
    "words_list_ = []\n",
    "vocab = Counter()\n",
    "tag_set = set(['Noun', 'Alpha'])\n",
    "stopwords = set(['글자'])\n",
    "\n",
    "for i, article in enumerate(articleList):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    \n",
    "    # tagger를 이용한 품사 태깅\n",
    "    words = t.pos(article, norm=True, stem=True)\n",
    "    \n",
    "    # 명사와 알파벳 tag를 가지며 철자 길이가 2이상이고 stopwords에 포함되지 않는 단어들로 리스트 생성\n",
    "    words = [w for w, t in words if t in tag_set and len(w) > 1 and w not in stopwords]\n",
    "    \n",
    "    vocab.update(words)\n",
    "    words_list_.append((words, article))\n",
    "    \n",
    "vocab = sorted([w for w, freq in vocab.most_common(10000)])\n",
    "word2id = {w: i for i, w in enumerate(vocab)}\n",
    "words_list = []\n",
    "for words, article in words_list_:\n",
    "    words = [w for w in words if w in word2id]\n",
    "    if len(words) > 10:\n",
    "        words_list.append((words, article))\n",
    "\n",
    "del words_list_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) Build document-term matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 document-term matrix를 만들어보겠습니다. 문서 개수 x 단어 개수의 형태를 가집니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import numpy as np\n",
    "\n",
    "dtm = np.zeros((len(words_list), len(vocab)), dtype=np.float32)\n",
    "for i, (words, article) in enumerate(words_list):\n",
    "    for word in words:\n",
    "        dtm[i, word2id[word]] += 1\n",
    "\n",
    "dtm = TfidfTransformer().fit_transform(dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4) Topic Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 document-term matrix를 non-negative factorization(NMF)을 이용해 행렬 분해를 해보겠습니다. \n",
    "\n",
    "이때 NMF는 주어진 행렬 non-negative matrix X를 non-negative matrix W와 H로 행렬 분해하는 알고리즘입니다. 이어지는 코드를 통해 W와 H의 의미에 대해 파악하겠습니다. \n",
    "\n",
    "참고: [Non-negative Matrix Factorization](https://angeloyeo.github.io/2020/10/15/NMF.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-negative Matrix Factorization\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "K = 5\n",
    "nmf = NMF(n_components=K, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn의 NMF를 이용해 W와 H matrix를 구했습니다. \n",
    "\n",
    "W는 document length x K, H는 K x term length의 차원을 갖고 있습니다.  \n",
    "W 하나의 row는 각각의 feature에 얼만큼의 가중치를 줄 지에 대한 weight입니다.  \n",
    "H 하나의 row는 하나의 feature를 나타냅니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1422: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "W = nmf.fit_transform(dtm)\n",
    "H = nmf.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선 하나의 Topic(H의 n번째 row)에 접근해서 해당 topic에 대해 값이 가장 높은 20개의 단어를 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th topic\n",
      "결제 인앱 강제 금지법 정책 꼼수 애플 시간 겉도 제출 추가 요구 자료 허용 계획 이행 연내 구글 방통위 방지법 \n",
      "1th topic\n",
      "사전 레볼루션 사이트 넷마블 실시 공식 나이 세븐 등록 신작 대작 구글 게임 급등 최소 NFT 론칭 내년 오리진 이상 \n",
      "2th topic\n",
      "삼성 미국 전자 픽셀 모뎀 기관 조사 탑재 처음 마이크로소프트 부회장 영진 확인 동맹 이재용 아마존 시장 구글 사운드 공개 \n",
      "3th topic\n",
      "애플 규제 경쟁 위원장 저승사자 EU 규칙 촉구 플랫폼 시행 구글 공룡 방지 강화 엄격 적용 테크 넷플릭스 방통위 시급 \n",
      "4th topic\n",
      "검색 도전 시장 아마존 클라우드 비즈 확대 과감 위해 글로벌 투자 vs 전쟁 점화 사용자 국내 네이버 테크 구글 메타 \n"
     ]
    }
   ],
   "source": [
    "for k in range(K):\n",
    "    print(f\"{k}th topic\")\n",
    "    for index in H[k].argsort()[::-1][:20]:\n",
    "        print(vocab[index], end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 W에서 하나의 topic (W의 n번째 column)에 접근해서 해당 topic에 대해 값이 가장 높은 3개의 뉴스 기사 제목을 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===0th topic===\n",
      "겉도는 인앱결제 강제금지법… 구글은 결제정책 꼼수, 애플은 시간끌기\n",
      "겉도는 인앱결제 강제금지법… 구글은 결제정책 꼼수, 애플은 시간끌기\n",
      "구글은 결제정책 꼼수, 애플은 모르쇠… 힘못쓰는 갑질방지법 [인앱결제강제 금지법 시행 100일]\n",
      "\n",
      "===1th topic===\n",
      "넷마블, 기대신작 세븐나이츠 레볼루션...'구글·공식 사이트 사전등록 실시'\n",
      "넷마블, 기대신작 '세븐나이츠 레볼루션' 구글/공식 사이트 사전등록 실시\n",
      "넷마블, 기대작 세븐나이츠 레볼루션 구글·공식 사이트 사전등록 실시\n",
      "\n",
      "===2th topic===\n",
      "이재용 삼성전자 부회장, 미국에서 '뉴삼성' 동맹 확인..마이크로소프트·아마존·구글 경영진 잇따라 만나\n",
      "이재용 삼성전자 부회장, 미국에서 '뉴삼성' 동맹 확인..마이크로소프트·아마존·구글 경영진 잇따라 만나\n",
      "조사기관 “구글 픽셀6에 삼성전자 5G모뎀 탑재, 미국시장에서 처음\"\n",
      "\n",
      "===3th topic===\n",
      "'구글‧애플 저승사자' EU경쟁위원장, 빅테크 규제 위한 규칙 시행 촉구\n",
      "'구글‧애플 저승사자' EU경쟁위원장, 빅테크 규제 위한 규칙 시행 촉구\n",
      "구글·애플·넷플릭스 ‘플랫폼 공룡’ 갑질 방지 강화… 방통위, 규제 엄격 적용\n",
      "\n",
      "===4th topic===\n",
      "구글 vs 네이버… 빅테크 ‘검색전쟁’ 재점화 국내시장 1위에 ‘사용자 친화 검색’으로 도전장\n",
      "구글 vs 네이버… 빅테크 ‘검색전쟁’ 재점화 국내시장 1위에 ‘사용자 친화 검색’으로 도전장\n",
      "[글로벌 비즈] 구글 클라우드, 시장 확대 위해 과감한 투자…아마존에 도전장\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(K):\n",
    "    print(f\"==={k}th topic===\")\n",
    "    for index in W[:, k].argsort()[::-1][:3]:\n",
    "        print(words_list[index][1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2번째 topic에 대해 가장 높은 가중치를 갖는 제목 5개를 출력하면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이재용 삼성전자 부회장, 미국에서 '뉴삼성' 동맹 확인..마이크로소프트·아마존·구글 경영진 잇따라 만나\n",
      "이재용 삼성전자 부회장, 미국에서 '뉴삼성' 동맹 확인..마이크로소프트·아마존·구글 경영진 잇따라 만나\n",
      "조사기관 “구글 픽셀6에 삼성전자 5G모뎀 탑재, 미국시장에서 처음\"\n",
      "조사기관 “구글 픽셀6에 삼성전자 5G모뎀 탑재, 미국시장에서 처음\"\n",
      "[더벨][뉴삼성 차세대 리더십]소프트웨어 경쟁력 높인다…구글·MS출신 발탁승진\n"
     ]
    }
   ],
   "source": [
    "for index in W[:, 2].argsort()[::-1][:5]:\n",
    "    print(words_list[index][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5) Visualization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 t-SNE를 이용해 topic별 시각화를 진행하겠습니다. \n",
    "\n",
    "t-SNE(t-Stochastic Neighbor Embedding)은 고차원의 벡터를 데이터간 구조적 특징을 유지한 상태로 저차원(2~3차원) 벡터로 축소하는 방법 중 하나입니다. 주로 고차원 데이터의 시각화를 위해 사용됩니다.\n",
    "\n",
    "참고: [lovit: t-SNE](https://lovit.github.io/nlp/representation/2018/09/28/tsne/#:~:text=t%2DSNE%20%EB%8A%94%20%EA%B3%A0%EC%B0%A8%EC%9B%90%EC%9D%98,%EC%9D%98%20%EC%A7%80%EB%8F%84%EB%A1%9C%20%ED%91%9C%ED%98%84%ED%95%A9%EB%8B%88%EB%8B%A4.)\n",
    "\n",
    "참고: [ratsgo: t-SNE](https://ratsgo.github.io/machine%20learning/2017/04/28/tSNE/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:982: FutureWarning: The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 63 nearest neighbors...\n",
      "[t-SNE] Indexed 64 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 64 samples in 0.003s...\n",
      "[t-SNE] Computed conditional probabilities for sample 64 / 64\n",
      "[t-SNE] Mean sigma: 0.107609\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 47.561291\n",
      "[t-SNE] KL divergence after 1000 iterations: -0.062155\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# n_components = 차원 수\n",
    "tsne = TSNE(n_components=2, init='pca', verbose=1)\n",
    "\n",
    "# W matrix에 대해 t-sne를 수행합니다.\n",
    "W2d = tsne.fit_transform(W)\n",
    "\n",
    "# 각 뉴스 기사 제목마다 가중치가 가장 높은 topic을 저장합니다.\n",
    "topicIndex = [v.argmax() for v in W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1131\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"1131\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n",
       "  const css_urls = [];\n",
       "  \n",
       "\n",
       "  const inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"1131\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"5a684a58-54da-4364-ac07-102665a18197\" data-root-id=\"1132\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  const docs_json = {\"b4682a68-fa0e-4e7d-8772-58b06cbc8579\":{\"defs\":[],\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1141\"}],\"center\":[{\"id\":\"1144\"},{\"id\":\"1148\"},{\"id\":\"1181\"}],\"height\":580,\"left\":[{\"id\":\"1145\"}],\"renderers\":[{\"id\":\"1168\"}],\"title\":{\"id\":\"1170\"},\"toolbar\":{\"id\":\"1156\"},\"width\":720,\"x_range\":{\"id\":\"1133\"},\"x_scale\":{\"id\":\"1137\"},\"y_range\":{\"id\":\"1135\"},\"y_scale\":{\"id\":\"1139\"}},\"id\":\"1132\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"label\":{\"field\":\"topic\"},\"renderers\":[{\"id\":\"1168\"}]},\"id\":\"1182\",\"type\":\"LegendItem\"},{\"attributes\":{\"source\":{\"id\":\"1163\"}},\"id\":\"1169\",\"type\":\"CDSView\"},{\"attributes\":{\"coordinates\":null,\"formatter\":{\"id\":\"1173\"},\"group\":null,\"major_label_policy\":{\"id\":\"1174\"},\"ticker\":{\"id\":\"1146\"}},\"id\":\"1145\",\"type\":\"LinearAxis\"},{\"attributes\":{\"data\":{\"color\":[\"#ffbb78\",\"#ffbb78\",\"#ffbb78\",\"#ffbb78\",\"#2ca02c\",\"#1f77b4\",\"#ffbb78\",\"#2ca02c\",\"#1f77b4\",\"#ffbb78\",\"#2ca02c\",\"#1f77b4\",\"#2ca02c\",\"#2ca02c\",\"#ffbb78\",\"#2ca02c\",\"#2ca02c\",\"#ffbb78\",\"#1f77b4\",\"#1f77b4\",\"#1f77b4\",\"#1f77b4\",\"#ffbb78\",\"#2ca02c\",\"#2ca02c\",\"#ffbb78\",\"#ffbb78\",\"#ff7f0e\",\"#ffbb78\",\"#2ca02c\",\"#ffbb78\",\"#ffbb78\",\"#2ca02c\",\"#2ca02c\",\"#ffbb78\",\"#ffbb78\",\"#aec7e8\",\"#aec7e8\",\"#ffbb78\",\"#2ca02c\",\"#aec7e8\",\"#ffbb78\",\"#2ca02c\",\"#aec7e8\",\"#ff7f0e\",\"#2ca02c\",\"#ffbb78\",\"#aec7e8\",\"#ffbb78\",\"#aec7e8\",\"#ffbb78\",\"#ff7f0e\",\"#ff7f0e\",\"#ff7f0e\",\"#ffbb78\",\"#ffbb78\",\"#ffbb78\",\"#ffbb78\",\"#2ca02c\",\"#2ca02c\",\"#ff7f0e\",\"#ff7f0e\",\"#ffbb78\",\"#ffbb78\"],\"document\":[\"'\\uc801\\uc911\\ub960 70%' \\ubbf8\\ub77c\\ud074\\ub808\\ud130 \\uc62c\\ud574\\ub3c4 10\\ub300\\uae30\\uc220 \\uc608\\uce21\\u2026\\uad6c\\uae00 AR\\uc548\\uacbd\\u00b7\\ud14c\\uc2ac\\ub77c \\ub85c\\ubd07\",\"\\\"\\uc62c\\ud574 \\uba54\\ud0c0\\ubc84\\uc2a4 \\uacbd\\uc7c1 \\ubcf8\\uaca9\\ud654\\\"...\\uba54\\ud0c0\\uac00 \\uc120\\ub450, \\uc560\\ud50c\\u00b7MS\\u00b7\\uad6c\\uae00\\uc774 \\ucd94\\uaca9\",\"\\uacf5\\uc815\\uc704\\uc6d0\\uc7a5 \\\"\\uad6c\\uae00 \\uc571\\ub9c8\\ucf13\\uc2dc\\uc7a5 \\uacbd\\uc7c1\\uc81c\\ud55c\\ud589\\uc704 \\uc804\\uc6d0\\ud68c\\uc758 \\uc2ec\\uc758 \\uc608\\uc815\\\"\",\"\\ud2f0\\uc564\\ucf00\\uc774\\ud329\\ud1a0\\ub9ac '\\uac80\\uc740\\uc655\\uad00:\\uba54\\uae30\\uc655\\uc758 \\ubd84\\ub178' \\uad6c\\uae00 \\ud50c\\ub808\\uc774 \\uc778\\uae30 \\uc21c\\uc704 1\\uc704 \\ub2ec\\uc131\",\"[\\uae00\\ub85c\\ubc8c \\ube44\\uc988] \\uad6c\\uae00 \\ud074\\ub77c\\uc6b0\\ub4dc, \\uc2dc\\uc7a5 \\ud655\\ub300 \\uc704\\ud574 \\uacfc\\uac10\\ud55c \\ud22c\\uc790\\u2026\\uc544\\ub9c8\\uc874\\uc5d0 \\ub3c4\\uc804\\uc7a5\",\"\\uc560\\ud50c, \\uc5f0\\ub0b4 \\uc778\\uc571\\uacb0\\uc81c\\uac15\\uc81c\\uae08\\uc9c0\\ubc95 \\uc774\\ud589\\uacc4\\ud68d \\uc81c\\ucd9c\\ud560\\uae4c?\\u2026\\ubc29\\ud1b5\\uc704, \\uad6c\\uae00\\uc5d0\\ub3c4 '\\uc81c3\\uc790 \\uacb0\\uc81c \\ud5c8\\uc6a9' \\ucd94\\uac00\\uc790\\ub8cc \\uc694\\uad6c\",\"\\uad6c\\uae00\\u00b7\\uc560\\ud50c\\u00b7\\ub137\\ud50c\\ub9ad\\uc2a4 \\u2018\\ud50c\\ub7ab\\ud3fc \\uacf5\\ub8e1\\u2019 \\uac11\\uc9c8 \\ubc29\\uc9c0 \\uac15\\ud654\\u2026 \\ubc29\\ud1b5\\uc704, \\uaddc\\uc81c \\uc5c4\\uaca9 \\uc801\\uc6a9\",\"[\\uae00\\ub85c\\ubc8c \\ube44\\uc988] \\uad6c\\uae00 \\ud074\\ub77c\\uc6b0\\ub4dc, \\uc2dc\\uc7a5 \\ud655\\ub300 \\uc704\\ud574 \\uacfc\\uac10\\ud55c \\ud22c\\uc790\\u2026\\uc544\\ub9c8\\uc874\\uc5d0 \\ub3c4\\uc804\\uc7a5\",\"\\uc560\\ud50c, \\uc5f0\\ub0b4 \\uc778\\uc571\\uacb0\\uc81c\\uac15\\uc81c\\uae08\\uc9c0\\ubc95 \\uc774\\ud589\\uacc4\\ud68d \\uc81c\\ucd9c\\ud560\\uae4c?\\u2026\\ubc29\\ud1b5\\uc704, \\uad6c\\uae00\\uc5d0\\ub3c4 '\\uc81c3\\uc790 \\uacb0\\uc81c \\ud5c8\\uc6a9' \\ucd94\\uac00\\uc790\\ub8cc \\uc694\\uad6c\",\"\\uad6c\\uae00\\u00b7\\uc560\\ud50c\\u00b7\\ub137\\ud50c\\ub9ad\\uc2a4 \\u2018\\ud50c\\ub7ab\\ud3fc \\uacf5\\ub8e1\\u2019 \\uac11\\uc9c8 \\ubc29\\uc9c0 \\uac15\\ud654\\u2026 \\ubc29\\ud1b5\\uc704, \\uaddc\\uc81c \\uc5c4\\uaca9 \\uc801\\uc6a9\",\"\\uad6c\\uae00 \\uacf5\\uc778 \\uad50\\uc721\\uc804\\ubb38\\uac00 \\uae40\\ub3d9\\uc6d0 \\ub300\\ud45c\\uc758 'Google \\ud65c\\uc6a9\\ubc95' \\ub124\\uc774\\ubc84 \\uc5d1\\uc2a4\\ud37c\\ud2b8 \\uc624\\ud508\",\"\\\"\\uc720\\ud29c\\ube0c\\ub3c4 \\ud1a0\\uc2a4\\ud398\\uc774\\ub85c\\\"\\u2026 \\ud1a0\\uc2a4\\ud398\\uc774\\uba3c\\uce20, \\uad6c\\uae00 \\uc81c\\ud734\\ub85c \\uac04\\ud3b8\\uacb0\\uc81c \\ud655\\uc7a5\",\"\\uc624\\ubbf8\\ud06c\\ub860 \\ud655\\uc0b0\\uc5d0 CES \\ube68\\uac04\\ubd88\\u2026\\ucd5c\\ud0dc\\uc6d0\\u00b7\\uc815\\uc758\\uc120 \\ucd9c\\uc7a5 \\uc7ac\\uac80\\ud1a0, \\uad6c\\uae00\\u00b7\\uba54\\ud0c0\\u00b7MS \\ubd88\\ucc38\",\"LG CNS, \\uad6c\\uae00 \\ud504\\ub9ac\\ubbf8\\uc5b4 \\ud30c\\ud2b8\\ub108 \\uc5b4\\uc6cc\\uc988\\uc11c \\ub9ac\\ub4dc \\uc0dd\\uc131\\uacfc \\ubca0\\uc2a4\\ud2b8\\ud300 2\\uac1c\\ubd80\\ubb38 \\uc218\\uc0c1\",\"\\ubbf8\\ub974\\uc758 \\uc804\\uc1242: MOM, \\uad6c\\uae00 \\ub9e4\\ucd9c \\uc21c\\uc704 \\uc0c1\\uc2b9\\uc138, \\uc0c1\\uc704\\uad8c \\uc9c4\\uc785 \\ubc1c\\ud310 \\ub9c8\\ub828\",\"LG CNS, \\u2018\\uad6c\\uae00 \\ud504\\ub9ac\\ubbf8\\uc5b4 \\ud30c\\ud2b8\\ub108 \\uc5b4\\uc6cc\\uc988\\u2019 3\\ud68c \\uc5f0\\uc18d \\uc218\\uc0c1\\u2026\\uc720\\uc77c 2\\uac1c\\ubd80\\ubb38 \\uc120\\uc815\",\"\\uc544\\ub9c8\\uc874. \\uba54\\ud0c0. \\ud2b8\\uc704\\ud130 \\uc774\\uc5b4 GM. \\uad6c\\uae00 \\uc6e8\\uc774\\ubaa8\\ub3c4 \\uc624\\ubbf8\\ud06c\\ub860 \\ud655\\uc0b0\\uc73c\\ub85c 'CES 2022' \\ucc38\\uac00 \\ucde8\\uc18c\",\"\\ud574\\ud53c\\uba38\\ub2c8, \\uad6c\\uae00\\uae30\\ud504\\ud2b8\\ucf54\\ub4dc \\uad6c\\ub9e4\\uace0\\uac1d \\ub300\\uc0c1 \\ub9ac\\ub2c8\\uc9c0W \\uc544\\uc774\\ud15c \\uc774\\ubca4\\ud2b8 \\uc9c4\\ud589\",\"\\uad6c\\uae00\\uc740 \\uacb0\\uc81c\\uc815\\ucc45 \\uaf3c\\uc218, \\uc560\\ud50c\\uc740 \\ubaa8\\ub974\\uc1e0\\u2026 \\ud798\\ubabb\\uc4f0\\ub294 \\uac11\\uc9c8\\ubc29\\uc9c0\\ubc95 [\\uc778\\uc571\\uacb0\\uc81c\\uac15\\uc81c \\uae08\\uc9c0\\ubc95 \\uc2dc\\ud589 100\\uc77c]\",\"\\ud1a0\\uc2a4\\ud398\\uc774\\uba3c\\uce20 \\uad6c\\uae00\\uacfc \\ud1a0\\uc2a4\\ud398\\uc774 \\uc81c\\ud734, \\uae40\\ubbfc\\ud45c \\\"\\uac04\\ud3b8\\ud55c \\uacb0\\uc81c\\uacbd\\ud5d8 \\uc9c0\\uc6d0\\\"\",\"\\uac89\\ub3c4\\ub294 \\uc778\\uc571\\uacb0\\uc81c \\uac15\\uc81c\\uae08\\uc9c0\\ubc95\\u2026 \\uad6c\\uae00\\uc740 \\uacb0\\uc81c\\uc815\\ucc45 \\uaf3c\\uc218, \\uc560\\ud50c\\uc740 \\uc2dc\\uac04\\ub04c\\uae30\",\"\\uac89\\ub3c4\\ub294 \\uc778\\uc571\\uacb0\\uc81c \\uac15\\uc81c\\uae08\\uc9c0\\ubc95\\u2026 \\uad6c\\uae00\\uc740 \\uacb0\\uc81c\\uc815\\ucc45 \\uaf3c\\uc218, \\uc560\\ud50c\\uc740 \\uc2dc\\uac04\\ub04c\\uae30\",\"[\\ud2b9\\uc9d5\\uc8fc] FSN, '\\ud2f1\\ud1a1' \\uad6c\\uae00 \\ub204\\ub974\\uace0 \\uc804\\uc138\\uacc41\\uc704 \\uae30\\ub85d\\u2026 \\uc804\\uc138\\uacc4 \\ud2f1\\ud1a1 \\uad11\\uace0\\ub300\\ud589 \\uad8c\\ud55c \\ubd80\\uac01\",\"[\\uc9d1\\uc911\\ucde8\\uc7acM] MS \\uad6c\\uae00 A\\ud559\\uc810, \\ub124\\uc774\\ubc84 \\uce74\\uce74\\uc624 F\\ud559\\uc810\\u2025IT\\uae30\\uc5c5\\ub4e4\\uc758 \\ud0c4\\uc18c \\uc131\\uc801\\ud45c\",\"[\\uae08\\uc77c \\uc0b0\\uc5c5\\uacc4 \\uc8fc\\uc694\\uae30\\uc0ac] \\\"\\uc624\\ubbf8\\ud06c\\ub860 \\ubcc0\\uc774 \\ud655\\uc0b0\\\" \\uad6c\\uae00\\u00b7\\uc544\\ub9c8\\uc874\\u00b7\\uba54\\ud0c0\\u00b7\\ud2f1\\ud1a1 CES \\ubd88\\ucc38\\u2026 \\\"8K \\uc0dd\\ud0dc\\uacc4 \\ud655\\uc7a5 \\uac00\\uc18d\\ud654\\\" \\uc544\\ub9c8\\uc874, '8K \\ud611\\ud68c' \\ud569\\ub958 \\u5916\",\"[\\ub274\\uc2a4\\ud574\\uc124]\\uc560\\ud50c\\u00b7\\uad6c\\uae00 \\uc790\\uccb4\\ub4f1\\uae09\\ubd84\\ub958 \\ub0a8\\uc6a9...\\uae30\\uc900 \\uc815\\ube44 \\uc2dc\\uae09\",\"[\\ub274\\uc2a4\\ud574\\uc124]\\uc560\\ud50c\\u00b7\\uad6c\\uae00 \\uc790\\uccb4\\ub4f1\\uae09\\ubd84\\ub958 \\ub0a8\\uc6a9...\\uae30\\uc900 \\uc815\\ube44 \\uc2dc\\uae09\",\"LG\\uc804\\uc790, 2022\\ub144\\ud615 \\uc0ac\\uc6b4\\ub4dc \\ubc14 \\uacf5\\uac1c...\\uad6c\\uae00\\u00b7\\uc544\\ub9c8\\uc874, \\uc778\\uacf5\\uc9c0\\ub2a5 \\uc2a4\\ud53c\\ucee4 \\uc5f0\\ub3d9 \\ud1b5\\ud574 \\uc74c\\uc131\\ub9cc\\uc73c\\ub85c \\uc0ac\\uc6b4\\ub4dc \\ubc14 \\uc870\\uc791\",\"[AICON \\uad11\\uc8fc 2021] \\uad6c\\uae00 \\ucf54\\ub9ac\\uc544 \\uae40\\ud0dc\\uc6d0 \\uc804\\ubb34 \\\"\\ub514\\uc9c0\\ud138 \\uae30\\uc220\\uc740 \\uc138\\uc0c1\\uc758 \\ubb38\\uc81c\\ub97c \\ud574\\uacb0\\ud55c\\ub2e4\\\"\",\"\\uc120\\uc6b0\\uc724 \\uc640\\uadf8 \\ub300\\ud45c \\\"\\uad6c\\uae00 \\ud611\\uc5c5 \\uccab \\uad6d\\ub0b4 OTA\\u2026\\uc678\\uad6d\\uc778\\ub3c4 \\uc774\\uc81c \\uc6b0\\ub9ac \\uace0\\uac1d\\\" [\\uc778\\ud130\\ubdf0]\",\"\\uad11\\uc9c4\\uc708\\ud14d, 3D\\uc0ac\\uc6b4\\ub4dc \\ucd2c\\uc601 \\uc2e0\\uae30\\uc220 \\uac1c\\ubc1c...\\uad6c\\uae00 \\ub4f1 \\uc2a4\\ub9c8\\ud2b8\\ub514\\ubc14\\uc774\\uc2a4 \\uacb0\\ud569 1\\ucc28 \\uc0c1\\uc6a9\\ubaa8\\ub378 \\uc591\\uc0b0 \\ubaa9\\ud45c\",\"'\\uad6c\\uae00\\u00b7\\ub137\\ud50c\\ub9ad\\uc2a4' \\ub300\\uc0c1 \\ub9dd \\uc548\\uc815\\uc131 \\ud655\\ubcf4 \\uac00\\uc774\\ub4dc\\ub77c\\uc778 \\ub9c8\\ub828\\u2026 \\uc778\\ud130\\ub137 \\ud68c\\uc120 \\uc6a9\\ub7c9 \\ud655\\ubcf4 \\uc758\\ubb34\\ud654\",\"\\uad6c\\uae00 vs \\ub124\\uc774\\ubc84\\u2026 \\ube45\\ud14c\\ud06c \\u2018\\uac80\\uc0c9\\uc804\\uc7c1\\u2019 \\uc7ac\\uc810\\ud654 \\uad6d\\ub0b4\\uc2dc\\uc7a5 1\\uc704\\uc5d0 \\u2018\\uc0ac\\uc6a9\\uc790 \\uce5c\\ud654 \\uac80\\uc0c9\\u2019\\uc73c\\ub85c \\ub3c4\\uc804\\uc7a5\",\"\\uad6c\\uae00 vs \\ub124\\uc774\\ubc84\\u2026 \\ube45\\ud14c\\ud06c \\u2018\\uac80\\uc0c9\\uc804\\uc7c1\\u2019 \\uc7ac\\uc810\\ud654 \\uad6d\\ub0b4\\uc2dc\\uc7a5 1\\uc704\\uc5d0 \\u2018\\uc0ac\\uc6a9\\uc790 \\uce5c\\ud654 \\uac80\\uc0c9\\u2019\\uc73c\\ub85c \\ub3c4\\uc804\\uc7a5\",\"[\\uc704\\ud074\\ub9ac\\ub9ac\\ud3ec\\ud2b8 60\\ud638] '\\uc62c\\ud574 \\ud55c\\uad6d\\uc778\\uc774 \\uad6c\\uae00\\uc11c \\uac00\\uc7a5 \\ub9ce\\uc774 \\ucc3e\\uc740 \\uac80\\uc0c9\\uc5b4' 3\\uc704 \\uc624\\uc9d5\\uc5b4\\uac8c\\uc784, 2\\uc704 \\ubc31\\uc2e0\\uc608\\uc57d, 1\\uc704\\ub294\\u2026\",\"[\\uc704\\ud074\\ub9ac\\ub9ac\\ud3ec\\ud2b8 60\\ud638] '\\uc62c\\ud574 \\ud55c\\uad6d\\uc778\\uc774 \\uad6c\\uae00\\uc11c \\uac00\\uc7a5 \\ub9ce\\uc774 \\ucc3e\\uc740 \\uac80\\uc0c9\\uc5b4' 3\\uc704 \\uc624\\uc9d5\\uc5b4\\uac8c\\uc784, 2\\uc704 \\ubc31\\uc2e0\\uc608\\uc57d, 1\\uc704\\ub294\\u2026\",\"\\ub137\\ub9c8\\ube14, \\uae30\\ub300\\uc791 \\uc138\\ube10\\ub098\\uc774\\uce20 \\ub808\\ubcfc\\ub8e8\\uc158 \\uad6c\\uae00\\u00b7\\uacf5\\uc2dd \\uc0ac\\uc774\\ud2b8 \\uc0ac\\uc804\\ub4f1\\ub85d \\uc2e4\\uc2dc\",\"\\uc5d4\\ub3cc\\ud540\\ucee4\\ub125\\ud2b8 \\uc2e0\\uc791 '\\uc2a4\\ud0d1 \\ubc14\\uc774: \\uc0b0\\ud0c0 \\ub808\\uc774\\uc2a4' \\uad6c\\uae00 \\ud50c\\ub808\\uc774 \\uc2a4\\ud1a0\\uc5b4 \\ucd9c\\uc2dc\",\"\\ubbf8, \\uad6c\\uae00\\u00b7\\uba54\\ud0c0 '\\ud0dc\\ud3c9\\uc591 \\uad11\\ucf00\\uc774\\ube14' \\uc0ac\\uc6a9\\uc2b9\\uc778 \\uad8c\\uace0\\u2026\\\"\\uc548\\ubcf4 \\uc6b0\\ub824\\ub85c \\ud64d\\ucf69 \\uad6c\\uac04\\uc740 \\uc81c\\uc678\\\"\",\"\\uc2e4\\uc801 \\uc804\\ub9dd \\uc5c7\\uac08\\ub9ac\\ub294 \\u7f8e \\ube45\\ud14c\\ud06c, MS\\u00b7\\uad6c\\uae00\\u00b7\\uba54\\ud0c0 \\u2018\\ub9d1\\uc74c\\u2019 vs \\uc560\\ud50c\\u00b7\\uc544\\ub9c8\\uc874 \\u2018\\uae00\\uc384\\u2019\",\"\\ub137\\ub9c8\\ube14, \\uae30\\ub300\\uc2e0\\uc791 \\uc138\\ube10\\ub098\\uc774\\uce20 \\ub808\\ubcfc\\ub8e8\\uc158...'\\uad6c\\uae00\\u00b7\\uacf5\\uc2dd \\uc0ac\\uc774\\ud2b8 \\uc0ac\\uc804\\ub4f1\\ub85d \\uc2e4\\uc2dc'\",\"\\uc544\\uc774\\uc2a4\\ubc84\\ub4dc \\uac8c\\uc784\\uc988 '\\ubbf8\\ub974\\uc758 \\uc804\\uc1242: MOM', \\uad6c\\uae00 \\ubb34\\ub8cc \\uc778\\uae30 \\uc21c\\uc704 2\\uc704 \\ub2ec\\uc131\",\"\\ud55c\\uad6d\\uacf5\\uc608\\ub514\\uc790\\uc778\\ubb38\\ud654\\uc9c4\\ud765\\uc6d0, \\uad6c\\uae00 \\uc544\\ud2b8 \\uc564 \\uceec\\ucc98\\uc640 \\ud611\\uc5c5...\\ud55c\\uad6d\\uc758 \\uacf5\\uc608\\ubb38\\ud654 \\uc120\\ubcf4\\uc5ec\",\"\\ub137\\ub9c8\\ube14, \\uae30\\ub300\\uc2e0\\uc791 '\\uc138\\ube10\\ub098\\uc774\\uce20 \\ub808\\ubcfc\\ub8e8\\uc158' \\uad6c\\uae00/\\uacf5\\uc2dd \\uc0ac\\uc774\\ud2b8 \\uc0ac\\uc804\\ub4f1\\ub85d \\uc2e4\\uc2dc\",\"[\\ub354\\ubca8][\\ub274\\uc0bc\\uc131 \\ucc28\\uc138\\ub300 \\ub9ac\\ub354\\uc2ed]\\uc18c\\ud504\\ud2b8\\uc6e8\\uc5b4 \\uacbd\\uc7c1\\ub825 \\ub192\\uc778\\ub2e4\\u2026\\uad6c\\uae00\\u00b7MS\\ucd9c\\uc2e0 \\ubc1c\\ud0c1\\uc2b9\\uc9c4\",\"\\ud3ec\\uc2a4\\ud14d, \\uc2a4\\ud3ec\\uce20 \\uc778\\uacf5\\uc9c0\\ub2a5(AI) \\ubd84\\uc57c...\\uad6c\\uae00 \\ud074\\ub77c\\uc6b0\\ub4dc \\uc544\\u2027\\ud0dc \\uacf5\\uacf5\\ubd80\\ubb38 \\ud30c\\ud2b8\\ub108 \\uc120\\uc815\",\"[\\uc810\\uc2ec \\ube0c\\ub9ac\\ud551]\\uc554\\ud638\\ud654\\ud3d0 \\ud558\\ub77d\\uc138\\u00b7\\u00b7\\u00b7\\uc5d0\\ub9ad \\uc288\\ubbf8\\ud2b8 \\uad6c\\uae00 \\uc804 \\ud68c\\uc7a5, \\uccb4\\uc778\\ub9c1\\ud06c \\ud504\\ub85c\\uc81d\\ud2b8 \\ud569\\ub958\",\"\\ub124\\uc624\\ub9ac\\uc9c4, \\uc2e0\\uc791 \\uac8c\\uc784 \\uad6c\\uae00 \\ub4f1 3\\ub300 \\uc571 \\ub9c8\\ucf13\\ub860\\uce6d\\u2026\\u201c\\ub0b4\\ub144 \\ucd5c\\uc18c 2\\uac1c \\uc774\\uc0c1 \\uc2e0\\uc791\\uacfc NFT\\uac8c\\uc784 \\uacf5\\uac1c \\uc608\\uc815\\u201d\",\"[AICON \\uad11\\uc8fc 2021] \\uad6c\\uae00 \\ucf54\\ub9ac\\uc544 \\uae40\\ud0dc\\uc6d0 \\uc804\\ubb34 \\uae30\\uc870 \\uac15\\uc5f0 \\ub098\\uc11c... \\\"\\ub514\\uc9c0\\ud138 \\uae30\\uc220 \\ud1b5\\ud574 \\ub2f9\\ub300\\uc758 \\uad00\\uc2ec\\uc0ac\\uc640 \\ubcc0\\ud654 \\ud30c\\uc545\\ud560 \\uc218 \\uc788\\uc5b4!\\\"\",\"\\uc601\\uc6c5 \\uc218\\uc9d1 \\ud30c\\ud2f0 \\ubc29\\uce58\\ud615 RPG '\\ub9d0\\ub2e8 \\ubcd1\\uc0ac\\uc5d0\\uc11c \\uad70\\uc8fc\\uae4c\\uc9c0 - \\uad70\\uc8fc \\ud0a4\\uc6b0\\uae30' \\uad6c\\uae00\\ud50c\\ub808\\uc774 \\ucd9c\\uc2dc\",\"[\\ud2b9\\uc9d5\\uc8fc]NHN\\ubc85\\uc2a4, \\uad6c\\uae00\\u00b7\\uc560\\ud50c\\uc5d0 \\uc2f8\\uc774\\uc6d4\\ub4dc \\uc571 \\uc2e0\\uccad\\u2026\\ub124\\uc774\\ubc84\\u00b7\\uce74\\uce74\\uc624 \\uc787\\ub294 K-\\ud50c\\ub7ab\\ud3fc \\ucd9c\\uc0ac\\ud45c\",\"\\uad6c\\uae00, 12\\uc6d4 '\\ud53d\\uc140 \\ud53c\\ucc98 \\ub4dc\\ub86d' \\uc5c5\\ub370\\uc774\\ud2b8 \\uacf5\\uac1c.. '\\ud53d\\uc1406' \\uc9c0\\ubb38 \\uc13c\\uc11c \\uc131\\ub2a5 \\uac1c\\uc120\",\"\\uc870\\uc0ac\\uae30\\uad00 \\u201c\\uad6c\\uae00 \\ud53d\\uc1406\\uc5d0 \\uc0bc\\uc131\\uc804\\uc790 5G\\ubaa8\\ub380 \\ud0d1\\uc7ac, \\ubbf8\\uad6d\\uc2dc\\uc7a5\\uc5d0\\uc11c \\ucc98\\uc74c\\\"\",\"\\uc870\\uc0ac\\uae30\\uad00 \\u201c\\uad6c\\uae00 \\ud53d\\uc1406\\uc5d0 \\uc0bc\\uc131\\uc804\\uc790 5G\\ubaa8\\ub380 \\ud0d1\\uc7ac, \\ubbf8\\uad6d\\uc2dc\\uc7a5\\uc5d0\\uc11c \\ucc98\\uc74c\\\"\",\"[\\uae09\\ub4f1\\uc655\\uc758 '\\uae09\\ub4f1\\ub9e5 \\ud544\\uc0b4\\uae30'] NHN\\ubc85\\uc2a4, \\uad6c\\uae00\\u00b7\\uc560\\ud50c \\uc571 \\ub4f1\\ub85d \\uc2ec\\uc0ac \\uc2e0\\uccad \\uc18c\\uc2dd\\uc5d0 \\uc0c1\\uc2b9! GO? STOP?!\",\"\\uad6c\\uae00 \\uc790\\uccb4 \\uac1c\\ubc1c \\uc571\\ud50c\\ub808\\uc774\\uc5b4 'Google Play Games' \\uacf5\\uac1c, \\uc571 \\ud50c\\ub808\\uc774\\uc5b4 \\uc0dd\\ud0dc\\uacc4 \\uc9c0\\uac01\\ubcc0\\ub3d9 \\uc62c\\uae4c\",\"\\uc5d0\\ub9ad \\uc288\\ubbf8\\ud2b8 \\uc804 \\uad6c\\uae00 CEO, \\ube14\\ub85d\\uccb4\\uc778 \\uc624\\ub77c\\ud074 \\uc194\\ub8e8\\uc158 \\uac1c\\ubc1c\\uc0ac '\\uccb4\\uc778\\ub9c1\\ud06c' \\ud569\\ub958\",\"[\\uc5ec\\uc758\\uc625] \\uc5d0\\ub9ad \\uc288\\ubbf8\\ud2b8 \\uc804 \\uad6c\\uae00 CEO, \\ube14\\ub85d\\uccb4\\uc778 \\uc624\\ub77c\\ud074 \\uc194\\ub8e8\\uc158 \\uac1c\\ubc1c\\uc0ac \\uc804\\uaca9 \\ud569\\ub958\",\"\\ub098\\uc2a4\\ubbf8\\ub514\\uc5b4, '\\uad6c\\uae00 \\ud504\\ub9ac\\ubbf8\\uc5b4 \\ud30c\\ud2b8\\ub108 \\uc5b4\\uc6cc\\uc988 2021' \\uc218\\uc0c1\\u2026\\ube0c\\ub79c\\ub4dc \\uc9c0\\uc18d\\uac00\\ub2a5 \\uc131\\uc7a5\\uc5d0 \\uae30\\uc5ec\",\"[\\uc0bc\\uc815KPMG \\ubcf4\\uace0\\uc11c] \\ud14c\\ud06c \\uae30\\uc5c5, ESG \\ub9ac\\uc2a4\\ud06c \\uc9c1\\uba74\\u2026 \\\"\\uc6b0\\uc120 \\uacfc\\uc81c \\ub3c4\\ucd9c\\ud574\\uc57c\\\"\",\"\\uc774\\uc7ac\\uc6a9 \\uc0bc\\uc131\\uc804\\uc790 \\ubd80\\ud68c\\uc7a5, \\ubbf8\\uad6d\\uc5d0\\uc11c '\\ub274\\uc0bc\\uc131' \\ub3d9\\ub9f9 \\ud655\\uc778..\\ub9c8\\uc774\\ud06c\\ub85c\\uc18c\\ud504\\ud2b8\\u00b7\\uc544\\ub9c8\\uc874\\u00b7\\uad6c\\uae00 \\uacbd\\uc601\\uc9c4 \\uc787\\ub530\\ub77c \\ub9cc\\ub098\",\"\\uc774\\uc7ac\\uc6a9 \\uc0bc\\uc131\\uc804\\uc790 \\ubd80\\ud68c\\uc7a5, \\ubbf8\\uad6d\\uc5d0\\uc11c '\\ub274\\uc0bc\\uc131' \\ub3d9\\ub9f9 \\ud655\\uc778..\\ub9c8\\uc774\\ud06c\\ub85c\\uc18c\\ud504\\ud2b8\\u00b7\\uc544\\ub9c8\\uc874\\u00b7\\uad6c\\uae00 \\uacbd\\uc601\\uc9c4 \\uc787\\ub530\\ub77c \\ub9cc\\ub098\",\"'\\uad6c\\uae00\\u2027\\uc560\\ud50c \\uc800\\uc2b9\\uc0ac\\uc790' EU\\uacbd\\uc7c1\\uc704\\uc6d0\\uc7a5, \\ube45\\ud14c\\ud06c \\uaddc\\uc81c \\uc704\\ud55c \\uaddc\\uce59 \\uc2dc\\ud589 \\ucd09\\uad6c\",\"'\\uad6c\\uae00\\u2027\\uc560\\ud50c \\uc800\\uc2b9\\uc0ac\\uc790' EU\\uacbd\\uc7c1\\uc704\\uc6d0\\uc7a5, \\ube45\\ud14c\\ud06c \\uaddc\\uc81c \\uc704\\ud55c \\uaddc\\uce59 \\uc2dc\\ud589 \\ucd09\\uad6c\"],\"id\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63],\"topic\":[\"3\",\"3\",\"3\",\"3\",\"4\",\"0\",\"3\",\"4\",\"0\",\"3\",\"4\",\"0\",\"4\",\"4\",\"3\",\"4\",\"4\",\"3\",\"0\",\"0\",\"0\",\"0\",\"3\",\"4\",\"4\",\"3\",\"3\",\"2\",\"3\",\"4\",\"3\",\"3\",\"4\",\"4\",\"3\",\"3\",\"1\",\"1\",\"3\",\"4\",\"1\",\"3\",\"4\",\"1\",\"2\",\"4\",\"3\",\"1\",\"3\",\"1\",\"3\",\"2\",\"2\",\"2\",\"3\",\"3\",\"3\",\"3\",\"4\",\"4\",\"2\",\"2\",\"3\",\"3\"],\"x\":{\"__ndarray__\":\"UUTfQvR4IMNRyKnCwjTvQkkeQsPhb6zD6XBBw0keQsPhb6zD6XBBwwXJ+0GEqkfD6mQ+wlJo40G/IBZDFX+JQcrbJcKNS0BD3UTPwwmrG8NxhLzDcYS8w5Qzd0OsNApDX9wLwr9lZ8O/ZWfD9GJhQya9LEP8qKNCQ65XQ630wkGkAAvDpAALw95jXsLeY17CigIwQqyuk0MKNZ1CUkDJwih+w0J/Z2ZDDDgFQyh+w0I2apRDgvLWwglboEIld5RDy845QwVsQ0OalyDDPPCMQ0Tg1UNE4NVDx9TkQvPYA0NBqHBCyM4EQVRIo0IESaFB9OHUQ/Th1EM7ToTDO06Eww==\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[64]},\"y\":{\"__ndarray__\":\"0JeTQkGdF8OK0S3DfpkvQ+YfZ0OaZgdCaDOGw+YfZ0OaZgdCaDOGw9teMEM0s3pC//+QQm+60cIb+O9Cdy8twyU5E0Oc9HbCBC/qQajNBEKEpu7BhKbuwdCrjcFsItzCktm/wivJGMMryRjD7F0fw5Q8gELu1Q3DeIXbQu9Y18Hb+oVD2/qFQ16pW8FeqVvBvkusQzd8k0L/ePJCgW3SwoLOpENspDZCD0S3QYLOpEM1kSXDh6/1QllyKMC4/RRDIxuPP5a0MEO7KJrCf5zSwkjb/MFI2/zBzLBZw8IQDsLsDUdCAYPuQQ+XkcILj8ZCvwjBwr8IwcLZuYHD2bmBww==\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[64]}},\"selected\":{\"id\":\"1179\"},\"selection_policy\":{\"id\":\"1178\"}},\"id\":\"1163\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1177\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"1152\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1153\",\"type\":\"ResetTool\"},{\"attributes\":{\"overlay\":{\"id\":\"1155\"}},\"id\":\"1150\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1151\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1133\",\"type\":\"DataRange1d\"},{\"attributes\":{\"axis\":{\"id\":\"1141\"},\"coordinates\":null,\"group\":null,\"ticker\":null},\"id\":\"1144\",\"type\":\"Grid\"},{\"attributes\":{\"coordinates\":null,\"formatter\":{\"id\":\"1176\"},\"group\":null,\"major_label_policy\":{\"id\":\"1177\"},\"ticker\":{\"id\":\"1142\"}},\"id\":\"1141\",\"type\":\"LinearAxis\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"Topic\",\"@topic\"],[\"id\",\"@id\"],[\"Article\",\"@document\"]]},\"id\":\"1149\",\"type\":\"HoverTool\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.2},\"fill_color\":{\"field\":\"color\"},\"hatch_alpha\":{\"value\":0.2},\"hatch_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.2},\"line_color\":{\"field\":\"color\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1167\",\"type\":\"Circle\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"1163\"},\"glyph\":{\"id\":\"1165\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1167\"},\"nonselection_glyph\":{\"id\":\"1166\"},\"view\":{\"id\":\"1169\"}},\"id\":\"1168\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"bottom_units\":\"screen\",\"coordinates\":null,\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"group\":null,\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"1155\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"1146\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1154\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"coordinates\":null,\"group\":null,\"items\":[{\"id\":\"1182\"}],\"location\":\"top_left\"},\"id\":\"1181\",\"type\":\"Legend\"},{\"attributes\":{},\"id\":\"1137\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1135\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1173\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1139\",\"type\":\"LinearScale\"},{\"attributes\":{\"fill_color\":{\"field\":\"color\"},\"hatch_color\":{\"field\":\"color\"},\"line_color\":{\"field\":\"color\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1165\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"1178\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1174\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"1142\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1176\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1179\",\"type\":\"Selection\"},{\"attributes\":{\"tools\":[{\"id\":\"1149\"},{\"id\":\"1150\"},{\"id\":\"1151\"},{\"id\":\"1152\"},{\"id\":\"1153\"},{\"id\":\"1154\"}]},\"id\":\"1156\",\"type\":\"Toolbar\"},{\"attributes\":{\"axis\":{\"id\":\"1145\"},\"coordinates\":null,\"dimension\":1,\"group\":null,\"ticker\":null},\"id\":\"1148\",\"type\":\"Grid\"},{\"attributes\":{\"coordinates\":null,\"group\":null},\"id\":\"1170\",\"type\":\"Title\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"field\":\"color\"},\"hatch_alpha\":{\"value\":0.1},\"hatch_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"field\":\"color\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1166\",\"type\":\"Circle\"}],\"root_ids\":[\"1132\"]},\"title\":\"Bokeh Application\",\"version\":\"2.4.2\"}};\n",
       "  const render_items = [{\"docid\":\"b4682a68-fa0e-4e7d-8772-58b06cbc8579\",\"root_ids\":[\"1132\"],\"roots\":{\"1132\":\"5a684a58-54da-4364-ac07-102665a18197\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    let attempts = 0;\n",
       "    const timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1132"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.models import HoverTool\n",
    "from bokeh.palettes import Category20\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.plotting import figure, ColumnDataSource\n",
    "output_notebook()\n",
    "\n",
    "# 사용할 툴들\n",
    "tools_to_show = 'hover, box_zoom, pan, save, reset, wheel_zoom'\n",
    "p = figure(plot_width=720, plot_height=580, tools=tools_to_show)\n",
    "\n",
    "source = ColumnDataSource(data={\n",
    "    'x': W2d[:, 0],\n",
    "    'y': W2d[:, 1],\n",
    "    'id': [i for i in range(W.shape[0])],\n",
    "    'document': [article for words, article in words_list],\n",
    "    'topic': [str(i) for i in topicIndex],  # 토픽 번호\n",
    "    'color': [Category20[K][i] for i in topicIndex]\n",
    "})\n",
    "p.circle(\n",
    "    'x', 'y',\n",
    "    source=source,\n",
    "    legend='topic',\n",
    "    color='color'\n",
    ")\n",
    "\n",
    "# interaction\n",
    "p.legend.location = \"top_left\"\n",
    "hover = p.select({'type': HoverTool})\n",
    "hover.tooltips = [(\"Topic\", \"@topic\"), ('id', '@id'), (\"Article\", \"@document\")]\n",
    "hover.mode = 'mouse'\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Word Embedding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Embedding은 단어가 가지는 고유한 벡터를 가지고 의미가 유사하면 유사도가 높도록(내적값이 커지도록) 의미가 작아지면 유사도가 작아지도록(내적값이 작아지도록) 해주는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.1 Word2Vec**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec에는 CBOW와 Skip-Grad 두 가지 방식이 있습니다. CBOW는 주변에 있는 단어들을 가지고, 중간에 있는 단어들을 예측하는 방법입니다. 반대로, Skip-Gram은 중간에 있는 단어로 주변 단어들을 예측하는 방법입니다. 매커니즘 자체는 거의 비슷합니다. 우선 CBOW에 대해서 알아보겠습니다. 이해를 위해 매우 간소화된 형태의 CBOW로 설명합니다.\n",
    "\n",
    "**예문: \"The fat cat sat on the mat\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) CBOW**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들어 코퍼스에 위와 같은 문장이 있습니다. {\"The\", \"fat\", \"cat\", \"on\", \"the\", \"mat\"}으로부터 \"sat\"을 예측하는 것이 CBOW가 할 일입니다. 이 때 예측하는 단어 sat을 중심 단어(center word)라고 하고, 예측에 사용되는 단어들을 주변 단어(context word)라고 합니다.\n",
    "\n",
    "중심 단어를 예측하기 위해 앞, 뒤로 몇 개의 단어를 볼지 결정했다면 이 범위를 윈도우(window)라고 합니다. 예를 들어 윈도우 크기가 2이고 예측하고자 하는 중심 단어가 sat이라고 한다면 앞의 두 단어인 fat과 cat, 그리고 뒤의 두 단어인 on, the를 참고합니다. 윈도우의 크기가 n이라고 한다면, 실제 중심 단어를 예측하기 위해 참고하려고 하는 주변 단어의 개수는 2n이 됩니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/22660/%EB%8B%A8%EC%96%B4.PNG\">\n",
    "\n",
    "윈도우 크기를 정했다면, 윈도우를 계속 움직여서 주변 단어와 중심 단어 선택을 바꿔가며 학습을 위한 데이터 셋을 만들 수 있는데, 이 방법을 슬라이딩 윈도우(sliding window)라고 합니다. \n",
    "\n",
    "위 그림에서 좌측의 중심 단어와 주변 단어의 변화는 윈도우 크기가 2일 때, 슬라이딩 윈도우가 어떤 식으로 이루어지면서 데이터 셋을 만드는지 보여줍니다. 또한 Word2Vec에서 입력은 원-핫 벡터가 되어야 하는데, 우측 그림은 중심 단어와 주변 단어를 어떻게 선택했을 때에 따라서 각각 어떤 원-핫 벡터가 되는지를 보여줍니다. 밑의 그림은 결국 CBOW를 위한 전체 데이터 셋을 보여주는 것입니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/22660/word2vec_renew_1.PNG\">\n",
    "\n",
    "CBOW의 인공 신경망을 간단히 도식화하면 위와 같습니다. 입력층(Input layer)의 입력으로서 앞, 뒤로 사용자가 정한 윈도우 크기 범위 안에 있는 주변 단어들의 원-핫 벡터가 들어가게 되고, 출력층(Output layer)에서 예측하고자 하는 중간 단어의 원-핫 벡터가 필요합니다. \n",
    "\n",
    "또한 위 그림에서 알 수 있는 사실은, Word2Vec은 딥 러닝 모델(Deep Learning Model)은 아니라는 점입니다. 보통 딥 러닝이라함은, 입력층과 출력층 사이의 은닉층의 개수가 충분히 쌓인 신경망을 학습할 때를 말하는데 Word2Vec는 입력층과 출력층 사이에 하나의 은닉층만이 존재합니다. 이렇게 은닉층이 1개인 경우에는 일반적으로 심층신경망(Deep Neural Network)이 아니라 얕은신경망(Shallow Neural Network)이라고 부릅니다. 또한 Word2Vec의 은닉층은 일반적인 은닉층과 달리 활성화 함수가 존재하지 않으며 룩업 테이블이라는 연산을 담당하는 층으로 일반적인 은닉층과 구분하기 위해 투사층(projection layer)이라고 부르기도 합니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/22660/word2vec_renew_2.PNG\">\n",
    "\n",
    "CBOW의 인공신경망을 더 확대하여 알아보겠습니다. 이 그림에서 투사층의 크기가 M이라는 것과 입력층과 투사층 사이의 가중치 W는 V x M이고 투사층과 출력층 사이 가중치 W'의 크기는 M x V임을 주목해야 합니다.\n",
    "\n",
    "먼저 CBOW에서 투사층의 크기 M은 임베딩하고 난 벡터의 차원이 됩니다. 다시 말해, 위 그림에서 투사층의 크기는 M = 5이기 때문에 CBOW를 수행하고 나서 얻는 각 단어의 임베딩 벡터의 차원은 5입니다.\n",
    "\n",
    "두번째로 V는 단어 집합의 크기를 의미합니다. 즉, 위의 그림처럼 원-핫 벡터의 차원이 7이고, M은 5라면 가중치 W는 7 x 5 행렬이고, W'는 5 x 7 행렬이 될 것입니다. 이때 W와 W'는 동일한 행렬을 전치한 것이 아니라 서로 다른 행렬입니다. 인공 신경망의 훈련 전에 이 가중치 행렬 W와 W'는 대게 굉장히 작은 랜덤 값을 가지게 됩니다. CBOW는 주변 단어로 중심 단어를 더 정확히 맞추기 위해서 W와 W'를 학습해가는 구조입니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/22660/word2vec_renew_3.PNG\">\n",
    "\n",
    "입력으로 들어오는 주변 단어의 원-핫 벡터와 가중치 W 행렬의 곱이 어떻게 이루어지는지 보겠습니다. 위 그림에서 각 주변 단어의 원-핫 벡터를 $x$로 표기했습니다. 입력 데이터는 원-핫 벡터입니다. 입력 벡터와 가중치 W 행렬의 곱은 사실 W행렬의 i번째 행을 그대로 읽어오는 것(lookup)과 같기에 이 작업을 룩업 테이블(lookup table)이라고 합니다. 여기서 lookup해온 W의 각 행벡터가 사실 Word2Vec을 수행한 후의 각 단어의 M차원 크기를 갖는 임베딩 벡터들입니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/22660/word2vec_renew_4.PNG\">\n",
    "\n",
    "이렇게 각 주변 단어의 원-핫 벡터에 대해서 가중치 W가 곱해서 생겨진 결과 벡터들은 투사층에서 만나 이들의 평균인 벡터를 구합니다. CBOW는 투사층에서 벡터의 평균을 구하지만 뒤에서 볼 Skip-Gram은 입력이 중심 단어 하나이기에 투사층에서 벡터의 평균을 구하지 않습니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/22660/word2vec_renew_5.PNG\">\n",
    "\n",
    "이제 투사층에서 구해진 평균 벡터는 두번째 가중치 행렬 W'와 곱해집니다. 곱셈의 결과는 원-핫 벡터들과 동일한 차원을 가진 벡터로 나옵니다. \n",
    "\n",
    "이 벡터에서 CBOW는 소프트맥스 함수를 사용합니다. 출력된 벡터의 총 합은 1이고 이렇게 나온 벡터를 스코어 벡터(score vector)라고 합니다. 스코어 벡터는 각 인덱스번째 단어가 중심 단어일 확률을 나타냅니다. 그리고 스코어 벡터가 우리가 가진 답의 원-핫 벡터와 가까워져야 합니다. \n",
    "\n",
    "스코어 벡터를 $\\hat{y}$, 중심 단어를 $y$라고 했을 때, CBOW의 손실 함수로 cross-entropy 함수를 사용합니다.\n",
    "\n",
    "$$H(\\hat{y}, y) = -\\sum_{j=1}^{\\lvert V \\rvert} y_j log(\\hat{y}_j)$$\n",
    "\n",
    "cross-entropy 함수에 실제 중심 단어인 원-핫 벡터와 스코어 벡터를 입력값으로 넣고, 이를 식으로 표현하면 위와 같습니다. \n",
    "\n",
    "$$H(\\hat{y}, y) = -y_i log(\\hat{y_i})$$\n",
    "\n",
    "그런데 y가 원-핫 벡터임을 고려하면, 식을 위와 같이 간소화할 수 있습니다. c를 중심 단어에서 1을 가진 차원의 값의 인덱스라고 한다면 $\\hat{y}_c = 1$는 $\\hat{y}$가 $y$를 정확하게 예측한 경우가 됩니다. 이를 식에 대입하면 $-1log(1) = 0$이기에 결과적으로 정확히 예측한 경우의 cross-entropy 값은 0이 됩니다. 따라서 위 식을 최소화하는 방향으로 학습해야 하며 loss function으로 사용해도 됩니다.\n",
    "\n",
    "이제 역전파를 수행하면 W와 W'가 학습되는데, 학습이 다 되었다면 M차원의 크기를 갖는 W의 행이나 W'의 열로부터 어떤 것을 임베딩 벡터로 사용할지 결정하면 됩니다. 떄로는 W와 W'의 평균치를 가지고 임베딩 벡터를 선택하기도 합니다.\n",
    "\n",
    "Word2Vec의 알고리즘을 다시 요약해보면 다음과 같습니다.\n",
    "\n",
    "![4-3-1](_image/4-3-1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) Skip-Gram**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip-gram은 CBOW를 이해했다면, 매커니즘 자체는 동일하기 때문에 쉽게 이해할 수 있습니다. 앞서 CBOW에선 주변 단어를 통해 중심 단어를 예측했다면, skip-gram은 중심 단어에서 주변 단어를 예측하겠습니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/22660/word2vec_renew_6.PNG\">\n",
    "\n",
    "앞서 언급한 동일한 예문에 대해서 인공 신경망을 도식화해보면 위와 같습니다. 이제 중심 단어에 대해서 주변 단어를 예측하기 때문에, 투사층에서 벡터들의 평균을 구하는 과정은 없습니다. \n",
    "\n",
    "여러 논문에서 성능 비교를 진행했을 때, 전반적으로 skip-gram이 CBOW보다 성능이 좋다고 알려져 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) Negative Sampling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대체적으로 Word2Vec를 사용한다고 하면 SGNS(Skip-Gram with Negative Sampling)을 사용합니다. 이는 skip-gram 방법에, 네거티브 샘플링이란 방법까지 추가로 사용하는 것입니다. 그렇기에 skip-gram을 전제로 네거티브 샘플링에 대해서 알아보겠습니다.\n",
    "\n",
    "위에서 배운 Word2Vec 모델은 속도가 문제입니다. 마지막 단계를 봅시다. 출력층에 있는 소프트맥스 함수는 단어 집합 크기의 벡터 내의 모든 값을 0과 1 사이의 값이면서 모두 더하면 1이 되도록 바꾸는 작업을 수행합니다. 그리고 이에 대한 오차를 구하고 모든 단어에 대한 임베딩을 조정합니다. 그 단어가 중심 단어나 주변 단어와 전혀 상관없는 단어라도 마찬가지입니다. 그런데 만약 단어 집합의 크기가 수백만에 달한다면 이 작업은 굉장히 무거워집니다.\n",
    "\n",
    "여기서 핵심은 모든 단어 집합에 대해서 소프트맥스 함수를 수행하고, 역전파를 수행하므로 주변 단어와 상관 없는 모든 단어까지 워드 임베딩 조정 작업을 수행한다는 것입니다. 만약 '강아지'와 '고양이'와 같은 단어에 집중한다면 '돈가스'나 '컴퓨터'와 같은 연관 관계가 없는 수많은 단어의 임베딩을 조정할 필요가 없습니다. \n",
    "\n",
    "그렇다면 전체 단어 집합이 아니라 일부 단어 집합에 대해서만 고려할 수는 없을까요? '강아지', '고양이' 같은 주변 단어들로 일부 단어 집합을 만듭니다. 그리고 여기에 '돈가스', '컴퓨터', '회의실' 같은 무작위로 선택된 주변 단어가 아닌 상관없는 단어들을 일부만 갖고옵니다. 이렇게 전체 단어 집합보다 훨씬 작은 단어 집합을 만들어놓고 마지막 단께를 이진 분류 문제로 바꿔버립니다. 즉, Word2Vec은 주변 단어들을 긍정(positive)으로 두고 무작위로 샘플링 된 단어들을 부정(negative)으로 둔 다음에 이진 분류 문제를 수행합니다. \n",
    "\n",
    "이는 기존의 다중 클래스 분류 문제를 이진 분류 문제로 바꾸면서도 연산량에 있어서 훨씬 효율적입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4) Word2Vec Property**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![4-3-2](_image/4-3-2.PNG)\n",
    "링크: https://ronxin.github.io/wevi/\n",
    "\n",
    "위 그림은 Word2Vec이 동작하는 것을 보여주는 페이지에 결과입니다. apple과 juice는 관계가 있기에 apple input vector와 juice output vector의 값이 모두 양수가 되는 것을 확인할 수 있습니다. 반대로 rice input vector와 juice output vector는 음수가 많이 나오는 것을 확인할 수 있습니다. \n",
    "\n",
    "또한 이렇게 구해진 embedding vector들은 유사한 관계를 가진 벡터쌍끼리 비슷한 관계를 가집니다. 예를 들어 (대한민국, 서울)과 (일본, 도쿄)는 (나라, 수도)의 관계를 가지고 있습니다. 그렇기에 대한민국 - 서울 = 일본 - 도쿄의 식이 성립됩니다. 그 외에도 여러 유사 관계를 밑의 그림에서 확인할 수 있습니다.\n",
    "\n",
    "![4-3-3](_image/4-3-3.PNG)\n",
    "\n",
    "이외에도 거의 대부분의 NLP분야에서 사용됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고 자료: https://shuuki4.wordpress.com/2016/01/27/word2vec-%EA%B4%80%EB%A0%A8-%EC%9D%B4%EB%A1%A0-%EC%A0%95%EB%A6%AC/  \n",
    "참고 자료: https://simonezz.tistory.com/35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.2 GloVe**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSA(Latent Semantic Analysis)는 각 단어의 빈도수를 카운트 한 행렬이라는 전체적인 통계 정보를 입력 받아 차원을 축소(Truncated SVD)하여 잠재된 의미를 끌어내는 방법론입니다. 반면, Word2Vec는 실제값과 예측값에 대한 오차를 손실 함수를 통해 줄여나가며 학습하는 예측 기반의 방법론입니다. \n",
    "\n",
    "LSA는 카운트 기반이기에 전체적인 통계 정보를 고려하기는 하지만, '왕:남자 = 여왕:?'과 같은 단어 의미의 유추 작업(Analogy task)에는 성능이 떨어집니다. Word2Vec는 예측 기반으로 단어 간 유추 작업에는 LSA보다 뛰어나지만, 임베딩 벡터가 윈도우 크기 내에서만 주변 단어를 고려하기 때문에 코퍼스의 전체적인 통계 정보를 반영하지 못합니다. GloVe는 이러한 기존 방법론들의 각각의 한계를 지적하며 LSA의 매커니즘이었던 카운트 기반의 방법과 Word2Vec의 매커니즘이었던 예측 기반의 방법론을 두 가지 모두 사용합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 GloVe에 대해 간단하게 살펴보겠습니다. GloVe는 위에서 이야기했듯 Word2Vec에 카운터 기반의 방법을 합친 것입니다. 그렇기에 단어들의 쌍들이 나오는 개수를 먼저 count하여 행렬로 만듭니다. 그리고 $W_1 \\cdot W_2$가 구한 행렬과 같아지도록 학습시키는 것입니다. 이때 the 등의 관사는 빈도수가 너무 높기에 이를 억제하기 위해 log항을 추가합니다. 또한 빈도수에 따라 가중치를 주지만 이 역시 너무 커지지 않도록 f라는 함수를 사용합니다. 임베딩 벡터로는 Word2Vec과 마찬가지로 $W_1$을 사용하거나 두 개의 평균을 임베딩 벡터로 사용합니다. \n",
    "\n",
    "밑의 그림은 loss function(bias = 0)과 f함수를 보여줍니다.\n",
    "\n",
    "![4-3-4](_image/4-3-4.PNG)\n",
    "\n",
    "이제 구체적으로 GloVe의 동작을 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) Windoe based Co-occurrence Matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 단어 쌍의 빈도수의 정보를 가지는 윈도우 기반 동시 등장 행렬에 대해 보겠습니다.\n",
    "\n",
    "단어의 동시 등장 행렬은 행과 열을 전체 단어 집합의 단어들을 구성하고, i 단어의 윈도우 크기(Window Size) 내에서 k 단어가 등장한 횟수를 i행 k열에 기재한 행렬을 말합니다. 예제를 보겠습니다.\n",
    "\n",
    "Ex)  \n",
    "I like deep learning  \n",
    "I like NLP  \n",
    "I enjoy flying  \n",
    "\n",
    "윈도우 크기가 N일 때는 좌, 우에 존재하는 N개의 단어만 참고하게 됩니다. 윈도우 크기가 1일 때, 위 텍스트를 가지고 동시 등장 행렬은 다음과 같습니다.\n",
    "\n",
    "|카운트|I|like|enjoy|deep|learning|NLP|flying|\n",
    "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "|I|0|2|1|0|0|0|0|\n",
    "|like|2|0|0|1|0|1|0|\n",
    "|enjoy|1|0|0|0|0|0|1|\n",
    "|deep|0|1|0|0|1|0|0|\n",
    "|learning|0|0|0|1|0|0|0|\n",
    "|NLP|0|1|0|0|0|0|0|\n",
    "|flying|0|0|1|0|0|0|0|\n",
    "\n",
    "위 행렬은 행렬을 전치(Transpose)해도 동일한 행렬이 된다는 특징이 있습니다. 그 이유는 i 단어의 윈도우 크기 내에서 k 단어가 등장한 빈도는 반대로 k 단어의 윈도우 크기 내에서 i 단어가 등장한 빈도와 동일하기 때문입니다. \n",
    "\n",
    "참고 자료: http://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture02-wordvecs2.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) Co-occurrence Probability**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 동시 등장 확률에 대해서 알아보겠습니다. 아래의 표는 어떤 동시 등장 행렬을 가지고 정리한 동시 등장 확률(Co-occurrence Probability)을 보여줍니다. 여기서 이야기하는 동시 등장 확률 $P(k|i)$는 동시 등장 행렬로부터 특정 단어 i의 전체 등장 횟수를 카운트하고, 특정 단어 i가 등장했을 때 어떤 단어 k가 등장한 횟수를 카운트하여 계산한 조건부 확률입니다. \n",
    "\n",
    "$P(k|i)$에서 i를 중심 단어(Center word), k를 주변 단어(Context word)라고 했을 때, 위에서 배운 동시 등장 행렬에서 중심 단어 i의 행의 모든 값을 더한 값을 분모로 하고 i행 k열의 값을 분자로 한 값이라고 볼 수 있겠습니다. 다음은 GloVe의 제안 논문에서 가져온 동시 등장 확률을 표로 정리한 하나의 예입니다.\n",
    "\n",
    "|동시 등장 확률과 크기 관계 비(ratio)|k=solid|k=gas|k=water|k=fasion|\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "|$P(k \\vert ice)$|0.00019|0.000066|0.003|0.000017|\n",
    "|$P(k \\vert steam)$|0.000022|0.00078|0.0022|0.000018|\n",
    "|$\\frac{P(k \\vert ice)}{P(k \\vert steam)}$|8.9|0.085|1.36|0.96|\n",
    "\n",
    "위의 표를 통해 알 수 있는 사실은 solid가 등장했을 때, ice가 등장할 확률은 0.00019은 solid가 등장했을 때 steam이 등장할 확률인 0.000022보다 약 8.9배 크다는 사실입니다. 그도 그럴 것이 solid는 '단단한'이라는 의미를 가졌으니까 '증기'라는 의미를 가지는 steam보다는 당연히 '얼음'이라는 의미를 가지는 ice라는 단어와 더 자주 등장할 겁니다.\n",
    "\n",
    "수식적으로 다시 정리하면 k가 solid일 때, $\\frac{P(solid \\vert ice)}{P(solid \\vert steam)}$를 계산한 값은 8.9가 나옵니다. 이는 1보다 매우 큰 값입니다. 왜냐면 $P(solid \\vert ice)$의 값은 크고, $P(solid \\vert steam)$의 값은 작기 때문입니다.\n",
    "\n",
    "그런데 k를 solid가 아니라 gas로 바꾸면 이야기는 완전히 달라집니다. gas는 ice보다는 steam과 더 자주 등장하므로, $\\frac{P(gas \\vert ice)}{P(gas \\vert steam)}$를 계산한 값은 1보다 훨씬 작은 값인 0.085가 나옵니다. 반면, k가 water인 경우에는 solid와 steam 두 단어 모두와 동시 등장하는 경우가 많으므로 1에 가까운 값이 나오고, k가 fasion인 경우에는 solid와 steam 두 단어 모두와 동시 등장하는 경우가 적으므로 1에 가까운 값이 나옵니다. 보기 쉽도록 조금 단순화해서 표현한 표는 다음과 같습니다.\n",
    "\n",
    "|동시 등장 확률과 크기 관계 비(ratio)|k=solid|k=gas|k=water|k=fasion|\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "|$P(k \\vert ice)$|큰 값|작은 값|큰 값|작은 값|\n",
    "|$P(k \\vert steam)$|작은 값|큰 값|큰 값|작은 값|\n",
    "|$\\frac{P(k \\vert ice)}{P(k \\vert steam)}$|큰 값|작은 값|1에 가까움|1에 가까움|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4) Loss Function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선 손실 함수를 설명하기 전에 각 용어를 정리하겠습니다.\n",
    "\n",
    "- $X$: 동시 등장 행렬(Co-occurrence Matrix)\n",
    "- $X_{ij}$: 중심 단어 i가 등장했을 때, 윈도우 내 주변 단어 j가 등장하는 횟수\n",
    "- $X_i$: $\\sum_j X_{ij}$: 동시 등장 행렬에서 i행의 값을 모두 더한 값\n",
    "- $P_{ik}$: $P(k \\vert i) = \\frac{X_{ik}}{X_i}$: 중심 단어 i가 등장했을 때, 윈도우 내 주변 단어 k가 등장할 확률  \n",
    "    Ex) $P(solid \\vert ice)$ = 단어 ice가 등장했을 때, 단어 solid가 등장할 확률\n",
    "- $\\frac{P_{ik}}{P_{jk}}$: $P_{ik}$를 $P_{jk}$로 나눠준 값  \n",
    "    Ex) $\\frac{P(solid \\vert ice)}{P(solid \\vert steam)}$ = 8.9\n",
    "- $w_i$: 중심 단어 i의 임베딩 벡터\n",
    "- $\\bar{w_k}$: 주변 단어 k의 임베딩 벡터\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GloVe의 아이디어를 한 줄로 요약하면 **'임베딩 된 중심 단어와 주변 단어 벡터의 내적이 전체 코퍼스에서의 동시 등장 확률이 되도록 만드는 것'** 입니다. 즉, 이를 만족하도록 임베딩 벡터를 만드는 것이 목표입니다. 이를 식으로 표현하면 다음과 같습니다.\n",
    "\n",
    "$dot product(w_i, \\bar{w_k}) \\approx P(k \\vert i) = P_{ik}$\n",
    "\n",
    "뒤에서 보겠지만, 더 정확히는 GloVe는 아래와 같은 관계를 가지도록 임베딩 벡터를 설계합니다.\n",
    "\n",
    "$dot product(w_i, \\bar{w_k}) \\approx log P(k \\vert i) = log P_{ik}$\n",
    "\n",
    "임베딩 벡터들을 만들기 위한 손실 함수를 처음부터 차근차근 설계해보겠습니다. 가장 중요한 것은 단어 간의 관계를 잘 표현하는 함수여야 한다는 것입니다. 이를 위해 앞서 배운 개념인 $P_{ik}/P_{jk}$를 식에 사용합니다. GloVe의 연구진들은 벡터 $w_i, w_j, \\bar{w_k}$를 가지고 어떤 함수 $F$를 수행하면 $P_{ik}/P_{jk}$가 나온다는 초기 식으로부터 전개를 시작합니다.\n",
    "\n",
    "$$F(w_i, w_j, \\bar{w_k}) = \\frac{P_{ik}}{P_{jk}}$$\n",
    "\n",
    "아직 이 함수가 $F$가 어떤 식을 가지고 있는지는 정해진 것이 없습니다. 위의 목적에 맞게 근사할 수 있는 함수식은 무수히 많겠으나 최적의 식에 다가가기 위해서 단계별로 디테일을 추가하겠습니다. 함수 $F$는 두 단어 사이의 동시 등장 확률의 크기 관계 비(ratio) 정보를 벡터 공간에 인코딩하는 것이 목적입니다. 이를 위해 GloVe 연구진들은 $w_i$와 $w_j$라는 두 벡터의 차이를 함수 $F$의 입력으로 사용하는 것을 제안합니다.\n",
    "\n",
    "$$F(w_i - w_j, \\bar{w_k}) = \\frac{P_{ik}}{P_{jk}}$$\n",
    "\n",
    "그런데 우변은 스칼라값이고 좌변은 벡터값입니다. 이를 성립하기 위해서 함수 $F$의 두 입력에 내적(dot product)을 수행합니다.\n",
    "\n",
    "$$F((w_i - w_j)^T \\bar{w_k}) = \\frac{P_{ik}}{P_{jk}}$$\n",
    "\n",
    "정리하면, 선형 공간(Linear space)에서 단어의 의미 관계를 표현하기 위해 뺄셈과 내적을 택했습니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 함수 $F$가 만족해야 할 필수 조건이 있습니다. 중심 단어 $w$와 주변 단어 $\\bar{w}$라는 선택 기준은 실제로는 무작위 선택이므로 이 둘의 관계는 자유롭게 교환될 수 있도록 해야합니다. 이것이 성립되게 하기 위해서 GloVe 연구진은 함수 $F$가 실수의 덧셈과 양수의 곱셈에 대해서 **준동형(Homomorphism)** 을 만족하도록 합니다. 이를 쉽게 정리하면 $a$와 $b$에 대해서 함수 $F$가 $F(a + b)$가 $F(a)F(b)$와 같도록 만족시켜야 한다는 의미입니다.\n",
    "\n",
    "식으로 나타내면 다음과 같습니다.\n",
    "\n",
    "$$F(a + b) = F(a)F(b), \\forall a, b \\in \\mathbb{R}$$\n",
    "\n",
    "이제 이 준동형식을 현재 전개하던 GloVe 식에 적용할 수 있도록 조금씩 바꿔보겠습니다. 전개하던 GloVe 식에 따르면, 함수 $F$는 결과값으로 스칼라 값($\\frac{P_{ik}}{P_{jk}}$)이 나와야 합니다. 준동형식에서 $a$와 $b$가 각각 벡터값이라면 함수 $F$의 결과값으로는 스칼라 값이 나올 수 없지만, $a$와 $b$가 각각 사실 두 벡터의 내적값이라고 하면 결과값으로 스칼라 값이 나올 수 있습니다. 그러므로 위의 준동형식을 아래와 같이 바꿔보겠습니다. 여기서 $v_1, v_2, v_3, v_4$는 각각 벡터값입니다. 아래의 $V$는 벡터를 의미합니다.\n",
    "\n",
    "$$F(v_1^T v_2 + v_3^T v_4) = F(v_1^T v_2)F(v_3^T v_4), \\forall v_1, v_2, v_3, v_4 \\in V$$\n",
    "\n",
    "그런데 앞서 작성한 GloVe 식에서는 $w_i$와 $w_j$라는 두 벡터의 차이를 함수 $F$의 입력으로 받았습니다. GloVe식에 바로 적용을 위해 준동형식을 뺄셈에 대한 준동형식으로 변경합니다. 그러면 곱셈도 나눗셈으로 바뀌게 됩니다.\n",
    "\n",
    "$$F(v_1^T v_2 - v_3^T v_4) = \\frac{F(v_1^T v_2)}{F(v_3^T v_4)}, \\forall v_1, v_2, v_3, v_4 \\in V$$\n",
    "\n",
    "이제 이 준동형식을 GloVe 식에 적용하겠습니다. 우선, 함수 $F$의 우변은 다음과 같이 바뀌어야 합니다.\n",
    "\n",
    "$$F((w_i - w_j)^T \\bar{w_k}) = \\frac{F(w_i^T \\bar{w_k})}{F(w_j^T \\bar{w_k})}$$\n",
    "\n",
    "그런데 이전의 식에 따르면 우변은 본래 $\\frac{P_{ik}}{P_{jk}}$였으므로, 결과적으로 다음과 같습니다.\n",
    "\n",
    "$$\\frac{P_{ik}}{P_{jk}} = \\frac{F(w_i^T \\bar{w_k})}{F(w_j^T \\bar{w_k})}$$\n",
    "\n",
    "$$F(w_i^T \\bar{w_k}) = P_{ik} = \\frac{X_{ik}}{X_i}$$\n",
    "\n",
    "좌변을 풀어쓰면 다음과 같습니다.\n",
    "\n",
    "$$F(w_i^T \\bar{w_k} - w_j^T \\bar{w_k}) = \\frac{F(w_i^T \\bar{w_k})}{F(w_j^T \\bar{w_k})}$$\n",
    "\n",
    "이는 뺄셈에 대한 준동형식의 형태와 정확히 일치합니다. 이제 이를 만족하는 함수 $F$를 찾아야 합니다. 그리고 이를 정확하게 만족시키는 함수가 있는데 바로 지수 함수입니다. $F$를 지수 함수 **exp** 라고 해봅시다.\n",
    "\n",
    "$$exp(w_i^T \\bar{w_k} - w_j^T \\bar{w_k}) = \\frac{exp(w_i^T \\bar{w_k})}{exp(w_j^T \\bar{w_k})}$$\n",
    "\n",
    "$$exo(w_i^T \\bar{w_k}) = P_{ik} = \\frac{X_{ik}}{X_i}$$\n",
    "\n",
    "위의 두 번째 식으로부터 다음과 같은 식을 얻을 수 있습니다.\n",
    "\n",
    "$$w_i^T \\bar{w_k} = log P_{ik} = log(\\frac{X_{ik}}{X_i}) = log X_{ik} - log X_i$$\n",
    "\n",
    "그런데 여기서 상기해야할 것은 앞서 언급했듯이, 사실 $w_i$와 $\\bar{w_k}$는 두 값의 위치를 서로 바꾸어도 식이 성립해야 합니다. $X_{ik}$의 정의를 생각해보면 $X_{ki}$와도 같습니다. 그런데 이게 성립되려면 위의 식에서 $log X_i$ 항이 걸림돌입니다. 이 부분만 없다면 이를 성립시킬 수 있습니다. 그래서 GloVe 연구팀은 이 $log X_i$항을 $w_i$에 대한 편향 $b_i$라는 상수항으로 대체하기로 합니다. 같은 이유로 $\\bar{w_k}$에 대한 편향 $\\bar{b_k}$를 추가합니다.\n",
    "\n",
    "$$w_i^T \\bar{w_k} + b_i + \\bar{b_k} = log X_{ik}$$\n",
    "\n",
    "이 식이 손실 함수의 핵심이 되는 식입니다. 우변의 값과 차이를 최소화하는 방향으로 좌변의 4개의 항이 학습을 통해 바뀌게 됩니다. 즉, 손실 함수는 다음과 같이 일반화될 수 있습니다.\n",
    "\n",
    "$$Loss \\; function = \\sum_{m, n = 1}^V (w_m^T \\bar{w_n} + b_m + \\bar{b_n} - log X_{mn})^2$$\n",
    "\n",
    "여기서 $V$는 단어 집합의 크기를 의미합니다. 그런데 아직 최적의 손실 함수라기에는 부족합니다. GloVe 연구진은 $log X_{ik}$에서 $X_{ik}$값이 0이 될 수 있음을 지적합니다. 대안 중 하나는 $log X_{ik}$항을 $log (1 + X_{ik})$로 변경하는 것입니다. 하지만 이렇게 해도 여전히 해결되지 않는 문제가 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "바로 동시 등장 행렬 $X$는 마치 DTM처럼 희소 행렬일 가능성이 다분하다는 점입니다. 동시 등장 행렬 $X$에는 많은 값이 0이거나, 동시 등장 빈도가 적어서 많은 값이 작은 수치를 가지는 경우가 많습니다. 앞서 빈도수를 가지고 가중치를 주는 고민을 하는 TF-ID나 LSA와 같은 몇 가지 방법들을 본 적이 있습니다. GloVe의 연구진은 동시 등장 행렬에서 동시 등장 빈도의 값 $X_{ik}$이 굉장히 낮은 경우에는 정보에 거의 도움이 되지 않는다고 판단합니다. 그래서 이에 대한 가중치를 주는 고민을 하게 되는데 GloVe 연구팀이 선택한 것은 바로 $X_{ik}$의 값에 영향을 받는 가중치 함수 $f(X_{ik})$를 손실 함수에 도입하는 것입니다. \n",
    "\n",
    "GloVe에 도입되는 $f(X_{ik})$의 그래프를 그려보겠습니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/22885/%EA%B0%80%EC%A4%91%EC%B9%98.PNG\">\n",
    "\n",
    "$X_{ik}$의 값이 작으면 상대적으로 함수의 값은 작도록 하고, 값이 크면 함수의 값은 상대적으로 크도록 합니다. 하지만 $X_{ik}$가 지나치게 높다고해서 지나친 가중치를 주지 않기 위해 함수의 최대값은 정해져 있습니다. (최대값은 1) 예를 들어 'It is'와 같은 불용어의 동시 등장 빈도수가 높다고해서 지나친 가중을 받아서는 안 됩니다. 이 함수의 값을 손실 함수에 곱해주면 가중치의 역할을 할 수 있습니다.\n",
    "\n",
    "이 함수 $f(x)$의 식은 다음과 같이 정의됩니다. \n",
    "\n",
    "$$f(x) = min(1, (\\frac{x}{x_{max}}^{\\frac{3}{4}}))$$\n",
    "\n",
    "최종적으로 다음과 같은 일반화 된 손실 함수를 얻어낼 수 있습니다.\n",
    "\n",
    "$$Loss \\; function = \\sum_{m, n = 1}^V f(X_{mn})(w_m^T \\bar{w_n} + b_m + \\bar{b_n} - log X_{mn})^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5) Pre-trained dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GloVe](https://nlp.stanford.edu/projects/glove/)에선 이미 학습된 임베딩 벡터를 제공합니다. 자료마다 뒤에 설명이 적혀있으니 참고하여 필요한 데이터를 사용하면 됩니다. 예를 들어 Wikipedia 2014 + Gigaword5에 대한 설명은 다음과 같습니다. \n",
    "\n",
    "- 6B tokens: 60억개의 토큰(중복 단어 허용)\n",
    "- 400k vocab: 40만개의 고유 단어(40만개의 one-hot vector)\n",
    "- uncased: 대소문자 구분 안 함\n",
    "- 50d, 100d, 200d, & 300d vectors: 50, 100, 200, 300을 target dimension으로 학습된 임베딩 벡터가 있음을 표시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.3 Doc2Vec**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc2Vec(Paragraph2Vec)는 기존 Word2Vec에 paragraph vector를 더해 확장한 문서 임베딩 모델입니다. 타켓 단어와 이전 단어 k개가 주어졌을 때, 이전 단어들과 해당 문서의 아이디로 타켓 단어를 예측합니다. 그리고 이 과정에서 문맥이 비슷한 문서 벡터와 단어 벡터가 유사하게 임베딩됩니다.\n",
    "\n",
    "Doc2Vec은 다량의 코퍼스를 문서 임베딩 할 때 훌룡한 성능을 보여줍니다. Word2Vec이 CBOW와 Skip-Gram우로 나뉘었듯 Doc2Vec도 PV-DM(Distributed Memory version of Paragraph Vector)과 PV-DBOW(Distributed Bag of Words version of Paragraph Vector)로 나눠집니다. 아래와 같은 예시가 있을 때 동작하는 것을 살펴보겠습니다.\n",
    "\n",
    "- sentence: the cat sat on the mat\n",
    "- window size: k = 3\n",
    "- [$\\text{paragraph}_1$, the, cat, sat] - on\n",
    "- [$\\text{paragraph}_1$, cat, sat, on] - the\n",
    "- [$\\text{paragraph}_1$, sat, on, the] - mat\n",
    "\n",
    "Doc2Vec은 paragraph에서 단어를 예측하며 로그 확률 평균을 최대화하는 과정에서 학습됩니다. $\\text{paragraph}_{id}$가 학습의 입력 데이터로 들어가기에 문맥이나 단어가 paragraph 벡터에 녹아든다고 볼 수 있습니다. \n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbOvRfL%2FbtqBzPhTjCD%2FNeKAov500OG05vrsvraZV0%2Fimg.png\" width = \"600px\" height = \"300px\"> \n",
    "\n",
    "각 문서 paragraph는 별도의 (문서의 수 x d 차원) 크기의 행렬에 담깁니다. 학습이 완료된 후, 이 행렬을 이용하여 paragraph의 임베딩된 벡터를 사용합니다. 즉, paragraph의 정보돠 이전 단어들을 통해 다음 단어를 유추하는 것입니다. 이를 PV-DM이라고 합니다. \n",
    "\n",
    "반대로 하나의 $\\text{paragraph}_{id}$로 해당 문서 내 단어들을 유추하는 것을 PV-DBOW라고 합니다. \n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbx8qpy%2FbtqBzjXPOfy%2FNPzuVPVD1RGp4TxKtIXQoK%2Fimg.png\">\n",
    "\n",
    "이제 예시를 통해 살펴보겠습니다. \n",
    "\n",
    "![4-3-5](_image/4-3-5.PNG)\n",
    "\n",
    "위 그림을 보면 input에 (study, female, 10s)가 들어가 있는 것을 볼 수 있습니다. 이는 단어인 'study'외에도 paragraph와 관련된 정보들이 추가로 들어가 있기 때문입니다. input을 통해 10대 여자가 썼다는 정보를 얻을 수 있습니다. \n",
    "\n",
    "![4-3-6](_image/4-3-6.PNG)\n",
    "\n",
    "입력이 여러개이기에 연산 과정에서 데이터들이 각 가중치에 곱해지고 합해집니다. 이 과정을 통해 단어뿐만 아니라 추가적으로 들어오는 paragraph의 정보들도 함께 학습합니다. 위 상황은 (study, female, 10s)라는 input을 통해 (math)라는 output을 얻은 것입니다. \n",
    "\n",
    "반대도 가능합니다. \n",
    "\n",
    "![4-3-7](_image/4-3-7.PNG)\n",
    "\n",
    "위 그림의 경우 단어만 주어지고 이를 통해 다음 단어뿐만 아니라 성별과 나이까지 유추합니다. 그렇기에 loss도 각각 따로 구하고 다른 가중치를 곱하여 합하는 것을 볼 수 있습니다. 소프트맥스를 할 때도 마찬가지로 (i, study, math), (male, female), (10s, 20s, 30s, 40s) 세 분류로 나누어 각각 소프트맥스해줍니다. \n",
    "\n",
    "![4-3-8](_image/4-3-8.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.4 Other Applications of Word2Vec**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec을 다른 방향으로 사용할 수도 있습니다. 예를 들어 밑의 그림을 보겠습니다. \n",
    "\n",
    "![4-3-9](_image/4-3-9.PNG)\n",
    "\n",
    "(John, Jane, Michael)이란 사람이 input으로 주어지고 그들이 구매하거나 관심있는 (Galaxy, iPhone, Macbook, iPad)가 output으로 주어집니다. 이를 통해 그 사람이 관심있는 상품들을 묶어 학습시킬 수도 있습니다. 즉 $W_1$은 사용자에 대한 임베딩 벡터, $W_2$는 사용자가 구매한 상품에 대한 임베딩 벡터가 되는 것입니다.\n",
    "\n",
    "또한 임베딩 벡터를 통하여 비슷한 제품군을 묶고 관련 상품으로 추천할 수도 있습니다.\n",
    "\n",
    "![4-3-10](_image/4-3-10.PNG)\n",
    "\n",
    "위 그림을 보면 비슷한 옷끼리 가까운 거리에 위치하는 것을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습1. Word2Vec 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from konlpy.tag import Mecab, Twitter, Okt, Kkma\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) 데이터 전처리**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 데이터를 확인하고 Word2Vec 형식에 맞게 전처리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [\n",
    "    \"정말 맛있습니다. 추천합니다.\",\n",
    "    \"기대했던 것보단 별로였네요.\",\n",
    "    \"다 좋은데 가격이 너무 비싸서 다시 가고 싶다는 생각이 안 드네요.\",\n",
    "    \"완전 최고입니다! 재방문 의사 있습니다.\",\n",
    "    \"음식도 서비스도 다 만족스러웠습니다.\",\n",
    "    \"위생 상태가 좀 별로였습니다. 좀 더 개선되기를 바랍니다.\",\n",
    "    \"맛도 좋았고 직원분들 서비스도 너무 친절했습니다.\",\n",
    "    \"기념일에 방문했는데 음식도 분위기도 서비스도 다 좋았습니다.\",\n",
    "    \"전반적으로 음식이 너무 짰습니다. 저는 별로였네요.\",\n",
    "    \"위생에 조금 더 신경 썼으면 좋겠습니다. 조금 불쾌했습니다.\"       \n",
    "]\n",
    "\n",
    "test_words = [\"음식\", \"맛\", \"서비스\", \"위생\", \"가격\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization과 vocab을 만드는 과정은 지난 챕터 실습들과 유사합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tokenized(data):\n",
    "    tokenized = []\n",
    "    for sent in tqdm(data):\n",
    "        tokens = tokenizer.morphs(sent, stem=True)\n",
    "        tokenized.append(tokens)\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.69it/s]\n"
     ]
    }
   ],
   "source": [
    "train_tokenized = make_tokenized(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "word_count = defaultdict(int)\n",
    "\n",
    "for tokens in tqdm(train_tokenized):\n",
    "    for token in tokens:\n",
    "        word_count[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', 14), ('도', 7), ('이다', 4), ('좋다', 4), ('별로', 3), ('다', 3), ('이', 3), ('너무', 3), ('음식', 3), ('서비스', 3), ('하다', 2), ('방문', 2), ('위생', 2), ('좀', 2), ('더', 2), ('에', 2), ('조금', 2), ('정말', 1), ('맛있다', 1), ('추천', 1), ('기대하다', 1), ('것', 1), ('보단', 1), ('가격', 1), ('비싸다', 1), ('다시', 1), ('가다', 1), ('싶다', 1), ('생각', 1), ('안', 1), ('드네', 1), ('요', 1), ('완전', 1), ('최고', 1), ('!', 1), ('재', 1), ('의사', 1), ('있다', 1), ('만족스럽다', 1), ('상태', 1), ('가', 1), ('개선', 1), ('되다', 1), ('기르다', 1), ('바라다', 1), ('맛', 1), ('직원', 1), ('분들', 1), ('친절하다', 1), ('기념일', 1), ('분위기', 1), ('전반', 1), ('적', 1), ('으로', 1), ('짜다', 1), ('저', 1), ('는', 1), ('신경', 1), ('써다', 1), ('불쾌하다', 1)]\n"
     ]
    }
   ],
   "source": [
    "word_count = sorted(word_count.items(), key=lambda x: x[1], reverse=True)\n",
    "print(list(word_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "w2i = {}\n",
    "for pair in tqdm(word_count):\n",
    "    if pair[0] not in w2i:\n",
    "        w2i[pair[0]] = len(w2i)\n",
    "\n",
    "i2w = {v:k for k, v in w2i.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['정말', '맛있다', '.', '추천', '하다', '.'], ['기대하다', '것', '보단', '별로', '이다', '.'], ['다', '좋다', '가격', '이', '너무', '비싸다', '다시', '가다', '싶다', '생각', '이', '안', '드네', '요', '.'], ['완전', '최고', '이다', '!', '재', '방문', '의사', '있다', '.'], ['음식', '도', '서비스', '도', '다', '만족스럽다', '.'], ['위생', '상태', '가', '좀', '별로', '이다', '.', '좀', '더', '개선', '되다', '기르다', '바라다', '.'], ['맛', '도', '좋다', '직원', '분들', '서비스', '도', '너무', '친절하다', '.'], ['기념일', '에', '방문', '하다', '음식', '도', '분위기', '도', '서비스', '도', '다', '좋다', '.'], ['전반', '적', '으로', '음식', '이', '너무', '짜다', '.', '저', '는', '별로', '이다', '.'], ['위생', '에', '조금', '더', '신경', '써다', '좋다', '.', '조금', '불쾌하다', '.']]\n",
      "{'.': 0, '도': 1, '이다': 2, '좋다': 3, '별로': 4, '다': 5, '이': 6, '너무': 7, '음식': 8, '서비스': 9, '하다': 10, '방문': 11, '위생': 12, '좀': 13, '더': 14, '에': 15, '조금': 16, '정말': 17, '맛있다': 18, '추천': 19, '기대하다': 20, '것': 21, '보단': 22, '가격': 23, '비싸다': 24, '다시': 25, '가다': 26, '싶다': 27, '생각': 28, '안': 29, '드네': 30, '요': 31, '완전': 32, '최고': 33, '!': 34, '재': 35, '의사': 36, '있다': 37, '만족스럽다': 38, '상태': 39, '가': 40, '개선': 41, '되다': 42, '기르다': 43, '바라다': 44, '맛': 45, '직원': 46, '분들': 47, '친절하다': 48, '기념일': 49, '분위기': 50, '전반': 51, '적': 52, '으로': 53, '짜다': 54, '저': 55, '는': 56, '신경': 57, '써다': 58, '불쾌하다': 59}\n"
     ]
    }
   ],
   "source": [
    "print(train_tokenized)\n",
    "print(w2i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) Dataset 클래스 구현**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 Word2Vec을 학습시키는 대표적인 방법인 Skip-Gram과 CBOW로 구현하겠습니다. 간단하게 요약하자면 다음과 같은 특징을 가지고 있었습니다.\n",
    "\n",
    "- CBOW는 주변단어를 이용해 주어진 단어를 예측하는 방법입니다.\n",
    "- Skip-Gram은 중심 단어를 이용하여 주변 단어를 예측하는 방법입니다. \n",
    "- 즉, 두 방법은 input과 output을 어떻게 설정하는지에 대한 차이가 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 모델에 들어가기 위한 input을 만들기 위해 Dataset 클래스를 먼저 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOWDataset(Dataset):\n",
    "    def __init__(self, train_tokenized, window_size=2):\n",
    "        self.x = [] # input word\n",
    "        self.y = [] # output word\n",
    "        \n",
    "        for tokens in tqdm(train_tokenized):\n",
    "            token_ids = [w2i[token] for token in tokens]\n",
    "            for i, id in enumerate(token_ids):\n",
    "                if i - window_size >= 0 and i + window_size < len(token_ids):\n",
    "                    self.x.append(token_ids[i - window_size:i] + token_ids[i + 1: i + window_size + 1])\n",
    "                    self.y.append(id)\n",
    "        self.x = torch.LongTensor(self.x) # (전체 데이터 개수, 2* window_size)\n",
    "        self.y = torch.LongTensor(self.y) # (전체 데이터 개수)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramDataset(Dataset):\n",
    "    def __init__(self, train_tokenized, window_size=2):\n",
    "        self.x = [] # input word\n",
    "        self.y = [] # output word\n",
    "        \n",
    "        for tokens in tqdm(train_tokenized):\n",
    "            token_ids = [w2i[token] for token in tokens]\n",
    "            for i, id in enumerate(token_ids):\n",
    "                if i - window_size >= 0 and i + window_size < len(token_ids):\n",
    "                    self.y += (token_ids[i - window_size:i] + token_ids[i + 1: i + window_size + 1])\n",
    "                    self.x += [id] * 2 * window_size # id로 window_size 내 주변 단어를 모두 유추해야함\n",
    "        \n",
    "        self.x = torch.LongTensor(self.x) # (전체 데이터 개수)\n",
    "        self.y = torch.LongTensor(self.y) # (전체 데이터 개수)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 모델에 맞는 Dataset 객체를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 9988.82it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor(0), tensor(17)), (tensor(0), tensor(18)), (tensor(0), tensor(19)), (tensor(0), tensor(10)), (tensor(19), tensor(18)), (tensor(19), tensor(0)), (tensor(19), tensor(10)), (tensor(19), tensor(0)), (tensor(22), tensor(20)), (tensor(22), tensor(21)), (tensor(22), tensor(4)), (tensor(22), tensor(2)), (tensor(4), tensor(21)), (tensor(4), tensor(22)), (tensor(4), tensor(2)), (tensor(4), tensor(0)), (tensor(23), tensor(5)), (tensor(23), tensor(3)), (tensor(23), tensor(6)), (tensor(23), tensor(7)), (tensor(6), tensor(3)), (tensor(6), tensor(23)), (tensor(6), tensor(7)), (tensor(6), tensor(24)), (tensor(7), tensor(23)), (tensor(7), tensor(6)), (tensor(7), tensor(24)), (tensor(7), tensor(25)), (tensor(24), tensor(6)), (tensor(24), tensor(7)), (tensor(24), tensor(25)), (tensor(24), tensor(26)), (tensor(25), tensor(7)), (tensor(25), tensor(24)), (tensor(25), tensor(26)), (tensor(25), tensor(27)), (tensor(26), tensor(24)), (tensor(26), tensor(25)), (tensor(26), tensor(27)), (tensor(26), tensor(28)), (tensor(27), tensor(25)), (tensor(27), tensor(26)), (tensor(27), tensor(28)), (tensor(27), tensor(6)), (tensor(28), tensor(26)), (tensor(28), tensor(27)), (tensor(28), tensor(6)), (tensor(28), tensor(29)), (tensor(6), tensor(27)), (tensor(6), tensor(28)), (tensor(6), tensor(29)), (tensor(6), tensor(30)), (tensor(29), tensor(28)), (tensor(29), tensor(6)), (tensor(29), tensor(30)), (tensor(29), tensor(31)), (tensor(30), tensor(6)), (tensor(30), tensor(29)), (tensor(30), tensor(31)), (tensor(30), tensor(0)), (tensor(2), tensor(32)), (tensor(2), tensor(33)), (tensor(2), tensor(34)), (tensor(2), tensor(35)), (tensor(34), tensor(33)), (tensor(34), tensor(2)), (tensor(34), tensor(35)), (tensor(34), tensor(11)), (tensor(35), tensor(2)), (tensor(35), tensor(34)), (tensor(35), tensor(11)), (tensor(35), tensor(36)), (tensor(11), tensor(34)), (tensor(11), tensor(35)), (tensor(11), tensor(36)), (tensor(11), tensor(37)), (tensor(36), tensor(35)), (tensor(36), tensor(11)), (tensor(36), tensor(37)), (tensor(36), tensor(0)), (tensor(9), tensor(8)), (tensor(9), tensor(1)), (tensor(9), tensor(1)), (tensor(9), tensor(5)), (tensor(1), tensor(1)), (tensor(1), tensor(9)), (tensor(1), tensor(5)), (tensor(1), tensor(38)), (tensor(5), tensor(9)), (tensor(5), tensor(1)), (tensor(5), tensor(38)), (tensor(5), tensor(0)), (tensor(40), tensor(12)), (tensor(40), tensor(39)), (tensor(40), tensor(13)), (tensor(40), tensor(4)), (tensor(13), tensor(39)), (tensor(13), tensor(40)), (tensor(13), tensor(4)), (tensor(13), tensor(2)), (tensor(4), tensor(40)), (tensor(4), tensor(13)), (tensor(4), tensor(2)), (tensor(4), tensor(0)), (tensor(2), tensor(13)), (tensor(2), tensor(4)), (tensor(2), tensor(0)), (tensor(2), tensor(13)), (tensor(0), tensor(4)), (tensor(0), tensor(2)), (tensor(0), tensor(13)), (tensor(0), tensor(14)), (tensor(13), tensor(2)), (tensor(13), tensor(0)), (tensor(13), tensor(14)), (tensor(13), tensor(41)), (tensor(14), tensor(0)), (tensor(14), tensor(13)), (tensor(14), tensor(41)), (tensor(14), tensor(42)), (tensor(41), tensor(13)), (tensor(41), tensor(14)), (tensor(41), tensor(42)), (tensor(41), tensor(43)), (tensor(42), tensor(14)), (tensor(42), tensor(41)), (tensor(42), tensor(43)), (tensor(42), tensor(44)), (tensor(43), tensor(41)), (tensor(43), tensor(42)), (tensor(43), tensor(44)), (tensor(43), tensor(0)), (tensor(3), tensor(45)), (tensor(3), tensor(1)), (tensor(3), tensor(46)), (tensor(3), tensor(47)), (tensor(46), tensor(1)), (tensor(46), tensor(3)), (tensor(46), tensor(47)), (tensor(46), tensor(9)), (tensor(47), tensor(3)), (tensor(47), tensor(46)), (tensor(47), tensor(9)), (tensor(47), tensor(1)), (tensor(9), tensor(46)), (tensor(9), tensor(47)), (tensor(9), tensor(1)), (tensor(9), tensor(7)), (tensor(1), tensor(47)), (tensor(1), tensor(9)), (tensor(1), tensor(7)), (tensor(1), tensor(48)), (tensor(7), tensor(9)), (tensor(7), tensor(1)), (tensor(7), tensor(48)), (tensor(7), tensor(0)), (tensor(11), tensor(49)), (tensor(11), tensor(15)), (tensor(11), tensor(10)), (tensor(11), tensor(8)), (tensor(10), tensor(15)), (tensor(10), tensor(11)), (tensor(10), tensor(8)), (tensor(10), tensor(1)), (tensor(8), tensor(11)), (tensor(8), tensor(10)), (tensor(8), tensor(1)), (tensor(8), tensor(50)), (tensor(1), tensor(10)), (tensor(1), tensor(8)), (tensor(1), tensor(50)), (tensor(1), tensor(1)), (tensor(50), tensor(8)), (tensor(50), tensor(1)), (tensor(50), tensor(1)), (tensor(50), tensor(9)), (tensor(1), tensor(1)), (tensor(1), tensor(50)), (tensor(1), tensor(9)), (tensor(1), tensor(1)), (tensor(9), tensor(50)), (tensor(9), tensor(1)), (tensor(9), tensor(1)), (tensor(9), tensor(5)), (tensor(1), tensor(1)), (tensor(1), tensor(9)), (tensor(1), tensor(5)), (tensor(1), tensor(3)), (tensor(5), tensor(9)), (tensor(5), tensor(1)), (tensor(5), tensor(3)), (tensor(5), tensor(0)), (tensor(53), tensor(51)), (tensor(53), tensor(52)), (tensor(53), tensor(8)), (tensor(53), tensor(6)), (tensor(8), tensor(52)), (tensor(8), tensor(53)), (tensor(8), tensor(6)), (tensor(8), tensor(7)), (tensor(6), tensor(53)), (tensor(6), tensor(8)), (tensor(6), tensor(7)), (tensor(6), tensor(54)), (tensor(7), tensor(8)), (tensor(7), tensor(6)), (tensor(7), tensor(54)), (tensor(7), tensor(0)), (tensor(54), tensor(6)), (tensor(54), tensor(7)), (tensor(54), tensor(0)), (tensor(54), tensor(55)), (tensor(0), tensor(7)), (tensor(0), tensor(54)), (tensor(0), tensor(55)), (tensor(0), tensor(56)), (tensor(55), tensor(54)), (tensor(55), tensor(0)), (tensor(55), tensor(56)), (tensor(55), tensor(4)), (tensor(56), tensor(0)), (tensor(56), tensor(55)), (tensor(56), tensor(4)), (tensor(56), tensor(2)), (tensor(4), tensor(55)), (tensor(4), tensor(56)), (tensor(4), tensor(2)), (tensor(4), tensor(0)), (tensor(16), tensor(12)), (tensor(16), tensor(15)), (tensor(16), tensor(14)), (tensor(16), tensor(57)), (tensor(14), tensor(15)), (tensor(14), tensor(16)), (tensor(14), tensor(57)), (tensor(14), tensor(58)), (tensor(57), tensor(16)), (tensor(57), tensor(14)), (tensor(57), tensor(58)), (tensor(57), tensor(3)), (tensor(58), tensor(14)), (tensor(58), tensor(57)), (tensor(58), tensor(3)), (tensor(58), tensor(0)), (tensor(3), tensor(57)), (tensor(3), tensor(58)), (tensor(3), tensor(0)), (tensor(3), tensor(16)), (tensor(0), tensor(58)), (tensor(0), tensor(3)), (tensor(0), tensor(16)), (tensor(0), tensor(59)), (tensor(16), tensor(3)), (tensor(16), tensor(0)), (tensor(16), tensor(59)), (tensor(16), tensor(0))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cbow_set = CBOWDataset(train_tokenized)\n",
    "skipgram_set = SkipGramDataset(train_tokenized)\n",
    "print(list(skipgram_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) 모델 구현**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "차례대로 두 가지 Word2Vec 모델을 구현하겠습니다.\n",
    "\n",
    "- self.embedding: vocab_size 크기의 one-hot vector를 특정 크기의 dim차원으로 embedding 시키는 layer\n",
    "- self.linear: 변환된 embedding vector를 다시 원래 vocab_size로 바꾸는 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, dim):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, dim, sparse=True)\n",
    "        self.linear = nn.Linear(dim, vocab_size)\n",
    "    \n",
    "    # B: batch size, W: window size, d_w: word embedding size, V: vocab size\n",
    "    def forward(self, x): # x:(B, 2W)\n",
    "        embeddings = self.embedding(x) # (B, 2W, d_w)\n",
    "        embeddings = torch.sum(embeddings, dim=1) # (B, d_w)\n",
    "        output = self.linear(embeddings) # (B, V)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGram(nn.Module):\n",
    "    def __init__(self, vocab_size, dim):\n",
    "        super(SkipGram, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, dim, sparse=True)\n",
    "        self.linear = nn.Linear(dim, vocab_size)\n",
    "    \n",
    "    # B: batch size, W: window size, d_w: word embedding size, V: vocab size\n",
    "    def forward(self, x): # x:(B)\n",
    "        embeddings = self.embedding(x) # (B, d_w)\n",
    "        output = self.linear(embeddings) # (B, V)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow = CBOW(vocab_size=len(w2i), dim=256)\n",
    "skipgram = SkipGram(vocab_size=len(w2i), dim=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4) 모델 학습**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음과 같이 하이퍼파라미터를 설정하고 DataLoader 객체를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "learning_rate = 5e-4\n",
    "num_epochs = 5\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "cbow_loader = DataLoader(cbow_set, batch_size=batch_size)\n",
    "skipgram_loader = DataLoader(skipgram_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 CBOW 모델을 학습하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 202.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.517364501953125\n",
      "Train loss: 5.722186088562012\n",
      "Train loss: 4.509489059448242\n",
      "Train loss: 4.71565055847168\n",
      "Train loss: 5.350027084350586\n",
      "Train loss: 4.911778926849365\n",
      "Train loss: 3.9825315475463867\n",
      "Train loss: 5.044991970062256\n",
      "Train loss: 4.438126564025879\n",
      "Train loss: 4.177204132080078\n",
      "Train loss: 4.603321075439453\n",
      "Train loss: 5.182714462280273\n",
      "Train loss: 4.771857738494873\n",
      "Train loss: 4.823988437652588\n",
      "Train loss: 4.422669410705566\n",
      "Train loss: 3.94539213180542\n",
      "##################################################\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 372.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.3733344078063965\n",
      "Train loss: 5.599576473236084\n",
      "Train loss: 4.3914265632629395\n",
      "Train loss: 4.599921703338623\n",
      "Train loss: 5.2240891456604\n",
      "Train loss: 4.6652021408081055\n",
      "Train loss: 3.808961868286133\n",
      "Train loss: 4.932811737060547\n",
      "Train loss: 4.332380294799805\n",
      "Train loss: 4.0147881507873535\n",
      "Train loss: 4.421172142028809\n",
      "Train loss: 4.863188743591309\n",
      "Train loss: 4.64410924911499\n",
      "Train loss: 4.702084064483643\n",
      "Train loss: 4.267542362213135\n",
      "Train loss: 3.8243963718414307\n",
      "##################################################\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 400.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.231768608093262\n",
      "Train loss: 5.478585243225098\n",
      "Train loss: 4.275032043457031\n",
      "Train loss: 4.485116004943848\n",
      "Train loss: 5.098927021026611\n",
      "Train loss: 4.427643775939941\n",
      "Train loss: 3.6395773887634277\n",
      "Train loss: 4.822075366973877\n",
      "Train loss: 4.22916316986084\n",
      "Train loss: 3.858006238937378\n",
      "Train loss: 4.246267795562744\n",
      "Train loss: 4.555294990539551\n",
      "Train loss: 4.518178939819336\n",
      "Train loss: 4.5822834968566895\n",
      "Train loss: 4.115230560302734\n",
      "Train loss: 3.706716537475586\n",
      "##################################################\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.092677116394043\n",
      "Train loss: 5.359189510345459\n",
      "Train loss: 4.160326957702637\n",
      "Train loss: 4.371255874633789\n",
      "Train loss: 4.97455358505249\n",
      "Train loss: 4.199728012084961\n",
      "Train loss: 3.4745688438415527\n",
      "Train loss: 4.712802410125732\n",
      "Train loss: 4.12832498550415\n",
      "Train loss: 3.706940174102783\n",
      "Train loss: 4.078704357147217\n",
      "Train loss: 4.260048866271973\n",
      "Train loss: 4.394067764282227"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 355.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 4.464550018310547\n",
      "Train loss: 3.9659085273742676\n",
      "Train loss: 3.592409372329712\n",
      "##################################################\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 410.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.956080436706543\n",
      "Train loss: 5.241368293762207\n",
      "Train loss: 4.047332763671875\n",
      "Train loss: 4.258368492126465\n",
      "Train loss: 4.850984573364258\n",
      "Train loss: 3.9820339679718018\n",
      "Train loss: 3.314148187637329\n",
      "Train loss: 4.605008125305176\n",
      "Train loss: 4.029695510864258\n",
      "Train loss: 3.5615880489349365\n",
      "Train loss: 3.9187049865722656\n",
      "Train loss: 3.978358268737793\n",
      "Train loss: 4.271775245666504\n",
      "Train loss: 4.348851680755615\n",
      "Train loss: 3.8197689056396484\n",
      "Train loss: 3.4815196990966797\n",
      "Finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cbow.train()\n",
    "cbow = cbow.to(device)\n",
    "optim = torch.optim.SGD(cbow.parameters(), lr=learning_rate)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "for e in range(1, num_epochs + 1):\n",
    "    print(\"#\" * 50)\n",
    "    print(f\"Epoch: {e}\")\n",
    "    for batch in tqdm(cbow_loader):\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device) # (B, W), (B)\n",
    "        output = cbow(x) # (B, V)\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss = loss_function(output, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        print(f\"Train loss: {loss.item()}\")\n",
    "\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로 Skip-Gram 모델을 학습하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 441.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.7030582427978516\n",
      "##################################################\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 481.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.6635866165161133\n",
      "##################################################\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 586.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.624561309814453\n",
      "##################################################\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 735.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.585994243621826\n",
      "##################################################\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 646.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.5478954315185547\n",
      "Finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "skipgram.train()\n",
    "skipgram = skipgram.to(device)\n",
    "optim = torch.optim.SGD(skipgram.parameters(), lr=learning_rate)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "for e in range(1, num_epochs + 1):\n",
    "    print(\"#\" * 50)\n",
    "    print(f\"Epoch: {e}\")\n",
    "    for batch in tqdm(skipgram_loader):\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device) # (B, W), (B)\n",
    "        output = skipgram(x) # (B, V)\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss = loss_function(output, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    \n",
    "    print(f\"Train loss: {loss.item()}\")\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5) 테스트**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: 음식\n",
      "tensor([-7.8031e-01,  3.4020e-01,  2.3965e-01,  1.1466e+00, -4.7382e-01,\n",
      "        -1.1625e-01,  2.5119e+00,  6.0728e-01,  2.4680e+00,  1.2630e-01,\n",
      "        -2.7188e-02,  3.9423e-01,  9.8465e-01, -5.1491e-01,  9.3773e-01,\n",
      "        -2.0908e+00,  9.9917e-01, -2.5360e-01, -4.9429e-01,  3.4974e-01,\n",
      "        -7.9115e-01, -3.7272e-01, -7.2416e-01,  7.1037e-01,  1.3163e-01,\n",
      "         5.8675e-01, -9.7430e-02,  1.3822e+00, -2.8502e-01, -7.8537e-01,\n",
      "        -9.5123e-01, -1.0286e+00,  7.6688e-01, -3.2761e-01,  1.3801e-01,\n",
      "        -4.0390e-01, -8.6721e-01, -1.2883e+00,  1.1042e+00,  2.2619e+00,\n",
      "         9.7791e-02,  9.4427e-01,  8.9367e-01,  1.3734e+00,  2.7213e-01,\n",
      "        -7.3901e-01,  3.9341e-01,  6.8423e-01,  1.5472e+00, -1.0421e-01,\n",
      "        -7.3628e-01, -2.1654e+00,  2.4462e-01,  9.1695e-01, -4.6950e-02,\n",
      "         5.0610e-03, -4.6465e-01, -7.3774e-01, -1.1797e+00, -8.8331e-01,\n",
      "         4.4442e-01,  9.0978e-01,  2.5616e+00,  1.6349e-01,  9.5964e-02,\n",
      "        -8.8922e-02,  1.5621e+00,  5.1451e-01, -5.3047e-01, -7.1057e-01,\n",
      "         1.9713e+00,  1.9023e+00,  9.7000e-01,  1.6177e+00, -4.8513e-01,\n",
      "        -5.9215e-01, -6.2762e-01,  6.5475e-02, -7.2082e-01, -1.6420e-01,\n",
      "        -2.2280e-01,  1.2401e+00,  3.4138e-01, -1.2840e+00, -1.6350e+00,\n",
      "        -6.5896e-01, -3.0616e-01, -1.3532e+00,  1.0170e+00,  3.7837e-01,\n",
      "        -2.6662e-01,  1.8364e+00,  2.4980e-01,  1.3723e+00, -1.7900e-02,\n",
      "        -1.4385e-01,  1.9547e+00, -5.1830e-01,  3.8538e-01,  9.2184e-01,\n",
      "        -5.4997e-01, -4.7631e-02, -1.0276e-01,  1.2959e-01, -3.1721e-01,\n",
      "         2.7689e-01,  6.1655e-01, -2.1437e+00, -1.4720e+00, -8.0351e-01,\n",
      "        -3.1372e-01,  1.7194e+00, -1.9934e+00,  1.7667e-02, -4.0639e-02,\n",
      "         3.7951e-01,  2.5669e-01, -1.6582e+00, -1.1023e-03,  1.9758e+00,\n",
      "        -1.6434e+00, -8.2522e-03, -8.5538e-01,  9.7460e-01,  1.5014e+00,\n",
      "         1.0897e-01,  2.0340e-01, -9.7940e-02,  2.3217e+00, -2.8914e-01,\n",
      "         1.0236e+00, -4.7788e-01,  1.3557e+00, -9.1947e-01, -9.4932e-01,\n",
      "        -1.3046e+00,  2.5262e+00,  1.1113e+00, -1.8813e-01, -7.9594e-01,\n",
      "        -8.4787e-01,  1.6889e+00,  3.4893e-01,  1.2047e-01,  3.1440e-01,\n",
      "         5.1613e-01,  9.5289e-01, -3.4682e-02,  4.3395e-01, -1.2423e+00,\n",
      "        -1.5560e-01,  3.4323e-02, -1.8101e+00, -9.7124e-01, -4.2865e-01,\n",
      "         5.4273e-01,  4.7482e-01, -1.2503e+00,  6.8545e-01,  3.9855e-01,\n",
      "         1.6989e-01,  1.4513e+00, -2.6038e-01,  2.2006e-01, -5.2606e-01,\n",
      "         1.6740e-01,  7.6959e-01, -9.7723e-01,  1.3092e+00,  1.7030e+00,\n",
      "        -7.1313e-01,  5.6531e-02,  4.8902e-01,  3.2708e-02,  8.6103e-02,\n",
      "        -1.0802e+00, -1.0031e+00, -1.4843e-02, -5.7045e-01,  1.8234e-01,\n",
      "        -1.0143e+00, -4.3484e-01, -8.4060e-01, -3.5553e-01, -1.0867e+00,\n",
      "        -4.1910e-01,  2.9517e-01,  7.2969e-02,  9.1472e-01, -4.2685e-01,\n",
      "         1.2463e+00, -8.6465e-01, -1.0092e+00,  8.5423e-01,  1.2691e+00,\n",
      "         2.9808e+00, -3.2207e-01, -5.6910e-01, -8.9806e-01, -3.3563e-01,\n",
      "        -9.4357e-01,  3.5381e-01, -2.9078e-01, -1.2577e+00,  4.7150e-01,\n",
      "        -3.9397e-01, -1.1603e+00, -1.4829e+00,  7.2038e-01, -7.6397e-02,\n",
      "         3.6751e-01,  7.5057e-01,  2.9799e-01,  1.8045e-02,  1.1808e+00,\n",
      "         2.4704e+00,  1.2356e+00, -9.0351e-01, -6.5906e-01,  1.7421e+00,\n",
      "        -3.6901e-01, -4.2717e-01,  6.7428e-01, -1.3162e+00, -1.4041e+00,\n",
      "        -4.2978e-01, -3.7173e-01,  1.1054e+00, -6.6969e-02, -8.8388e-01,\n",
      "        -1.3366e+00, -1.6624e-01, -1.0108e+00, -1.7806e-01,  3.7672e-01,\n",
      "        -3.2116e-01, -1.0270e+00,  1.8875e+00,  2.1317e+00, -1.3088e+00,\n",
      "         9.4271e-01, -1.7540e+00,  1.6453e+00,  4.4708e-01, -1.1201e-01,\n",
      "         3.8833e-01,  1.1898e+00,  1.0451e+00, -1.2772e+00, -1.4186e-02,\n",
      "        -4.9965e-01, -1.4359e-01,  7.3072e-01,  1.1311e+00,  8.0893e-01,\n",
      "        -4.7645e-01], grad_fn=<SqueezeBackward1>)\n",
      "Word: 맛\n",
      "tensor([ 1.6901e-01, -1.0049e+00,  1.3480e+00,  1.5568e-01, -8.4420e-01,\n",
      "        -2.6936e-01,  3.4812e-01,  1.6002e-01, -1.4371e+00,  2.5747e-02,\n",
      "        -7.1336e-01,  1.6903e+00, -7.1813e-02,  1.6065e-01,  1.1732e+00,\n",
      "        -1.1890e-01,  1.3415e+00, -5.9285e-01, -4.0044e-02,  6.3289e-01,\n",
      "         1.7741e+00,  1.5503e+00,  1.6715e-01, -7.3411e-01,  9.1571e-01,\n",
      "        -2.4276e-02,  1.4787e-04,  3.8662e-01,  1.9371e-01, -2.5370e-01,\n",
      "         5.1686e-01,  4.7265e-01,  1.3874e+00,  1.6561e+00,  1.7488e-01,\n",
      "         3.1223e-01, -1.1457e+00,  6.7954e-01, -4.6328e-01,  1.0931e+00,\n",
      "        -1.8031e-01, -5.1148e-02, -1.1415e+00, -1.4564e+00, -2.1409e+00,\n",
      "         1.2218e+00, -1.4853e+00, -4.2371e-01,  5.8552e-02, -4.8069e-02,\n",
      "         6.2347e-01, -7.4163e-01,  1.5641e+00,  8.0746e-01, -1.8197e+00,\n",
      "        -9.8870e-01,  2.2681e-01,  6.7259e-01, -1.0937e+00,  4.1984e-01,\n",
      "         1.2354e-01,  7.9609e-01,  1.9227e+00,  5.8682e-01, -8.4621e-01,\n",
      "        -2.7316e-01, -8.2723e-01, -6.6811e-01, -1.6487e+00, -1.2285e+00,\n",
      "        -6.4610e-01,  9.6252e-01,  9.1570e-01,  2.0233e-01, -4.2204e-01,\n",
      "        -3.4222e-01, -1.4430e-01,  1.2569e+00,  4.5863e-01,  1.5787e+00,\n",
      "         2.6811e-01,  5.3112e-01,  9.0662e-01, -5.8903e-01, -2.3962e-01,\n",
      "        -2.3606e+00, -4.1559e-01, -1.5379e-01, -3.1408e-02,  5.9724e-01,\n",
      "         8.0533e-02, -5.4447e-01,  1.5772e-01, -9.6826e-02,  2.0465e-01,\n",
      "        -4.9360e-01, -8.1467e-01,  5.3285e-01, -1.1031e+00,  1.7485e-01,\n",
      "         7.2805e-01, -3.2677e+00,  3.1684e-01,  7.9653e-01, -1.0023e+00,\n",
      "         1.0586e+00, -6.0206e-01, -1.4041e+00, -2.9468e-01,  1.5900e+00,\n",
      "        -3.9742e-01,  7.7016e-01, -5.4905e-01,  6.6624e-01, -3.3869e-01,\n",
      "        -1.9782e-01,  3.2276e-01,  4.9011e-01,  4.9391e-01,  7.9482e-01,\n",
      "         9.5320e-01, -1.1591e+00,  2.5278e-01,  2.1663e+00, -3.8787e-01,\n",
      "         7.8097e-01, -6.6166e-01,  1.2409e+00,  3.1721e-01, -1.5158e-01,\n",
      "        -1.4952e+00,  3.0164e-01,  9.9046e-01, -6.1769e-01, -9.2716e-02,\n",
      "        -7.6265e-02, -8.3602e-01, -2.2131e+00, -1.1500e+00, -2.7803e+00,\n",
      "        -1.8718e+00, -3.0469e+00,  7.7717e-01,  2.6127e-01,  7.3508e-02,\n",
      "        -7.2526e-01, -1.1701e+00, -3.9109e-01, -9.1339e-01,  4.0621e-01,\n",
      "        -2.1739e+00, -2.3541e-02,  4.1758e-01,  1.8640e-01,  2.5454e-01,\n",
      "         5.5782e-01,  1.5423e+00,  8.9363e-03,  2.0581e+00,  1.3317e+00,\n",
      "         1.0482e+00,  9.7399e-01, -2.0417e+00, -1.0542e+00,  8.0093e-01,\n",
      "         1.3092e+00, -3.5777e-01, -1.4895e+00,  7.8532e-01,  1.4665e+00,\n",
      "        -8.4920e-01,  1.0046e+00,  1.1601e+00,  1.7930e-01, -4.6181e-01,\n",
      "         1.4162e-01,  1.0516e+00, -1.8358e-01,  2.9896e-03, -1.3641e-01,\n",
      "        -4.2434e-01, -3.7151e-01,  2.6657e+00, -1.3582e+00,  8.2084e-01,\n",
      "         5.9090e-01, -2.4172e+00,  4.8679e-01, -5.7218e-01,  7.2174e-01,\n",
      "        -8.7474e-01, -2.2682e-01, -6.6114e-01,  7.6970e-01, -1.2855e+00,\n",
      "         1.3430e-01,  1.6261e+00,  1.1888e+00, -1.6298e+00,  7.8212e-01,\n",
      "        -7.3374e-01, -2.5756e-01,  2.2563e-01,  5.8384e-01, -1.2601e+00,\n",
      "         1.3137e+00, -9.4048e-01,  3.6340e-01, -1.2359e+00, -8.0351e-01,\n",
      "        -3.6785e-01,  1.6215e+00, -5.9459e-01, -1.1406e+00,  7.3910e-01,\n",
      "        -5.2536e-01, -6.9264e-01,  5.5694e-01,  3.7339e-01,  1.2103e-01,\n",
      "         7.6081e-02, -5.3887e-01, -3.0115e-01,  5.5235e-01,  1.0532e+00,\n",
      "        -1.4490e+00,  1.5598e-01, -1.1971e+00, -1.2939e+00, -8.1929e-01,\n",
      "         5.9641e-01,  1.7379e+00, -7.7979e-01,  9.7815e-01,  1.3706e-01,\n",
      "        -7.2082e-01,  1.4945e+00,  5.1033e-02,  1.0608e+00, -4.7713e-01,\n",
      "        -5.0263e-01, -2.5994e-01, -8.5715e-01,  3.3785e-01,  1.5411e-01,\n",
      "         1.0512e+00, -4.5928e-01,  2.2648e-02,  4.8071e-01, -2.9716e-01,\n",
      "         4.0865e-01,  7.9106e-01, -3.5934e-01,  1.0250e-01, -1.1335e+00,\n",
      "        -7.7716e-01], grad_fn=<SqueezeBackward1>)\n",
      "Word: 서비스\n",
      "tensor([ 1.4786,  0.3905, -0.8332,  0.6824,  0.6825, -0.2595,  0.2169,  1.3872,\n",
      "        -0.0100, -0.1580,  1.7148,  1.0895, -0.3647, -0.1574, -0.7596,  0.2503,\n",
      "        -1.3668,  1.4090,  0.2179,  0.5259, -1.1860, -0.0156,  0.5940, -0.4192,\n",
      "        -0.0226, -0.5109, -0.4486, -0.3341, -0.1876,  0.7814,  0.4346,  0.1015,\n",
      "         0.4027,  0.0152,  1.4765,  0.3903, -0.9880,  0.1375, -0.1512, -0.4297,\n",
      "         0.2159,  1.7700,  0.7895,  0.6924,  0.4461, -0.2688, -0.4754, -1.2588,\n",
      "        -0.5341, -0.3940,  0.9390, -0.0104,  0.2510,  1.4521, -0.2193,  1.4028,\n",
      "        -1.3823,  2.2198, -0.4409,  0.9056,  1.4681, -0.8094, -0.2513,  0.4803,\n",
      "        -0.6269,  0.1240, -0.0824,  0.5644,  0.2763, -1.3303, -0.5262, -1.5006,\n",
      "        -0.4220,  0.7490,  0.7180, -0.1650, -1.1135,  0.0506,  0.4551, -1.1252,\n",
      "        -0.4166,  0.6934, -0.1839, -0.2096,  1.1315,  1.9822, -1.5004,  0.2958,\n",
      "        -0.2023,  0.3634,  1.1735, -0.8921, -2.3070, -1.4083,  0.7632,  0.8900,\n",
      "        -0.0410, -0.5672, -0.8005, -2.7274,  0.6574,  0.6026, -0.0748,  0.3155,\n",
      "         1.0800,  1.6752,  0.3543, -0.5470,  0.8532, -0.1549, -0.8645,  0.1838,\n",
      "        -0.0161, -0.6124,  1.9449,  0.2742, -0.8567,  0.0487,  0.4903,  0.4960,\n",
      "        -1.2039,  1.6423,  1.2369, -0.9319, -0.1591, -0.2267, -0.1603,  0.6340,\n",
      "        -0.8392,  0.2487, -0.6730, -1.3916,  0.2334, -0.3258,  1.2465,  0.9748,\n",
      "         0.2215, -1.0458,  1.0770,  0.1202, -0.5817, -2.0978,  1.9575, -0.1301,\n",
      "        -2.3554, -0.5285,  0.9435, -0.8807, -0.4890, -0.9258,  0.1643,  0.2921,\n",
      "         0.9330,  1.2865,  0.6115, -0.1013,  0.2073, -0.5822,  0.9370,  0.4972,\n",
      "        -1.2810,  0.3117, -0.0859,  0.4496,  0.0574, -0.2001, -1.4972, -0.5973,\n",
      "         0.1081, -1.3723, -0.6360, -0.4325,  1.1219,  0.2154,  0.0724, -0.9239,\n",
      "         0.1641, -0.3740, -0.7120,  0.1564, -1.5373,  1.1095, -0.7086, -0.0225,\n",
      "        -0.1747,  0.3444, -0.1286,  1.6360,  0.9330,  0.1188,  0.8471,  1.4425,\n",
      "         0.7179, -0.7834,  1.1145, -1.2957, -1.2940,  1.2295,  0.4106,  0.5870,\n",
      "        -0.7864,  0.6853, -0.0083,  0.3745, -0.5534, -1.4724,  1.0150, -0.8643,\n",
      "        -1.1095, -0.8150,  1.8162, -1.9256, -0.5253,  0.9136, -1.4277,  0.3404,\n",
      "         0.7384,  1.4030, -0.1202, -0.9031,  0.7609,  0.8396, -0.0690,  1.1332,\n",
      "        -0.9305, -0.6475,  0.7680, -2.6760, -0.2516,  0.6909, -0.3202, -1.7600,\n",
      "        -0.1745, -0.0107,  0.9714,  0.5449,  0.0936,  0.8449,  0.4360, -1.2196,\n",
      "         0.8882, -0.9520,  0.5715,  0.3791, -1.4208,  0.3457,  0.2081,  0.7361,\n",
      "        -0.4422,  0.3124, -0.0735,  0.8806, -0.8429,  1.7410, -0.2047, -2.0036],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "Word: 위생\n",
      "tensor([-0.1306, -0.5503,  0.5981,  1.8302,  0.1846, -1.8209,  0.5263, -0.3091,\n",
      "         0.0841, -1.3783, -0.5422,  1.2531, -1.0689, -0.6920,  1.1438, -1.3189,\n",
      "        -1.4783,  0.8767,  0.8526, -1.6881, -1.2899,  0.0588,  0.9375,  1.2213,\n",
      "        -0.5093, -2.4534,  1.3259, -0.0463,  1.1031,  0.7655,  0.2626, -0.5971,\n",
      "        -1.2813,  0.2130,  0.6178, -0.5844,  0.6627,  0.3429,  0.3647, -0.6265,\n",
      "         0.7559,  0.5838,  0.1278, -0.1372, -1.4410, -2.1312,  1.6435, -0.0296,\n",
      "        -0.2525,  0.0705,  0.9042,  1.2123, -0.6495,  0.2127,  0.5034, -0.4762,\n",
      "        -0.7084, -1.7937, -0.6218,  1.5456, -0.7402,  0.3890,  2.2705, -1.1000,\n",
      "        -0.4446,  0.1800, -1.1886,  0.8471, -0.5484, -1.7029, -0.2535, -0.0286,\n",
      "         1.2128, -0.4033,  2.0873,  1.1846, -0.7220, -0.6984, -0.8581, -0.0054,\n",
      "         0.2558, -1.0960,  0.4160,  0.3282, -0.4621, -0.7780,  0.2706, -0.2725,\n",
      "        -0.4773,  1.2636,  0.3878, -0.0492, -1.5415,  0.2287,  0.9904,  0.9204,\n",
      "        -1.1925,  0.4645,  0.3404, -0.1524, -0.5073, -1.0112, -1.6690, -0.7504,\n",
      "         0.8497,  1.1142, -1.6302, -0.2487, -0.1865,  1.7033, -0.8740,  0.4011,\n",
      "        -0.4040,  0.0094,  0.4626,  0.1769, -1.0019, -0.3839,  0.2870, -1.8927,\n",
      "         0.1181,  1.5805, -0.0747,  0.0530, -1.0567, -0.0885, -0.7684, -0.6548,\n",
      "        -0.8156,  0.4568,  0.0609,  0.4350, -0.4085, -0.8899, -0.6338, -1.6243,\n",
      "         0.6539,  0.3071,  0.2140, -0.3226,  0.3615, -0.2384, -1.1142, -0.4122,\n",
      "         0.1026, -0.8625,  0.2809, -1.1912,  1.6659,  0.9913,  0.6064, -0.0044,\n",
      "        -1.5937,  1.2577,  0.8393, -0.8690, -1.1631, -0.0654, -1.6048, -0.1612,\n",
      "        -1.7264, -0.8909, -0.8089, -1.7673,  0.2937, -1.0551, -0.1806,  1.1926,\n",
      "        -0.1650,  1.4575,  0.3186, -0.2004,  1.2739, -0.3049,  1.8466, -0.2369,\n",
      "        -1.1611,  0.4048, -0.7719, -0.9549,  0.2042, -0.6746, -0.3499, -0.2160,\n",
      "        -0.8772,  0.5782,  0.9718,  2.3043, -0.0473,  0.5502,  0.9040,  0.1089,\n",
      "         0.6408, -0.6027, -0.7139, -0.8962,  1.1385, -1.6694, -0.2347, -1.2821,\n",
      "        -1.1654, -0.4584,  0.4595,  0.1401, -1.4371, -1.5660,  0.2138,  0.6419,\n",
      "        -0.2066, -0.2180,  2.8650,  0.8050, -0.1723, -0.6224, -1.0556, -0.7432,\n",
      "        -1.4035,  0.0217, -1.0817, -1.5586, -0.5679, -0.1897, -0.0445, -1.5548,\n",
      "         1.0591,  0.5604, -0.6568, -0.7803, -1.0942,  1.8636,  1.3162, -0.2088,\n",
      "         0.7473,  0.2843, -0.6974, -0.0235, -0.7480, -0.4158,  0.0723, -0.0562,\n",
      "         0.5322,  0.6094, -1.4957,  0.0674,  2.0369,  1.6286,  0.3153,  1.5175,\n",
      "        -0.0265,  0.9406,  0.7995, -0.0992, -0.1685,  1.5488,  0.7992, -0.3007],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "Word: 가격\n",
      "tensor([-8.0965e-01,  1.8518e+00,  7.0028e-01, -9.7737e-01,  1.1395e-01,\n",
      "         8.1721e-01,  1.8472e-01, -1.6783e+00, -9.1599e-01,  9.3096e-01,\n",
      "         3.4165e-01,  5.1518e-01, -6.7325e-01, -1.8944e+00,  2.6670e-01,\n",
      "        -5.0753e-01, -1.0888e+00,  1.7228e-01,  6.5019e-01,  4.2171e-01,\n",
      "         7.4153e-01, -1.4398e+00,  1.4322e+00, -4.2825e-02,  1.0888e-03,\n",
      "        -1.2548e+00, -1.2899e-01,  1.1182e-01, -1.3197e+00,  5.6138e-01,\n",
      "         2.7946e-01,  9.6595e-01,  1.3965e-01,  1.0532e+00,  4.3431e-01,\n",
      "         7.7353e-01, -8.8760e-01,  4.7291e-01,  2.0867e+00, -1.3279e-01,\n",
      "        -1.9776e-01, -1.5983e-01,  8.8798e-01,  2.0015e+00, -9.9080e-01,\n",
      "         3.7029e-01, -6.4019e-01, -1.0480e+00,  1.2524e-01, -3.3436e-01,\n",
      "        -9.7821e-01, -2.8486e+00, -1.4798e-01, -4.5723e-01,  1.3780e+00,\n",
      "         7.9205e-01, -6.8587e-01, -1.5576e-01,  1.1264e-01, -2.3960e+00,\n",
      "         1.5794e+00,  5.0979e-03, -9.8058e-01, -1.1610e+00,  1.5532e+00,\n",
      "         9.1733e-02,  1.3534e+00,  7.0596e-01, -5.3444e-01, -4.7658e-01,\n",
      "         2.0636e-01, -1.1733e+00, -5.1508e-01, -3.0931e-01, -4.1946e-01,\n",
      "         3.4572e-01, -5.8687e-01, -1.6034e+00, -1.1595e+00, -6.1469e-01,\n",
      "        -1.3930e+00, -2.1698e-01,  5.4527e-02, -2.5565e+00,  4.4855e-01,\n",
      "        -1.0519e+00, -3.0263e-01,  2.0952e-01, -5.7367e-01,  1.3690e-01,\n",
      "         1.9352e+00, -2.0027e-02,  1.9303e-01, -5.1098e-01, -4.6199e-01,\n",
      "         2.6107e-01, -3.9752e-01,  2.5428e+00, -1.7225e+00,  1.6051e+00,\n",
      "         1.0206e+00, -1.0391e+00, -3.4299e-01,  5.2178e-01, -8.9704e-01,\n",
      "        -8.4118e-01,  7.5761e-01, -1.4196e+00, -8.5993e-02, -1.2593e+00,\n",
      "        -1.1290e-01,  2.2576e-01, -5.4540e-01,  6.1779e-01,  1.5775e+00,\n",
      "        -9.7427e-01, -5.5002e-01,  4.9793e-01, -1.2230e+00, -5.1931e-01,\n",
      "         2.1633e+00, -9.0222e-01, -7.0338e-01, -9.2751e-01, -3.3058e-01,\n",
      "        -1.6480e+00, -2.2832e-01, -1.2155e-01, -8.7960e-01, -6.4992e-01,\n",
      "         1.3998e+00,  1.7956e-01, -1.0770e-01,  1.0948e+00,  1.9888e-01,\n",
      "         8.2993e-01,  2.3199e+00,  4.7803e-01,  2.9562e-02, -5.5670e-01,\n",
      "         4.7429e-01,  7.0182e-01, -8.2699e-01, -6.6544e-01,  8.4800e-01,\n",
      "         2.2838e-01,  1.2905e+00, -4.4617e-01,  6.3598e-01, -7.1121e-01,\n",
      "        -5.9919e-01,  1.8028e+00,  6.4534e-01,  1.1291e+00, -8.1661e-01,\n",
      "         1.0726e-03, -1.2488e+00,  1.2401e+00, -1.9581e+00,  6.5370e-01,\n",
      "         1.0659e+00,  8.5115e-01,  1.7011e+00,  3.4682e-01,  1.5328e+00,\n",
      "         9.6251e-01,  1.7253e+00, -1.0591e+00, -1.5345e+00, -2.0918e-01,\n",
      "        -3.9503e-01,  3.4039e-01,  9.8129e-01, -9.9683e-01, -2.3404e+00,\n",
      "         6.5583e-01, -8.4204e-01, -1.5520e+00, -1.6055e+00,  1.1070e+00,\n",
      "        -3.6491e-02, -1.1632e-01,  8.8725e-01, -7.8314e-01,  1.5193e-01,\n",
      "         6.1178e-01, -1.1269e-01,  4.8437e-01, -3.4669e-01, -7.0832e-01,\n",
      "        -6.9608e-01, -2.1627e+00, -2.4018e-01, -4.2566e-01, -1.3250e-01,\n",
      "        -5.5337e-01, -6.8013e-02,  1.1942e-01,  5.2750e-02,  1.6676e+00,\n",
      "        -9.0238e-01,  2.2026e-01, -1.2480e+00,  4.2234e-01, -1.4971e-01,\n",
      "         6.1410e-01,  3.3572e-01,  4.5658e-01, -5.6234e-01,  1.0450e+00,\n",
      "         6.0659e-01, -1.1285e+00, -1.6710e-02, -9.6300e-01,  2.6695e-01,\n",
      "        -5.5280e-01, -5.3736e-01,  9.8844e-01, -4.8514e-01,  2.0609e-01,\n",
      "        -1.4276e+00, -3.3616e-01,  6.7304e-01, -1.4876e+00,  1.2799e+00,\n",
      "        -4.5736e-01, -3.6241e-01, -4.4477e-01, -9.8067e-01,  4.0120e-01,\n",
      "        -1.0357e+00,  1.3047e+00, -2.1641e+00,  2.6026e-01,  1.3470e+00,\n",
      "         2.6431e-01,  9.2605e-01, -9.1644e-01,  8.6914e-01, -1.5532e+00,\n",
      "         1.0205e+00,  1.1146e+00,  6.0641e-02,  8.7321e-02,  1.7003e+00,\n",
      "         2.3906e-01,  8.5954e-01, -9.2422e-01, -4.6875e-02, -4.9152e-01,\n",
      "        -1.7092e-01,  4.2116e-02,  2.1851e-01, -1.0242e+00,  4.1510e-01,\n",
      "         2.1404e-02], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "for word in test_words:\n",
    "    input_id = torch.LongTensor([w2i[word]]).to(device)\n",
    "    emb = cbow.embedding(input_id)\n",
    "    \n",
    "    print(f\"Word: {word}\")\n",
    "    print(emb.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: 음식\n",
      "tensor(2.7317, grad_fn=<UnbindBackward0>)\n",
      "Word: 맛\n",
      "tensor(2.5442, grad_fn=<UnbindBackward0>)\n",
      "Word: 서비스\n",
      "tensor(3.7710, grad_fn=<UnbindBackward0>)\n",
      "Word: 위생\n",
      "tensor(2.9354, grad_fn=<UnbindBackward0>)\n",
      "Word: 가격\n",
      "tensor(3.1709, grad_fn=<UnbindBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for word in test_words:\n",
    "    input_id = torch.LongTensor([w2i[word]]).to(device)\n",
    "    emb = skipgram.embedding(input_id)\n",
    "    \n",
    "    print(f\"Word: {word}\")\n",
    "    print(max(emb.squeeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['음식', '맛', '서비스', '위생', '가격']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(word, top_k=5):\n",
    "    input_id = torch.LongTensor([w2i[word]]).to(device)\n",
    "    input_emb = skipgram.embedding(input_id)\n",
    "    score = torch.matmul(input_emb, skipgram.embedding.weight.transpose(1, 0)).view(-1)\n",
    "    \n",
    "    _, top_k_ids = torch.topk(score, top_k)\n",
    "    return [i2w[word_id.item()] for word_id in top_k_ids][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['있다', '완전', '정말', '더']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('가격')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6) Word2Vec 시각화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# matplotlib 패키지 한글 깨짐 처리\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "# plt.rc('font', family='AppleGothic) # mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Skip-Gram 결과**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_weight = pca.fit_transform(skipgram.embedding.weight.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 8722 (\\N{MINUS SIGN}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "for word_id, (x_coordinate, y_coordinate) in enumerate(pc_weight):\n",
    "    plt.scatter(x_coordinate, y_coordinate, color=\"blue\")\n",
    "    plt.annotate(i2w[word_id], (x_coordinate, y_coordinate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **CBOW 결과**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_weight = pca.fit_transform(cbow.embedding.weight.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 8722 (\\N{MINUS SIGN}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "for word_id, (x_coordinate, y_coordinate) in enumerate(pc_weight):\n",
    "    plt.scatter(x_coordinate, y_coordinate, color=\"blue\")\n",
    "    plt.annotate(i2w[word_id], (x_coordinate, y_coordinate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. RNNs with Attention**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'3. Deep Learning'에서 배운 Seq2Seq와 Attention에 대해서 간략하게 복습 및 보충하겠습니다. 자세한 건 '3. Deep Learning'을 참고하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.1 Sequence to Sequecne**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![4-4-1](_image/4-4-1.PNG)\n",
    "\n",
    "위 그림을 보면 알 수 있듯이 시퀀스 투 시퀀스는 입력을 받는 인코더와 출력하는 디코더로  이루어져있습니다. 그리고 인코더와 디코더는 각각의 RNN, LSTM, GRU 중 하나로 구성되어 있습니다. \n",
    "\n",
    "문장의 의미를 더욱 정확하게 파악하기 위해서 양방향 RNN을 사용할 수도 있습니다. 문장을 순방향으로 읽는 RNN과 역방향으로 읽는 RNN을 이용해 나온 최종 은닉 상태를 합하여 사용합니다. 이때 디코더는 순방향으로 하나씩 출력해야하므로 디코더에선 양방향을 사용하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.2 Attention**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seq2Seq는 큰 문제점을 하나 가지고 있었습니다. 마지막 은닉 상태가 문장의 모든 의미를 함축해야 하는데 문장의 길이가 길어질수록 그것이 불가능하다는 것입니다. 즉, 앞쪽의 의미는 잊어버리게 됩니다. 이를 방지하기 위해 우리는 Attention이란 방법을 도입했었습니다.\n",
    "\n",
    "간단하게 말하면 인코더에서 구한 은닉 상태의 결과들을 디코더가 필요한 결과들을 위주로 사용하는 방법이었습니다. 예를 들어 곱셈 기반의 attention을 보겠습니다.\n",
    "\n",
    "![4-4-2](_image/4-4-2.PNG)\n",
    "\n",
    "먼저 인코더에서 구해진 은닉 상태를 다 저장합니다. 이제 디코더에서 은닉 상태를 거칠 때, 인코더의 은닉 상태들과 내적으로 유사도를 구하여 소프트맥스합니다. 그리고 그 비율을 각각 인코더의 은닉 상태에 곱하여 합한 뒤, 구해진 값을 디코더의 추가 입력값으로 사용합니다.\n",
    "\n",
    "예를 들어 기계 번역에선 문장에서 나와야 할 품사가 동일할 때 가중치가 더 높게 측정되는 것입니다. \n",
    "\n",
    "단어마다 어떤 단어에 가중치가 주어졌는지 그래프로 그려보면 다음과 같습니다. 가로축은 input, 세로축은 output 단어들입니다.\n",
    "\n",
    "![4-4-3](_image/4-4-3.PNG)\n",
    "\n",
    "(a)를 보면 중간에 어순이 바뀐 것을 확인할 수 있습니다. 또한 (b)를 보면 어떤 언어에선 하나의 단어가 다른 언어에선 여러 단어로 표현되는 것을 확인할 수 있습니다. \n",
    "\n",
    "이 이외도 다른 attention 방법이 있습니다. 예를 들어 concat 기반의 어텐션이 있습니다. 이는 인코더의 각각 은닉 상태들을 디코더의 은닉 상태와 concat하여 fc를 거치게 하고 하나의 노드를 출력으로 받습니다. 모든 인코더의 은닉 상태에게 적용하여 나온 값들을 가중치로 사용하여 적용하는 방법입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습1. Seq2Seq with Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 실습은 Seq2Seq 모델을 구현하고 attention 모듈을 추가해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) Seq2Seq with toy example**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **데이터 전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "src_data를 trg_data로 바꾸는 번역 task를 수행하기 위한 sample data를 준비합니다.\n",
    "\n",
    "전체 단어 수는 100개이고 다음과 같이 pad token, start, token, end token의 id도 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 100\n",
    "pad_id = 0\n",
    "sos_id = 1 # <sos> : start of sentence\n",
    "eos_id = 2 # <eos> : end of sentnece\n",
    "\n",
    "src_data = [\n",
    "    [3, 77, 56, 26, 3, 55, 12, 36, 31],\n",
    "    [58, 20, 65, 46, 26, 10, 76, 44],\n",
    "    [58, 17, 8],\n",
    "    [59],\n",
    "    [29, 3, 52, 74, 73, 51, 39, 75, 19],\n",
    "    [41, 55, 77, 21, 52, 92, 97, 69, 54, 14, 93],\n",
    "    [39, 47, 96, 68, 55, 16, 90, 45, 89, 84, 19, 22, 32, 99, 5],\n",
    "    [75, 34, 17, 3, 86, 88],\n",
    "    [63, 39, 5, 35, 67, 56, 68, 89, 55, 66],\n",
    "    [12, 40, 69, 39, 49]\n",
    "]\n",
    "\n",
    "trg_data = [\n",
    "    [75, 13, 22, 77, 89, 21, 13, 86, 95],\n",
    "    [79, 14, 91, 41, 32, 79, 88, 34, 8, 68, 32, 77, 58, 7, 9, 87],\n",
    "    [85, 8, 50, 30],\n",
    "    [47, 30],\n",
    "    [8, 85, 87, 77, 47, 21, 23, 98, 83, 4, 47, 97, 40, 43, 70, 8, 65, 71, 69, 88],\n",
    "    [32, 37, 31, 77, 38, 93, 45, 74, 47, 54, 31, 18],\n",
    "    [37, 14, 49, 24, 93, 37, 54, 51, 39, 84],\n",
    "    [16, 98, 68, 57, 55, 46, 66, 85, 18],\n",
    "    [20, 70, 14, 6, 58, 90, 30, 17, 91, 18, 90],\n",
    "    [37, 93, 98, 13, 45, 28, 89, 72, 70]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# target data의 각 문장의 시작과 끝에 <sos> token id와 <eos> token id를 추가합니다.\n",
    "trg_data = [[sos_id] + seq + [eos_id] for seq in tqdm(trg_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 문장의 길이를 동일하게 맞춰주기 위해 <pad> token id를 추가하는 padding 함수를 정의합니다.\n",
    "def padding(data):\n",
    "    max_len = len(max(data, key=len))\n",
    "    print(f\"Maximum sequence length: {max_len}\")\n",
    "    \n",
    "    valid_lens = []\n",
    "    for i, seq in enumerate(tqdm(data)):\n",
    "        valid_lens.append(len(seq))\n",
    "        if len(seq) < max_len:\n",
    "            data[i] = seq + [pad_id] * (max_len - len(seq))\n",
    "    \n",
    "    return data, valid_lens, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10017.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "src_data, src_lens, src_max_len = padding(src_data)\n",
    "trg_data, trg_lens, trg_max_len = padding(trg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 15])\n",
      "torch.Size([10])\n",
      "torch.Size([10, 22])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# B: batch size,\n",
    "# S_L: source maximum sequence length\n",
    "# T_L: target maximum sequence length\n",
    "\n",
    "src_batch = torch.LongTensor(src_data) # (B, S_L)\n",
    "src_batch_lens = torch.LongTensor(src_lens) # (B)\n",
    "trg_batch = torch.LongTensor(trg_data) # (B, T_L)\n",
    "trg_batch_lens = torch.LongTensor(trg_lens) # (B)\n",
    "\n",
    "print(src_batch.shape)\n",
    "print(src_batch_lens.shape)\n",
    "print(trg_batch.shape)\n",
    "print(trg_batch_lens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[39, 47, 96, 68, 55, 16, 90, 45, 89, 84, 19, 22, 32, 99,  5],\n",
      "        [41, 55, 77, 21, 52, 92, 97, 69, 54, 14, 93,  0,  0,  0,  0],\n",
      "        [63, 39,  5, 35, 67, 56, 68, 89, 55, 66,  0,  0,  0,  0,  0],\n",
      "        [ 3, 77, 56, 26,  3, 55, 12, 36, 31,  0,  0,  0,  0,  0,  0],\n",
      "        [29,  3, 52, 74, 73, 51, 39, 75, 19,  0,  0,  0,  0,  0,  0],\n",
      "        [58, 20, 65, 46, 26, 10, 76, 44,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [75, 34, 17,  3, 86, 88,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [12, 40, 69, 39, 49,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [58, 17,  8,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [59,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([15, 11, 10,  9,  9,  8,  6,  5,  3,  1])\n",
      "tensor([[ 1, 37, 14, 49, 24, 93, 37, 54, 51, 39, 84,  2,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0],\n",
      "        [ 1, 32, 37, 31, 77, 38, 93, 45, 74, 47, 54, 31, 18,  2,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0],\n",
      "        [ 1, 20, 70, 14,  6, 58, 90, 30, 17, 91, 18, 90,  2,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0],\n",
      "        [ 1, 75, 13, 22, 77, 89, 21, 13, 86, 95,  2,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0],\n",
      "        [ 1,  8, 85, 87, 77, 47, 21, 23, 98, 83,  4, 47, 97, 40, 43, 70,  8, 65,\n",
      "         71, 69, 88,  2],\n",
      "        [ 1, 79, 14, 91, 41, 32, 79, 88, 34,  8, 68, 32, 77, 58,  7,  9, 87,  2,\n",
      "          0,  0,  0,  0],\n",
      "        [ 1, 16, 98, 68, 57, 55, 46, 66, 85, 18,  2,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0],\n",
      "        [ 1, 37, 93, 98, 13, 45, 28, 89, 72, 70,  2,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0],\n",
      "        [ 1, 85,  8, 50, 30,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0],\n",
      "        [ 1, 47, 30,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0]])\n",
      "tensor([12, 14, 13, 11, 22, 18, 11, 11,  6,  4])\n"
     ]
    }
   ],
   "source": [
    "src_batch_lens, sorted_idx = src_batch_lens.sort(descending=True)\n",
    "src_batch = src_batch[sorted_idx]\n",
    "trg_batch = trg_batch[sorted_idx]\n",
    "trg_batch_lens = trg_batch_lens[sorted_idx]\n",
    "\n",
    "print(src_batch)\n",
    "print(src_batch_lens)\n",
    "print(trg_batch)\n",
    "print(trg_batch_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder 구현\n",
    "- Embedding layer, output layer, GRU cell을 포함한 encoder 모듈을 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 256\n",
    "hidden_size = 512\n",
    "num_layers = 2\n",
    "num_dirs = 2 # 2 if bidirectional=True otherwise 1\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=embedding_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True if num_dirs > 1 else False,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.linear = nn.Linear(num_dirs * hidden_size, hidden_size)\n",
    "    \n",
    "    def forward(self, batch, batch_lens): # batch: (B, S_L), batch_lens: (B)\n",
    "        # d_w: word embedding size\n",
    "        batch_emb = self.embedding(batch) # (B, S_L, d_w)\n",
    "        batch_emb = batch_emb.transpose(0, 1) # (S_L, B, d_w)\n",
    "        \n",
    "        packed_input = pack_padded_sequence(batch_emb, batch_lens)\n",
    "        \n",
    "        h_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size)) # (num_dirs*num_layers, B, d_h) = (4, B, d_h)\n",
    "        packed_outputs, h_n = self.gru(packed_input, h_0) # h_n: (4, B, d_h)\n",
    "        outputs = pad_packed_sequence(packed_outputs)[0] # outputs: (S_L, B, 2d_h)\n",
    "        outputs = torch.tanh(self.linear(outputs)) # (S_L, B, d_h)\n",
    "        \n",
    "        forward_hidden = h_n[-2, :, :]\n",
    "        backward_hidden = h_n[-1, :, :]\n",
    "        hidden = torch.tanh(self.linear(torch.cat((forward_hidden, backward_hidden), dim=-1))).unsqueeze(0) # (1, B, d_h)\n",
    "        \n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) Dot-product Attention 구현**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attention 중 대표적 형태인 dot-product attention을 구현하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, decoder_hidden, encoder_outputs): # (1, B, d_h), (S_L, B, d_h)\n",
    "        query = decoder_hidden.squeeze(0) # (B, d_h)\n",
    "        key = encoder_outputs.transpose(0, 1) # (B, S_L, d_h)\n",
    "        \n",
    "        energy = torch.sum(torch.mul(key, query.unsqueeze(1)), dim=-1) # (B, S_L)\n",
    "        \n",
    "        attn_scores = F.softmax(energy, dim=-1) # (B, S_L)\n",
    "        attn_values = torch.sum(torch.mul(encoder_outputs.transpose(0, 1), attn_scores.unsqueeze(2)), dim=1) # (B, d_h)\n",
    "        \n",
    "        return attn_values, attn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_attn = DotAttention()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 attention 모듈을 가지는 decoder 클래스를 구현하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, attention):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.attention = attention\n",
    "        self.rnn = nn.GRU(\n",
    "            embedding_size,\n",
    "            hidden_size,\n",
    "        )\n",
    "        self.output_linear = nn.Linear(2 * hidden_size, vocab_size)\n",
    "    \n",
    "    def forward(self, batch, encoder_outputs, hidden):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            batch : (B)\n",
    "            encoder_outputs: (L, B, d_h)\n",
    "            hidden: (1, B, d_h)\n",
    "        \"\"\"\n",
    "        batch_emb = self.embedding(batch) # (B, d_w)\n",
    "        batch_emb = batch_emb.unsqueeze(0) # (1, B, d_w)\n",
    "        \n",
    "        outputs, hidden = self.rnn(batch_emb, hidden) # (1, B, d_h), (1, B, d_h)\n",
    "        attn_values, attn_scores = self.attention(hidden, encoder_outputs) # (B, d_h), (B, S_L)\n",
    "        concat_outputs = torch.cat((outputs, attn_values.unsqueeze(0)), dim=-1) # (1, B, 2d_h)\n",
    "        \n",
    "        return self.output_linear(concat_outputs).squeeze(0), hidden # (B, V), (1, B, d_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(dot_attn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) Seq2Seq 모델 구축**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, src_batch, src_batch_lens, trg_batch, teacher_forcing_prob=0.5):\n",
    "        # src_batch: (B, S_L), src_batch_lens: (B), trg_batch: (B, T_L)\n",
    "        \n",
    "        # encoder_outputs: (S_L, B, d_h), hidden: (1, B, d_h)\n",
    "        encoder_outputs, hidden = self.encoder(src_batch, src_batch_lens) \n",
    "        \n",
    "        input_ids = trg_batch[:, 0] # (B)\n",
    "        batch_size = src_batch.shape[0]\n",
    "        outputs = torch.zeros(trg_max_len, batch_size, vocab_size) # (T_L, B, V)\n",
    "        \n",
    "        for t in range(1, trg_max_len):\n",
    "            # decoder_outputs: (B, V), hidden: (1, B, d_h)\n",
    "            decoder_outputs, hidden = self.decoder(input_ids, encoder_outputs, hidden)\n",
    "            \n",
    "            outputs[t] = decoder_outputs\n",
    "            _, top_ids = torch.max(decoder_outputs, dim=-1) # top_ids: (B)\n",
    "            \n",
    "            input_ids = trg_batch[:, t] if random.random() > teacher_forcing_prob else top_ids\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq = Seq2Seq(encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4) 모델 사용하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0476, -0.0706, -0.0480,  ..., -0.0360, -0.1264, -0.1105],\n",
      "         [-0.0360, -0.0926, -0.0160,  ..., -0.0398, -0.1155, -0.0975],\n",
      "         [-0.0370, -0.0307, -0.0097,  ..., -0.0366, -0.1466, -0.0853],\n",
      "         ...,\n",
      "         [-0.0619, -0.0664, -0.0315,  ..., -0.0459, -0.1248, -0.0681],\n",
      "         [-0.0397, -0.0941, -0.0628,  ..., -0.0383, -0.1492, -0.1058],\n",
      "         [-0.0464, -0.0722, -0.0397,  ..., -0.0575, -0.1219, -0.1070]],\n",
      "\n",
      "        [[ 0.0566,  0.0247,  0.0921,  ..., -0.0740, -0.1147, -0.0941],\n",
      "         [ 0.1006, -0.1363, -0.0872,  ..., -0.0866, -0.0738, -0.0402],\n",
      "         [ 0.0830, -0.0025, -0.0901,  ..., -0.0033, -0.0938, -0.1105],\n",
      "         ...,\n",
      "         [ 0.0448,  0.0354,  0.0873,  ..., -0.0744, -0.1027, -0.0705],\n",
      "         [-0.0363,  0.0505, -0.0638,  ..., -0.1132, -0.0789, -0.0805],\n",
      "         [ 0.0252, -0.1121, -0.0074,  ..., -0.0606, -0.1374, -0.0013]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0445,  0.1121,  0.1322,  ...,  0.0137, -0.0070, -0.2259],\n",
      "         [-0.0700,  0.0950,  0.0992,  ...,  0.0074,  0.0204, -0.2266],\n",
      "         [-0.0444,  0.1465,  0.1398,  ...,  0.0291,  0.0215, -0.2402],\n",
      "         ...,\n",
      "         [-0.0361,  0.1392,  0.1096,  ..., -0.0003,  0.0096, -0.2335],\n",
      "         [-0.0426,  0.1305,  0.1159,  ...,  0.0084,  0.0080, -0.2614],\n",
      "         [-0.0423,  0.1394,  0.1214,  ...,  0.0130,  0.0209, -0.2602]],\n",
      "\n",
      "        [[-0.0428,  0.1019,  0.1194,  ...,  0.0227, -0.0052, -0.2364],\n",
      "         [-0.0614,  0.0934,  0.1016,  ...,  0.0208,  0.0184, -0.2404],\n",
      "         [-0.0415,  0.1373,  0.1271,  ...,  0.0379,  0.0218, -0.2524],\n",
      "         ...,\n",
      "         [-0.0352,  0.1294,  0.0969,  ...,  0.0111,  0.0116, -0.2437],\n",
      "         [-0.0419,  0.1203,  0.1024,  ...,  0.0195,  0.0111, -0.2694],\n",
      "         [-0.0418,  0.1289,  0.1078,  ...,  0.0239,  0.0239, -0.2681]],\n",
      "\n",
      "        [[-0.0415,  0.0959,  0.1102,  ...,  0.0285, -0.0038, -0.2436],\n",
      "         [-0.0550,  0.0933,  0.1002,  ...,  0.0286,  0.0181, -0.2503],\n",
      "         [-0.0393,  0.1321,  0.1178,  ...,  0.0433,  0.0223, -0.2603],\n",
      "         ...,\n",
      "         [-0.0346,  0.1234,  0.0878,  ...,  0.0185,  0.0131, -0.2507],\n",
      "         [-0.0416,  0.1140,  0.0929,  ...,  0.0266,  0.0134, -0.2748],\n",
      "         [-0.0415,  0.1224,  0.0984,  ...,  0.0309,  0.0260, -0.2736]]],\n",
      "       grad_fn=<CopySlices>)\n",
      "torch.Size([22, 10, 100])\n"
     ]
    }
   ],
   "source": [
    "# V: vocab size\n",
    "outputs = seq2seq(src_batch, src_batch_lens, trg_batch) # (T_L, B, V)\n",
    "print(outputs)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sent = [4, 10, 88, 46, 72, 34, 14, 51]\n",
    "sample_len = len(sample_sent)\n",
    "\n",
    "sample_batch = torch.LongTensor(sample_sent).unsqueeze(0) # (1, L)\n",
    "sample_batch_len = torch.LongTensor([sample_len]) # (1)\n",
    "\n",
    "encoder_output, hidden = seq2seq.encoder(sample_batch, sample_batch_len) # hidden: (4, 1, d_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_id = torch.LongTensor([sos_id]) # (1)\n",
    "output = []\n",
    "\n",
    "for t in range(1, trg_max_len):\n",
    "    # decoder_output: (1, V), hidden: (4, 1, d_h)\n",
    "    decoder_output, hidden = seq2seq.decoder(input_id, encoder_output, hidden)\n",
    "    \n",
    "    _, top_id = torch.max(decoder_output, dim=-1) # top_ids: (1)\n",
    "    \n",
    "    if top_id == eos_id:\n",
    "        break\n",
    "    else:\n",
    "        output += top_id.tolist()\n",
    "        input_id = top_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31,\n",
       " 80,\n",
       " 84,\n",
       " 40,\n",
       " 95,\n",
       " 40,\n",
       " 88,\n",
       " 40,\n",
       " 65,\n",
       " 34,\n",
       " 73,\n",
       " 28,\n",
       " 10,\n",
       " 24,\n",
       " 91,\n",
       " 26,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5) Concat Attention 구현**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bahdanau Attention이라고도 불리는 Concat Attention을 구현해보겠습니다.\n",
    "- self.w: concat한 query와 key 벡터를 1차적으로 linear transformation.\n",
    "- self.v: attention logit 값을 계산."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.w = nn.Linear(2 * hidden_size, hidden_size, bias=False)\n",
    "        self.v = nn.Linear(hidden_size, 1, bias=False)\n",
    "    \n",
    "    def forward(self, decoder_hidden, encoder_outputs): # (1, B, d_h), (S_L, B, d_h)\n",
    "        src_max_len = encoder_outputs.shape[0]\n",
    "        \n",
    "        decoder_hidden = decoder_hidden.transpose(0, 1).repeat(1, src_max_len, 1) # (B, S_L, d_h)\n",
    "        encoder_outputs = encoder_outputs.transpose(0, 1) # (B, S_L, d_h)\n",
    "        \n",
    "        concat_hiddens = torch.cat((decoder_hidden, encoder_outputs), dim=2) # (B, S_L, 2d_h)\n",
    "        energy = torch.tanh(self.w(concat_hiddens)) # (B, S_L, d_h)\n",
    "        \n",
    "        attn_scores = F.softmax(self.v(energy), dim=1) # (B, S_L, 1)\n",
    "        attn_values = torch.sum(torch.mul(encoder_outputs, attn_scores), dim=1) # (B, d_h)\n",
    "        \n",
    "        return attn_values, attn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_attn = ConcatAttention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, attention):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.attention = attention\n",
    "        self.rnn = nn.GRU(\n",
    "            embedding_size + hidden_size,\n",
    "            hidden_size,\n",
    "        )\n",
    "        self.output_linear = nn.Linear(hidden_size, vocab_size)\n",
    "    \n",
    "    def forward(self, batch, encoder_outputs, hidden): \n",
    "        # batch: (B), encoder_outputs: (S_L, B, d_h), hidden: (1, B, d_h)\n",
    "        batch_emb = self.embedding(batch) # (B, d_w)\n",
    "        batch_emb = batch_emb.unsqueeze(0) # (1, B, d_w)\n",
    "        \n",
    "        attn_values, attn_scores = self.attention(hidden, encoder_outputs) # (B, d_h), (B, S_L)\n",
    "        concat_emb = torch.cat((batch_emb, attn_values.unsqueeze(0)), dim=-1) # (1, B, d_w + d_h)\n",
    "        outputs, hidden = self.rnn(concat_emb, hidden) # (1, B, d_h), (1, B, d_h)\n",
    "        \n",
    "        return self.output_linear(outputs).squeeze(0), hidden # (B, V), (1, B, d_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(concat_attn)\n",
    "seq2seq = Seq2Seq(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.1234, -0.0919,  0.0954,  ...,  0.0174, -0.0957,  0.0635],\n",
      "         [ 0.0748, -0.0693,  0.0969,  ...,  0.0345, -0.0742,  0.0858],\n",
      "         [ 0.0761, -0.0433,  0.0738,  ..., -0.0406, -0.1071,  0.0789],\n",
      "         ...,\n",
      "         [ 0.0550, -0.0180,  0.0806,  ..., -0.0030, -0.0848,  0.1004],\n",
      "         [ 0.0797, -0.0439,  0.1005,  ...,  0.0147, -0.0971,  0.0638],\n",
      "         [ 0.0514, -0.0450,  0.1144,  ...,  0.0259, -0.1010,  0.0609]],\n",
      "\n",
      "        [[-0.0212,  0.0125,  0.0370,  ..., -0.0458, -0.0731, -0.0334],\n",
      "         [-0.0589,  0.0125,  0.0457,  ..., -0.0460, -0.0658, -0.0264],\n",
      "         [-0.0607,  0.0353,  0.0419,  ..., -0.0753, -0.0857, -0.0265],\n",
      "         ...,\n",
      "         [-0.0694,  0.0475,  0.0353,  ..., -0.0655, -0.0614, -0.0113],\n",
      "         [-0.0673,  0.0363,  0.0507,  ..., -0.0583, -0.0700, -0.0386],\n",
      "         [-0.0786,  0.0351,  0.0567,  ..., -0.0538, -0.0697, -0.0344]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1755,  0.1572, -0.1401,  ...,  0.0178, -0.1422,  0.0904],\n",
      "         [-0.0350, -0.2412, -0.0698,  ..., -0.0938,  0.0814, -0.0316],\n",
      "         [-0.2355,  0.0217, -0.1771,  ..., -0.1213, -0.0469, -0.1071],\n",
      "         ...,\n",
      "         [-0.2572,  0.1105, -0.0361,  ..., -0.0130,  0.1346, -0.1780],\n",
      "         [-0.0286,  0.0276,  0.2028,  ...,  0.1104, -0.1056, -0.0120],\n",
      "         [-0.1494,  0.0849,  0.1229,  ..., -0.1065,  0.0329, -0.0645]],\n",
      "\n",
      "        [[-0.0428,  0.1872, -0.1489,  ..., -0.0396, -0.0277, -0.0952],\n",
      "         [-0.0054, -0.0692, -0.0783,  ..., -0.1333,  0.0268, -0.1651],\n",
      "         [-0.1482,  0.1468, -0.1828,  ..., -0.1198, -0.0458, -0.2241],\n",
      "         ...,\n",
      "         [-0.1111,  0.1853, -0.0878,  ...,  0.0039,  0.0613, -0.1889],\n",
      "         [-0.0183,  0.0920,  0.0304,  ...,  0.0139,  0.0010, -0.1439],\n",
      "         [-0.0888,  0.1568, -0.0254,  ..., -0.1437,  0.0029, -0.1730]],\n",
      "\n",
      "        [[-0.0043,  0.1780, -0.1649,  ..., -0.0872,  0.0090, -0.1809],\n",
      "         [-0.0138,  0.0235, -0.1073,  ..., -0.1672,  0.0121, -0.2183],\n",
      "         [-0.0945,  0.1763, -0.1795,  ..., -0.1487, -0.0348, -0.2644],\n",
      "         ...,\n",
      "         [-0.0561,  0.1961, -0.1283,  ..., -0.0613,  0.0306, -0.2075],\n",
      "         [-0.0152,  0.1272, -0.0532,  ..., -0.0618,  0.0340, -0.2008],\n",
      "         [-0.0664,  0.1772, -0.0980,  ..., -0.1714, -0.0078, -0.2245]]],\n",
      "       grad_fn=<CopySlices>)\n",
      "torch.Size([22, 10, 100])\n"
     ]
    }
   ],
   "source": [
    "outputs = seq2seq(src_batch, src_batch_lens, trg_batch)\n",
    "print(outputs)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5. Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자연어 처리 과정의 맥락을 간단하게 살펴보면 다음과 같습니다.\n",
    "\n",
    "$$raw\\;data \\overset{pre-processing}{\\longrightarrow} pre-processed\\;data \\overset{tokenization}{\\longrightarrow} token \\; idx \\overset{input}{\\longrightarrow} output \\overset{post-processing}{\\longrightarrow} result$$\n",
    "\n",
    "#### **Normalization**\n",
    "preprocessing 과정이며 일반적으론 특정 범위에 값이 모두 들어가도록 처리하는 일련의 과정을 말합니다. nlp에선 입력받은 raw data를 가공하는 것을 말합니다. 예를 들어 문장의 좌우 공백 제거, utf-8로 변환, 온점을 문장과 뗴어놓기 등 필요에 따라 다양한 normalization을 할 수 있습니다. \n",
    "\n",
    "#### **Pre-tokenization**\n",
    "normalization을 거쳐도 바로 tokenization을 진행하기엔 무리가 있습니다. 특히 한국어는 띄어쓰기만으로 전처리를 해도 tokenization이 불가능하기에 문장을 더 작은 객체들로 나눠주는 pre-tokenization을 거쳐야합니다. \n",
    "\n",
    "#### **Tokenization**\n",
    "이제 전처리가 모두 끝난 객체(단어)들에 인덱싱하여 token으로 만들어 저장합니다. 이에 관련해선 이후 자세하게 배웁니다.\n",
    "\n",
    "#### **Post-processing**\n",
    "모델에 들어가 output이 나오면 이것을 우리가 받을 결과로 후처리하여 결과를 얻게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.1 Normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization은 크게 **Cleaning**과 **Normalization**으로 이루어집니다. Cleaning은 noise를 제거하는 것이고 Normalization은 단어들을 정규화하는 것입니다. 위에서 이야기했듯 정규화하는 방법과 종류는 다양합니다. \n",
    "\n",
    "#### **Cased / Uncased**\n",
    "Cased / Uncased는 대소문자를 구분할 지, 구분하지 않을지를 결정합니다. uncased를 사용해 대소문자 구분을 하지 않으면 단어의 수가 줄어들어 메모리를 확보할 수 있으나 자칫 여러 의미가 하나의 단어로 정의되어 성능이 떨어질 수 있습니다.\n",
    "\n",
    "하지만 현재 여러 언어들을 입력받아도 동작이 잘 되도록 하는 연구가 트렌드이고 단어가 많아질수록 사전의 비중이 너무 커져 막상 파라미터의 비중이 줄어드는 등의 이유로 uncased를 많이 사용합니다. 또한 두 개의 성능이 눈에 띄게 크기 않는 이유도 있습니다. 물론 어떤 목적이냐에 따라 cased가 더 효과적일 수도 있습니다. 그렇기에 두 개의 경우를 모두 확인하고 더 좋은 것을 사용하는 것이 일반적입니다.\n",
    "\n",
    "\n",
    "#### **Stemming, Lemmatization**\n",
    "Stemming은 단어들을 원형으로 바꿔주는 것을 의미합니다. 예를 들어 '먹었다'라는 과거형이 들어오면 '먹다'라는 일반형으로 바꿔준느 것입니다. 특별한 필요가 있을 때 사용하지만 대체적으로 사용하지 않습니다. 인위적으로 data를 바꾸는 것이 새로운 noise를 만들고 성능을 저하시키기 때문입니다.\n",
    "\n",
    "\n",
    "#### **불필요한 단어 제거**\n",
    "관심이 없는 단어이거나 의미가 없는 빈칸, 개별적 문자로 채워진 것들을 제거합니다.\n",
    "\n",
    "\n",
    "#### **Regular expression**\n",
    "개인 정보 등 데이터에서 공개되면 안 되는 것이 있을 때, 그것을 가리거나 제거하는 것을 말합니다. 예를 들어 신상정보가 있다면 그것을 x로 표시하거나 빈칸으로 대체하는 것을 말합니다. 이 역시 필요할 때만 사용합니다. \n",
    "\n",
    "대체적으로 파이썬의 re 패키지를 이용해 정규식으로 regular expression을 수행합니다. re 패키지를 사용할 때, 먼저 re.compile()을 사용하면 속도나 성능을 조금 끌어올릴 수 있습니다. (다른 re.함수들이 시작할 때마다 compile을 불러오지 않아도 됨으로) 다른 방법으로 NLTK도 있으나 거의 쓰이지 않는 추세입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.2 Pre-tokenization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토큰화 작업 전 데이터를 가공할 땐, 기본적으로 특수 문자 제거와 공백에 따른 분리를 목표로 합니다. 물론 상황에 따라 안 하거나 다르게 할 수 있습니다. 예를 들어 aren't를 are not으로 바꾸는 것입니다. \n",
    "\n",
    "한국어의 경우 공백만으로 token을 나눌 수 없습니다. 그렇기에 띄어쓰기를 고치고 형태소 분석기를 사용하여 토큰화 전처리를 합니다. 지도학습 기반의 KoNLPy, Khaiii와 비지도학습 기반의 soynlp가 있습니다. 간단하게 여러 text 전처리 툴을 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **0) Regular Expression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규식 표현은 nlp에서 기본적으로 데이터 가공할 때 사용됩니다. \n",
    "\n",
    "> Reference: https://wikidocs.net/21703"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". 기호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 한 개의 문자를 나타내는 .\n",
    "r = re.compile(\"a.c\")\n",
    "r.search(\"ab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 3), match='abc'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "? 기호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(1, 2), match='c'>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ? 앞의 문자가 존재할 수도 있고, 존재하지 않을 수도 있는 경우\n",
    "r = re.compile(\"a?c\")\n",
    "r.search(\"bc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 2), match='ac'>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 존재 하는 경우의 매칭\n",
    "r.search(\"ac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(2, 3), match='c'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 존재하지 않는 경우의 매칭\n",
    "r.search(\"abc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\* 기호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *은 바로 앞의 문자가 0개 이상일 경우\n",
    "r = re.compile(\"ab*c\") # b가 하나도 없거나, 여러 개인 경우\n",
    "r.search(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 2), match='ac'>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"ac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 3), match='abc'>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 6), match='abbbbc'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abbbbc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\+ 기호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# + 앞의 문자가 최소 1개 이상 있을 경우\n",
    "r = re.compile(\"ab+c\")\n",
    "r.search(\"ac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 3), match='abc'>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 5), match='abbbc'>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abbbc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ 기호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^ 시작되는 글자를 지정함\n",
    "r = re.compile(\"^a\")\n",
    "r.search(\"bbc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 1), match='a'>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"ab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{숫자} 기호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞 문자를 해당 숫자만큼 반복해야 함.\n",
    "r = re.compile(\"ab{2}c\")\n",
    "r.search(\"ac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.search(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 4), match='abbc'>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abbc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{숫자1, 숫자2} 기호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞 문자를 숫자1 ~ 숫자2 만큼 반복해야 함\n",
    "r = re.compile(\"ab{2,8}c\") # 띄어쓰기 하면 안 됨\n",
    "r.search(\"ac\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.search(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 4), match='abbc'>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abbc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 10), match='abbbbbbbbc'>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abbbbbbbbc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.search(\"abbbbbbbbbc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{숫자,} 기호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞 문자를 숫자 이상만큼 반복해야 함\n",
    "r = re.compile(\"a{2,}bc\")\n",
    "r.search(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 4), match='aabc'>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"aabc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[] 기호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [] 안에 있는 문자들 중 한 개의 문자와 매치\n",
    "# 범위를 지정할 수도 있음. 예) a-z, A-Z, 0-9\n",
    "r = re.compile('[abc]')\n",
    "r.search(\"dd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 1), match='a'>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 1), match='a'>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"adb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[^문자] 기호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^ 기호 뒤에 붙은 문자들을 제외한 모든 문자를 매치함\n",
    "r = re.compile(\"[^abc]\") # abc를 제외한 모든 문자\n",
    "r.search(\"ab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(3, 4), match='d'>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(3, 4), match='e'>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abcedf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) KoNLPy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[KoNLPy](https://konlpy.org/en/latest/)는 Hannanum, Kkma, Komoran, Mecab, Okt 등 다양한 형태소 분석기를 제공합니다. 그리고 형태소로 나누는 함수, 명사만 뽑아내는 함수, 형태소와 묶어서 분리하는 함수 등 다양한 함수들이 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['환영', '하', 'ㅂ니다', '!', '자연어', '처리', '수업', '은', '재미있', '게', '듣', '고', '계시', 'ㄴ가', '요', '?']\n",
      "['환영', '자연어', '처리', '수업']\n",
      "[('환영', 'N'), ('하', 'X'), ('ㅂ니다', 'E'), ('!', 'S'), ('자연어', 'N'), ('처리', 'N'), ('수업', 'N'), ('은', 'J'), ('재미있', 'P'), ('게', 'E'), ('듣', 'P'), ('고', 'E'), ('계시', 'P'), ('ㄴ가', 'E'), ('요', 'J'), ('?', 'S')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Hannanum\n",
    "hannanum = Hannanum()\n",
    "text = '환영합니다! 자연어 처리 수업은 재미있게 듣고 계신가요?'\n",
    "print(hannanum.morphs(text))  # Parse phrase to morphemes\n",
    "print(hannanum.nouns(text))   # Noun extractors\n",
    "print(hannanum.pos(text))     # POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['환영', '하', 'ㅂ니다', '!', '자연어', '처리', '수업', '은', '재미있', '게', '듣', '고', '계시', 'ㄴ가요', '?']\n",
      "['환영', '자연어', '처리', '수업']\n",
      "[('환영', 'NNG'), ('하', 'XSV'), ('ㅂ니다', 'EFN'), ('!', 'SF'), ('자연어', 'NNG'), ('처리', 'NNG'), ('수업', 'NNG'), ('은', 'JX'), ('재미있', 'VA'), ('게', 'ECD'), ('듣', 'VV'), ('고', 'ECE'), ('계시', 'VXA'), ('ㄴ가요', 'EFQ'), ('?', 'SF')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Kkma\n",
    "kkma = Kkma()\n",
    "text = '환영합니다! 자연어 처리 수업은 재미있게 듣고 계신가요?'\n",
    "print(kkma.morphs(text))  # Parse phrase to morphemes\n",
    "print(kkma.nouns(text))   # Noun extractors\n",
    "print(kkma.pos(text))     # POS tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) Khaiii**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Khaiii](https://tech.kakao.com/2018/12/13/khaiii/)(Kakao Hangul Analyzer III)는 카카오의 딥러닝 기반 형태소 분석기입니다. 국립국어원에서 배포한 세종코퍼스로 학습하였습니다. 한국어에서 형태소 분석은 가장 기본적 전처리 과정으로 속도가 매우 중요하다는 판단하에 nlp에서 자주 쓰이는 LSTM이나 RNN을 제외하고 CNN을 사용하여 구현되었습니다. \n",
    "\n",
    "<img src = \"https://t1.daumcdn.net/thumb/R1280x0/?fname=http://t1.daumcdn.net/brunch/service/user/1oU7/image/DXlTnCNYfeYzWIR4kN428VouYKQ.png\">\n",
    "\n",
    "[Khaiii github](https://github.com/kakao/khaiii)\n",
    "\n",
    "윈도우는 지원하지 않기에 ubuntu 상에서 확인했습니다. \n",
    "\n",
    "ubuntu에서 `jupyter notebook` 명령어로 실행하여 확인하면 됩니다.\n",
    "\n",
    "[윈도우에서 khaiii 설치 방법](https://sy-log.tistory.com/55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) PyKoSpacing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[PyKoSpacing](https://github.com/haven-jeon/PyKoSpacing)은 띄어쓰기가 되어있지 않은 문장에 띄어쓰기를 적용해줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "띄어쓰기가 없는 문장:\n",
      " 구름자연어처리전문가양성과정2기에오신여러분을환영합니다!\n",
      "정답:\n",
      " 구름 자연어 처리 전문가 양성 과정 2기에 오신 여러분을 환영합니다!\n",
      "띄어쓰기 교정 후:\n",
      " 구름자연어 처리 전문가 양성과정 2기에 오신 여러분을 환영합니다!\n"
     ]
    }
   ],
   "source": [
    "from pykospacing import Spacing\n",
    "\n",
    "spacing = Spacing()\n",
    "\n",
    "sent = \"구름 자연어 처리 전문가 양성 과정 2기에 오신 여러분을 환영합니다!\"\n",
    "new_sent = sent.replace(\" \", \"\")\n",
    "kospacing_sent = spacing(new_sent)\n",
    "\n",
    "print(\"띄어쓰기가 없는 문장:\\n\", new_sent)\n",
    "print(\"정답:\\n\", sent)\n",
    "print(\"띄어쓰기 교정 후:\\n\", kospacing_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4) Py-Hanspell**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네이버 한글 맞춤법 검사기를 바탕으로 만들어진 패키지입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': True,\n",
       " 'original': '안녕 하세요. 저는 한국인 입니다. 이문장은 한글로 작성됬습니다.',\n",
       " 'checked': '안녕하세요. 저는 한국인입니다. 이 문장은 한글로 작성됐습니다.',\n",
       " 'errors': 4,\n",
       " 'words': OrderedDict([('안녕하세요.', 2),\n",
       "              ('저는', 0),\n",
       "              ('한국인입니다.', 2),\n",
       "              ('이', 2),\n",
       "              ('문장은', 2),\n",
       "              ('한글로', 0),\n",
       "              ('작성됐습니다.', 1)]),\n",
       " 'time': 0.13100790977478027}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hanspell import spell_checker\n",
    "\n",
    "result = spell_checker.check(u'안녕 하세요. 저는 한국인 입니다. 이문장은 한글로 작성됬습니다.')\n",
    "result.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "맞춤법 틀리면 왜 안돼? 쓰고 싶은 대로 쓰면 되지\n"
     ]
    }
   ],
   "source": [
    "sent = \"맞춤법 틀리면 외 않되? 쓰고싶은대로쓰면돼지 \"\n",
    "spelled_sent = spell_checker.check(sent)\n",
    "\n",
    "hanspell_sent = spelled_sent.checked\n",
    "print(hanspell_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5) soynlp**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[soynlp](https://github.com/lovit/soynlp)는 한국어와 관련된 전처리 함수와 여러 함수들이 모아져있는 라이브러리입니다. 비지도학습 기반이기에 어느 정도 규모가 있는 동일한 집단 문서에서 잘 작동합니다. 예를 들어 영화댓글이나 뉴스 기사 등이 있습니다. \n",
    "\n",
    "Noun extractor, word extraction, tokenizer, part of speech tagger, vectorizer, normalizer 등의 기능을 가진 함수들이 있습니다. 밑에는 그 중 normalization의 함수를 사용한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㅋㅋㅋㅜㅜㅜ\n",
      "와하하핫\n",
      "가나다ㅏㅑㅓㅋㅋ쿠ㅜㅜㅜ 아핫\n",
      "가나다ㅏㅑㅓㅋㅋ쿠ㅜㅜㅜ 123 아핫\n",
      "가나다ㅏㅑㅓㅋㅋ쿠ㅜㅜㅜabcd123!!아핫\n"
     ]
    }
   ],
   "source": [
    "from soynlp.normalizer import *\n",
    "\n",
    "print(emoticon_normalize('ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ쿠ㅜㅜㅜㅜㅜㅜ', num_repeats=3))\n",
    "\n",
    "print(repeat_normalize('와하하하하하하하하하핫', num_repeats=2))\n",
    "\n",
    "print(only_hangle('가나다ㅏㅑㅓㅋㅋ쿠ㅜㅜㅜabcd123!!아핫'))\n",
    "\n",
    "print(only_hangle_number('가나다ㅏㅑㅓㅋㅋ쿠ㅜㅜㅜabcd123!!아핫'))\n",
    "\n",
    "print(only_text('가나다ㅏㅑㅓㅋㅋ쿠ㅜㅜㅜabcd123!!아핫'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "더 다양한 것은 각 라이브러리 홈페이지를 참고하면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습1. 네이버 영화 감상평을 크롤링하고 전처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네이버 영화 감상평을 크롤링하고 전처리 과정을 거쳐 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen # 웹서버에 접근하는 모듈\n",
    "from bs4 import BeautifulSoup # 웹페이지 내용구조를 분석하는 모듈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) 네이버 영화 감상평 크롤링**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://movie.naver.com/movie/bi/mi/pointWriteFormList.naver?code=187348&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page=1'\n",
    "html=urlopen(url)\n",
    "html_source = BeautifulSoup(html,'html.parser',from_encoding='utf-8') # 댓글 페이지를 utf-8형식으로 html 소스가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<!DOCTYPE html>\n",
      "\n",
      "<html lang=\"ko\">\n",
      "<head>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n",
      "<title>네이버 영화</title>\n",
      "<link href=\"https://ssl.pstatic.net/static/m/movie/icons/naver_movie_favicon.ico\" rel=\"shortcut icon\" type=\"image/x-icon\"/>\n",
      "<link href=\"/css/common.css?20220110163618\" rel=\"stylesheet\" type=\"text/css\">\n",
      "<link href=\"/css/movie_tablet.css?20220110163618\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "<link href=\"/css/movie_end.css?20220110163618\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "<script src=\"/js/deploy/movie.all.js?20220110163618\" type=\"text/javascript\"></script>\n",
      "</link></head>\n",
      "<body>\n",
      "<!-- content -->\n",
      "<input id=\"movieCode\" name=\"movieCode\" type=\"hidden\" value=\"187348\"/>\n",
      "<input id=\"onlyActualPointYn\" name=\"onlyActualPointYn\" type=\"hidden\" value=\"N\"/>\n",
      "<input id=\"includeSpoilerYn\" name=\"includeSpoilerYn\" type=\"hidden\" value=\"N\"/>\n",
      "<input id=\"order\" name=\"order\" type=\"hidden\" value=\"sympathyScore\"/>\n",
      "<input id=\"page\" name=\"page\" type=\"hidden\" value=\"1\"/>\n",
      "<div class=\"ifr_area basic_ifr\">\n",
      "<div class=\"input_netizen \">\n",
      "<!-- [D] 관람객 평점 작성 완료 -->\n",
      "<div class=\"ly_viewer\" id=\"actualPointWriteExecuteLayer\" style=\"display:none\">\n",
      "<h4>관람객 평점 작성 완료 안내</h4>\n",
      "<p>관람객 평점이 등록되었습니다.<br/><em>네이버페이 포인트 500원</em>이 적립되었습니다.<br/><em>7일 이후</em> 확인 가능합니다.</p>\n",
      "<p>(평점 삭제시, 적립된 포인트는 회수됩니다.)</p>\n",
      "<div class=\"btn\">\n",
      "<a class=\"ok\" href=\"#\" id=\"actualPointWriteExecuteLayerOkButton\">확인</a>\n",
      "<a class=\"close\" href=\"#\" id=\"actualPointWriteExecuteLayerCloseButton\" title=\"닫기\">관람객 평점 작성 완료 안내 레이어 닫기</a>\n",
      "</div>\n",
      "</div>\n",
      "<!-- //관람객 평점 작성 완료 -->\n",
      "<!-- [D] 관람객 평점 작성 완료2 -->\n",
      "<div class=\"ly_viewer\" id=\"pointWriteExecuteLayer\" style=\"display:none\">\n",
      "<h4>관람객 평점 작성 완료 안내</h4>\n",
      "<p class=\"msg1\">관람객 평점이 등록되었습니다.</p>\n",
      "<div class=\"btn\">\n",
      "<a class=\"ok\" href=\"#\" id=\"pointWriteExecuteLayerOkButton\">확인</a>\n",
      "<a class=\"close\" href=\"#\" id=\"pointWriteExecuteLayerCloseButton\" title=\"닫기\">관람객 평점 작성 완료 안내 레이어 닫기</a>\n",
      "</div>\n",
      "</div>\n",
      "<!-- //관람객 평점 작성 완료2 -->\n",
      "<div class=\"score_total\">\n",
      "<strong class=\"total\">관람객 평점 <em>9,035</em>건<button class=\"btn_review\" id=\"open-form-btn\">내 평점 등록</button></strong>\n",
      "</div>\n",
      "<div class=\"top_behavior\" id=\"orderCheckbox\">\n",
      "<ul class=\"sorting_list\">\n",
      "<li class=\"on\"><a href=\"#\" onclick=\"parent.clickcr(this, 'ara.bysym', '', '', event); dislplayOrder('sympathyScore');\">공감순</a></li>\n",
      "<li><a href=\"#\" onclick=\"parent.clickcr(this, 'ara.byrct', '', '', event); dislplayOrder('newest');\">최신순</a></li>\n",
      "<li><a href=\"#\" onclick=\"parent.clickcr(this, 'ara.high', '', '', event); dislplayOrder('highest');\">평점 높은 순</a></li>\n",
      "<li><a href=\"#\" onclick=\"parent.clickcr(this, 'ara.low', '', '', event); dislplayOrder('lowest');\">평점 낮은 순</a></li>\n",
      "</ul>\n",
      "<ul class=\"quarter_mode\">\n",
      "<li>\n",
      "<input class=\"blind \" id=\"spoilerYnCheckBox\" name=\"spilerViewer\" onclick=\"parent.clickcr(this,'','','',event); return false;\" title=\"스포일러 보기\" type=\"checkbox\"/>\n",
      "<label class=\"label_viewer\" for=\"spoilerYnCheckBox\" id=\"spoilerYnLable\">스포일러 보기</label>\n",
      "</li>\n",
      "<li>\n",
      "<input class=\"blind \" id=\"actualYnCheckBox\" name=\"viewer\" onclick=\"parent.clickcr(this,'ura.mgs','','',event); return false;\" title=\"관람객 평점만 보기\" type=\"checkbox\"/>\n",
      "<label class=\"label_viewer\" for=\"actualYnCheckBox\" id=\"actualYnLable\">관람객 평점만 보기</label>\n",
      "<a class=\"help _actualPointHelp\" href=\"#\" id=\"actualPointHelpButton\" title=\"도움말\">관람객 평점만 보기 도움말</a>\n",
      "<div class=\"ly_help _actualPointHelp\" id=\"actualPointHelp\" style=\"display:none\">\n",
      "<h5>관람객평점만 보기 안내 레이어</h5>\n",
      "<div class=\"ly_cont _actualPointHelp\">\n",
      "<p>네이버 영화에서 예매하신 고객님들이<br/> 영화 관람 후 등록해주신 평점입니다.</p>\n",
      "</div>\n",
      "<button class=\"btn_close _actualPointHelp\" id=\"actualPointHelpCloseButton\" title=\"닫기\" type=\"button\"><span class=\"blind\">관람객 평점만 보기 안내 레이어 닫기</span></button>\n",
      "<span class=\"arr _actualPointHelp\"></span>\n",
      "</div>\n",
      "</li>\n",
      "</ul>\n",
      "</div>\n",
      "<div class=\"score_result\">\n",
      "<ul>\n",
      "<li>\n",
      "<div class=\"star_score\">\n",
      "<span class=\"st_off\"><span class=\"st_on\" style=\"width:60.0%\"></span></span><em>6</em>\n",
      "</div>\n",
      "<div class=\"score_reple\">\n",
      "<p>\n",
      "<span class=\"ico_viewer\">관람객</span>\n",
      "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
      "<span id=\"_filtered_ment_0\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t명품 브랜드라 믿고 샀는데 안에 made in china가 적혀있었다 \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "</p>\n",
      "<dl>\n",
      "<dt>\n",
      "<em>\n",
      "<a href=\"#\" onclick=\"javascript:showPointListByNid(17683851, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
      "<span>유한솔(u_hs****)</span>\n",
      "</a>\n",
      "</em>\n",
      "<em>2021.09.01 23:12</em>\n",
      "</dt>\n",
      "<dd>\n",
      "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','u_hs****', '5yeZlbUoM83MSnyA4B69g2/9Kp6/vWUPiWtbjRDZ/Ic=', '17683851', 'point_after', false);return false;\"><em>신고</em></a>\n",
      "</dd>\n",
      "</dl>\n",
      "</div>\n",
      "<div class=\"btn_area\">\n",
      "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
      "<span class=\"ico_up\"></span>\n",
      "<span class=\"blind\">공감</span>\n",
      "<strong class=\"sympathy_17683851\">3530</strong>\n",
      "</a>\n",
      "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
      "<span class=\"ico_down\"></span>\n",
      "<span class=\"blind\">비공감</span>\n",
      "<strong class=\"notSympathy_17683851\">999</strong>\n",
      "</a>\n",
      "</div>\n",
      "</li>\n",
      "<li>\n",
      "<div class=\"star_score\">\n",
      "<span class=\"st_off\"><span class=\"st_on\" style=\"width:60.0%\"></span></span><em>6</em>\n",
      "</div>\n",
      "<div class=\"score_reple\">\n",
      "<p>\n",
      "<span class=\"ico_viewer\">관람객</span>\n",
      "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
      "<span id=\"_filtered_ment_1\">\n",
      "<span class=\"_unfold_ment\" id=\"_unfold_ment1\">\n",
      "<a data-src=\"자세히 보면 중국 문화 올려치는 영화입니다. 초반부터 똥양계는 무조건 한국인 취급하는데 우리는 당당히 중국인이다. ㅇㅈㄹ하고요. 깊고 정통한 중국 문화는 대를 이어서 간다. 마카오에서 K-POP 댄스 추는 거 보고 무조건 힙하지? 우리 중국 문화야 ㅋ 구미호, 기린, 용은 우리 문화다. 사람 죽으면 물에 연등 띄우는 거? 우리 중국 문화다. 동북공정 영화입니다. 영화는 자세히 보세요. 의도가 있습니다. \" href=\"javascript:void(0);\" onclick=\"unfoldPointMent(this);\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t자세히 보면 중국 문화 올려치는 영화입니다. 초반부터 똥양계는 무조건 한국인 취급하는데 우리는 당당히 중국인이다. ㅇㅈㄹ하고요. 깊고 정통한 중국 문화는 대를 이어서 간다. 마카오에서 K-POP 댄스 추는 거 보고 ...\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>\n",
      "</span>\n",
      "</span>\n",
      "</p>\n",
      "<dl>\n",
      "<dt>\n",
      "<em>\n",
      "<a href=\"#\" onclick=\"javascript:showPointListByNid(17684413, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
      "<span>다른별명(quda****)</span>\n",
      "</a>\n",
      "</em>\n",
      "<em>2021.09.02 09:07</em>\n",
      "</dt>\n",
      "<dd>\n",
      "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','quda****', 'yDhDuoAGvFlSapTkwfceEoomxBNCGqOlYHBXUhATmZs=', '17684413', 'point_after', false);return false;\"><em>신고</em></a>\n",
      "</dd>\n",
      "</dl>\n",
      "</div>\n",
      "<div class=\"btn_area\">\n",
      "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
      "<span class=\"ico_up\"></span>\n",
      "<span class=\"blind\">공감</span>\n",
      "<strong class=\"sympathy_17684413\">2452</strong>\n",
      "</a>\n",
      "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
      "<span class=\"ico_down\"></span>\n",
      "<span class=\"blind\">비공감</span>\n",
      "<strong class=\"notSympathy_17684413\">765</strong>\n",
      "</a>\n",
      "</div>\n",
      "</li>\n",
      "<li>\n",
      "<div class=\"star_score\">\n",
      "<span class=\"st_off\"><span class=\"st_on\" style=\"width:10.0%\"></span></span><em>1</em>\n",
      "</div>\n",
      "<div class=\"score_reple\">\n",
      "<p>\n",
      "<span class=\"ico_viewer\">관람객</span>\n",
      "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
      "<span id=\"_filtered_ment_2\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t마블의 중국산 D-War \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "</p>\n",
      "<dl>\n",
      "<dt>\n",
      "<em>\n",
      "<a href=\"#\" onclick=\"javascript:showPointListByNid(17683609, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
      "<span>eodb****</span>\n",
      "</a>\n",
      "</em>\n",
      "<em>2021.09.01 21:52</em>\n",
      "</dt>\n",
      "<dd>\n",
      "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','eodb****', 'tREtwejBYWKbW6jlqJ1pIjGadMB7X8Mut/wC4lCPwbg=', '17683609', 'point_after', false);return false;\"><em>신고</em></a>\n",
      "</dd>\n",
      "</dl>\n",
      "</div>\n",
      "<div class=\"btn_area\">\n",
      "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
      "<span class=\"ico_up\"></span>\n",
      "<span class=\"blind\">공감</span>\n",
      "<strong class=\"sympathy_17683609\">1672</strong>\n",
      "</a>\n",
      "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
      "<span class=\"ico_down\"></span>\n",
      "<span class=\"blind\">비공감</span>\n",
      "<strong class=\"notSympathy_17683609\">524</strong>\n",
      "</a>\n",
      "</div>\n",
      "</li>\n",
      "<li>\n",
      "<div class=\"star_score\">\n",
      "<span class=\"st_off\"><span class=\"st_on\" style=\"width:50.0%\"></span></span><em>5</em>\n",
      "</div>\n",
      "<div class=\"score_reple\">\n",
      "<p>\n",
      "<span class=\"ico_viewer\">관람객</span>\n",
      "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
      "<span id=\"_filtered_ment_3\">\n",
      "<span class=\"_unfold_ment\" id=\"_unfold_ment3\">\n",
      "<a data-src=\"세계관이나 설정들이 너무 붕 떠있고 개연성은 밥말아 먹어놓고 억지 신파 끼워넣기에 주인공은 무색무취 아무 매력 없음. 10초전 까지 죽일듯이 싸우던 애들이 갑자기 우리 함께 싸우자 ㅇㅈㄹ 하질 않나. 아부지 행동들 감정기복 너무 심해서 공감도 안가고, 사건들이 빌드업도 없이 무지성으로 튀어나오니까 몰입도 안 됨. 배우가 너무 아깝다. \" href=\"javascript:void(0);\" onclick=\"unfoldPointMent(this);\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t세계관이나 설정들이 너무 붕 떠있고 개연성은 밥말아 먹어놓고 억지 신파 끼워넣기에 주인공은 무색무취 아무 매력 없음. 10초전 까지 죽일듯이 싸우던 애들이 갑자기 우리 함께 싸우자 ㅇㅈㄹ 하질 않나. 아부지 행동들 ...\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>\n",
      "</span>\n",
      "</span>\n",
      "</p>\n",
      "<dl>\n",
      "<dt>\n",
      "<em>\n",
      "<a href=\"#\" onclick=\"javascript:showPointListByNid(17682177, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
      "<span>멍멍(mild****)</span>\n",
      "</a>\n",
      "</em>\n",
      "<em>2021.09.01 11:21</em>\n",
      "</dt>\n",
      "<dd>\n",
      "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','mild****', 'ojMhodyJCw+vC49FARXW6LajOidxylKbd4sd7FWy2YM=', '17682177', 'point_after', false);return false;\"><em>신고</em></a>\n",
      "</dd>\n",
      "</dl>\n",
      "</div>\n",
      "<div class=\"btn_area\">\n",
      "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
      "<span class=\"ico_up\"></span>\n",
      "<span class=\"blind\">공감</span>\n",
      "<strong class=\"sympathy_17682177\">1632</strong>\n",
      "</a>\n",
      "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
      "<span class=\"ico_down\"></span>\n",
      "<span class=\"blind\">비공감</span>\n",
      "<strong class=\"notSympathy_17682177\">502</strong>\n",
      "</a>\n",
      "</div>\n",
      "</li>\n",
      "<li>\n",
      "<div class=\"star_score\">\n",
      "<span class=\"st_off\"><span class=\"st_on\" style=\"width:50.0%\"></span></span><em>5</em>\n",
      "</div>\n",
      "<div class=\"score_reple\">\n",
      "<p>\n",
      "<span class=\"ico_viewer\">관람객</span>\n",
      "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
      "<span id=\"_filtered_ment_4\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t마블의 탈을 쓴 중국 무협영화. 중국 시장과 자본을 지나치게 의식한 디즈니의 연이은 헛발질. CG 범벅에 협소한 공간에서 몇 안되는 인원들의 액션 등 스케일마저 왜 이리 작아진 건지... \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "</p>\n",
      "<dl>\n",
      "<dt>\n",
      "<em>\n",
      "<a href=\"#\" onclick=\"javascript:showPointListByNid(17684461, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
      "<span>삼생삼세(lexp****)</span>\n",
      "</a>\n",
      "</em>\n",
      "<em>2021.09.02 10:25</em>\n",
      "</dt>\n",
      "<dd>\n",
      "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','lexp****', 'R9qgmU3/u5wIhbcc9qwxbAqnEQDmQoQBBGF+r/BIDoM=', '17684461', 'point_after', false);return false;\"><em>신고</em></a>\n",
      "</dd>\n",
      "</dl>\n",
      "</div>\n",
      "<div class=\"btn_area\">\n",
      "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
      "<span class=\"ico_up\"></span>\n",
      "<span class=\"blind\">공감</span>\n",
      "<strong class=\"sympathy_17684461\">1200</strong>\n",
      "</a>\n",
      "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
      "<span class=\"ico_down\"></span>\n",
      "<span class=\"blind\">비공감</span>\n",
      "<strong class=\"notSympathy_17684461\">260</strong>\n",
      "</a>\n",
      "</div>\n",
      "</li>\n",
      "<li>\n",
      "<div class=\"star_score\">\n",
      "<span class=\"st_off\"><span class=\"st_on\" style=\"width:10.0%\"></span></span><em>1</em>\n",
      "</div>\n",
      "<div class=\"score_reple\">\n",
      "<p>\n",
      "<span class=\"ico_viewer\">관람객</span>\n",
      "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
      "<span id=\"_filtered_ment_5\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t하 정말 재미없네요.. \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "</p>\n",
      "<dl>\n",
      "<dt>\n",
      "<em>\n",
      "<a href=\"#\" onclick=\"javascript:showPointListByNid(17683742, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
      "<span>LEEE(oh1m****)</span>\n",
      "</a>\n",
      "</em>\n",
      "<em>2021.09.01 22:30</em>\n",
      "</dt>\n",
      "<dd>\n",
      "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','oh1m****', 'ILR9piLlT+GT5bopI6SQwT5g/ONv1kL+aNF8BR9L6GI=', '17683742', 'point_after', false);return false;\"><em>신고</em></a>\n",
      "</dd>\n",
      "</dl>\n",
      "</div>\n",
      "<div class=\"btn_area\">\n",
      "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
      "<span class=\"ico_up\"></span>\n",
      "<span class=\"blind\">공감</span>\n",
      "<strong class=\"sympathy_17683742\">1242</strong>\n",
      "</a>\n",
      "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
      "<span class=\"ico_down\"></span>\n",
      "<span class=\"blind\">비공감</span>\n",
      "<strong class=\"notSympathy_17683742\">441</strong>\n",
      "</a>\n",
      "</div>\n",
      "</li>\n",
      "<li>\n",
      "<div class=\"star_score\">\n",
      "<span class=\"st_off\"><span class=\"st_on\" style=\"width:80.0%\"></span></span><em>8</em>\n",
      "</div>\n",
      "<div class=\"score_reple\">\n",
      "<p>\n",
      "<span class=\"ico_viewer\">관람객</span>\n",
      "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
      "<span id=\"_filtered_ment_6\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t마블 영화를 본 건지 중국 영화를 본 건지 모르겠지만 양조위는 너무 멋있더라.... \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "</p>\n",
      "<dl>\n",
      "<dt>\n",
      "<em>\n",
      "<a href=\"#\" onclick=\"javascript:showPointListByNid(17683773, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
      "<span>아오이키(akpl****)</span>\n",
      "</a>\n",
      "</em>\n",
      "<em>2021.09.01 22:41</em>\n",
      "</dt>\n",
      "<dd>\n",
      "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','akpl****', '7VcZSNARn0DmciXUgvpCdhpWhySrrgIlUvXk9ThEANs=', '17683773', 'point_after', false);return false;\"><em>신고</em></a>\n",
      "</dd>\n",
      "</dl>\n",
      "</div>\n",
      "<div class=\"btn_area\">\n",
      "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
      "<span class=\"ico_up\"></span>\n",
      "<span class=\"blind\">공감</span>\n",
      "<strong class=\"sympathy_17683773\">904</strong>\n",
      "</a>\n",
      "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
      "<span class=\"ico_down\"></span>\n",
      "<span class=\"blind\">비공감</span>\n",
      "<strong class=\"notSympathy_17683773\">175</strong>\n",
      "</a>\n",
      "</div>\n",
      "</li>\n",
      "<li>\n",
      "<div class=\"star_score\">\n",
      "<span class=\"st_off\"><span class=\"st_on\" style=\"width:100.0%\"></span></span><em>10</em>\n",
      "</div>\n",
      "<div class=\"score_reple\">\n",
      "<p>\n",
      "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
      "<span id=\"_filtered_ment_7\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t마블의 새로운 시작이다… 재밌어요 \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "</p>\n",
      "<dl>\n",
      "<dt>\n",
      "<em>\n",
      "<a href=\"#\" onclick=\"javascript:showPointListByNid(17682380, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
      "<span>서울자취생(osan****)</span>\n",
      "</a>\n",
      "</em>\n",
      "<em>2021.09.01 12:57</em>\n",
      "</dt>\n",
      "<dd>\n",
      "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','osan****', '/nJNfnEViK1sAU2EfhMyhySFZOOvQGfkPEf8vne0pEU=', '17682380', 'point_after', false);return false;\"><em>신고</em></a>\n",
      "</dd>\n",
      "</dl>\n",
      "</div>\n",
      "<div class=\"btn_area\">\n",
      "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
      "<span class=\"ico_up\"></span>\n",
      "<span class=\"blind\">공감</span>\n",
      "<strong class=\"sympathy_17682380\">704</strong>\n",
      "</a>\n",
      "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
      "<span class=\"ico_down\"></span>\n",
      "<span class=\"blind\">비공감</span>\n",
      "<strong class=\"notSympathy_17682380\">162</strong>\n",
      "</a>\n",
      "</div>\n",
      "</li>\n",
      "<li>\n",
      "<div class=\"star_score\">\n",
      "<span class=\"st_off\"><span class=\"st_on\" style=\"width:60.0%\"></span></span><em>6</em>\n",
      "</div>\n",
      "<div class=\"score_reple\">\n",
      "<p>\n",
      "<span class=\"ico_viewer\">관람객</span>\n",
      "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
      "<span class=\"text_spo _text_spo\" id=\"_text_spo_8\">스포일러가 포함된 감상평입니다. <a class=\"btn_more\" href=\"javascript:void(0);\" onclick=\"showMovieReview('8');\" role=\"button\">감상평 보기</a></span>\n",
      "<span id=\"_filtered_ment_8\" style=\"display:none;\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t아부지를 왜케 미워하는거지 훈련빡시케 시켰다고 그러는건가아부지를 죽인댔다가 갑자기 필요하다하고 개연성이 좀 부족..텐링즈의 전설이란 제목도 뭐 굳이... \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "</p>\n",
      "<dl>\n",
      "<dt>\n",
      "<em>\n",
      "<a href=\"#\" onclick=\"javascript:showPointListByNid(17683572, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
      "<span>척설오추(jagi****)</span>\n",
      "</a>\n",
      "</em>\n",
      "<em>2021.09.01 21:42</em>\n",
      "</dt>\n",
      "<dd>\n",
      "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','jagi****', 'A6a4XYMPqy60LytWz0YbOrrZvTCupul3o2z1kR64W5M=', '17683572', 'point_after', false);return false;\"><em>신고</em></a>\n",
      "</dd>\n",
      "</dl>\n",
      "</div>\n",
      "<div class=\"btn_area\">\n",
      "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
      "<span class=\"ico_up\"></span>\n",
      "<span class=\"blind\">공감</span>\n",
      "<strong class=\"sympathy_17683572\">590</strong>\n",
      "</a>\n",
      "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
      "<span class=\"ico_down\"></span>\n",
      "<span class=\"blind\">비공감</span>\n",
      "<strong class=\"notSympathy_17683572\">117</strong>\n",
      "</a>\n",
      "</div>\n",
      "</li>\n",
      "<li class=\"last\">\n",
      "<div class=\"star_score\">\n",
      "<span class=\"st_off\"><span class=\"st_on\" style=\"width:60.0%\"></span></span><em>6</em>\n",
      "</div>\n",
      "<div class=\"score_reple\">\n",
      "<p>\n",
      "<span class=\"ico_viewer\">관람객</span>\n",
      "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
      "<span id=\"_filtered_ment_9\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t마블영화보면서 처음으로 졸았습니다 ㅜㅜ \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "</p>\n",
      "<dl>\n",
      "<dt>\n",
      "<em>\n",
      "<a href=\"#\" onclick=\"javascript:showPointListByNid(17686410, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
      "<span>kupyt192(neid****)</span>\n",
      "</a>\n",
      "</em>\n",
      "<em>2021.09.03 11:02</em>\n",
      "</dt>\n",
      "<dd>\n",
      "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','neid****', 'saQhtz9jiCIRvm10d92XoilJfNG9PWkYufbLt2TIid0=', '17686410', 'point_after', false);return false;\"><em>신고</em></a>\n",
      "</dd>\n",
      "</dl>\n",
      "</div>\n",
      "<div class=\"btn_area\">\n",
      "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
      "<span class=\"ico_up\"></span>\n",
      "<span class=\"blind\">공감</span>\n",
      "<strong class=\"sympathy_17686410\">730</strong>\n",
      "</a>\n",
      "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
      "<span class=\"ico_down\"></span>\n",
      "<span class=\"blind\">비공감</span>\n",
      "<strong class=\"notSympathy_17686410\">271</strong>\n",
      "</a>\n",
      "</div>\n",
      "</li>\n",
      "</ul>\n",
      "</div>\n",
      "<div class=\"paging\">\n",
      "<div>\n",
      "<a href=\"/movie/bi/mi/pointWriteFormList.naver?code=187348&amp;type=after&amp;isActualPointWriteExecute=false&amp;isMileageSubscriptionAlready=false&amp;isMileageSubscriptionReject=false&amp;page=1\" id=\"pagerTagAnchor1\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span class=\"on\">1</span></a>\n",
      "<a href=\"/movie/bi/mi/pointWriteFormList.naver?code=187348&amp;type=after&amp;isActualPointWriteExecute=false&amp;isMileageSubscriptionAlready=false&amp;isMileageSubscriptionReject=false&amp;page=2\" id=\"pagerTagAnchor2\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span>2</span></a>\n",
      "<a href=\"/movie/bi/mi/pointWriteFormList.naver?code=187348&amp;type=after&amp;isActualPointWriteExecute=false&amp;isMileageSubscriptionAlready=false&amp;isMileageSubscriptionReject=false&amp;page=3\" id=\"pagerTagAnchor3\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span>3</span></a>\n",
      "<a href=\"/movie/bi/mi/pointWriteFormList.naver?code=187348&amp;type=after&amp;isActualPointWriteExecute=false&amp;isMileageSubscriptionAlready=false&amp;isMileageSubscriptionReject=false&amp;page=4\" id=\"pagerTagAnchor4\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span>4</span></a>\n",
      "<a href=\"/movie/bi/mi/pointWriteFormList.naver?code=187348&amp;type=after&amp;isActualPointWriteExecute=false&amp;isMileageSubscriptionAlready=false&amp;isMileageSubscriptionReject=false&amp;page=5\" id=\"pagerTagAnchor5\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span>5</span></a>\n",
      "<a href=\"/movie/bi/mi/pointWriteFormList.naver?code=187348&amp;type=after&amp;isActualPointWriteExecute=false&amp;isMileageSubscriptionAlready=false&amp;isMileageSubscriptionReject=false&amp;page=6\" id=\"pagerTagAnchor6\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span>6</span></a>\n",
      "<a href=\"/movie/bi/mi/pointWriteFormList.naver?code=187348&amp;type=after&amp;isActualPointWriteExecute=false&amp;isMileageSubscriptionAlready=false&amp;isMileageSubscriptionReject=false&amp;page=7\" id=\"pagerTagAnchor7\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span>7</span></a>\n",
      "<a href=\"/movie/bi/mi/pointWriteFormList.naver?code=187348&amp;type=after&amp;isActualPointWriteExecute=false&amp;isMileageSubscriptionAlready=false&amp;isMileageSubscriptionReject=false&amp;page=8\" id=\"pagerTagAnchor8\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span>8</span></a>\n",
      "<a href=\"/movie/bi/mi/pointWriteFormList.naver?code=187348&amp;type=after&amp;isActualPointWriteExecute=false&amp;isMileageSubscriptionAlready=false&amp;isMileageSubscriptionReject=false&amp;page=9\" id=\"pagerTagAnchor9\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span>9</span></a>\n",
      "<a href=\"/movie/bi/mi/pointWriteFormList.naver?code=187348&amp;type=after&amp;isActualPointWriteExecute=false&amp;isMileageSubscriptionAlready=false&amp;isMileageSubscriptionReject=false&amp;page=10\" id=\"pagerTagAnchor10\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span>10</span></a>\n",
      "<a class=\"pg_next\" href=\"/movie/bi/mi/pointWriteFormList.naver?code=187348&amp;type=after&amp;isActualPointWriteExecute=false&amp;isMileageSubscriptionAlready=false&amp;isMileageSubscriptionReject=false&amp;page=2\" id=\"pagerTagAnchor2\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\" title=\"다음\"><em>다음</em></a>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<!-- //content -->\n",
      "<form accept-charset=\"utf-8\" id=\"reportForm\" method=\"POST\" name=\"reportForm1\"></form>\n",
      "<script type=\"text/javascript\">\n",
      "\n",
      "\n",
      "if (false == false && \"after\" == \"after\" && false) {\n",
      "\tif (true && false) {\n",
      "\t\tjindo.$Element(\"pointWriteExecuteLayer\").show();\n",
      "\t} else if (false && true) {\n",
      "\t\tjindo.$Element(\"actualPointWriteExecuteLayer\").show();\n",
      "\t}\n",
      "}\n",
      "\n",
      "var oElActualPointWriteExecuteLayer = jindo.$Element(\"actualPointWriteExecuteLayer\");\n",
      "\n",
      "if (oElActualPointWriteExecuteLayer != null && oElActualPointWriteExecuteLayer != \"undefined\") {\n",
      "\n",
      "\t\n",
      "\tjindo.$Element(\"actualPointWriteExecuteLayerOkButton\").attach(\"click\", function(e){\n",
      "\t\te.stop(jindo.$Event.CANCEL_DEFAULT);\n",
      "\t\tjindo.$Element(\"actualPointWriteExecuteLayer\").hide();\n",
      "\t\trefreshPage();\n",
      "\t});\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\tjindo.$Element(\"actualPointWriteExecuteLayerCloseButton\").attach(\"click\", function(e){\n",
      "\t\te.stop(jindo.$Event.CANCEL_DEFAULT);\n",
      "\t\tjindo.$Element(\"actualPointWriteExecuteLayer\").hide();\n",
      "\t\trefreshPage();\n",
      "\t});\n",
      "\t\n",
      "}\n",
      "\n",
      "var oElPointWriteExecuteLayer = jindo.$Element(\"pointWriteExecuteLayer\");\n",
      "\n",
      "if (oElPointWriteExecuteLayer != null && oElPointWriteExecuteLayer != \"undefined\") {\n",
      "\t\n",
      "\tjindo.$Element(\"pointWriteExecuteLayerOkButton\").attach(\"click\", function(e){\n",
      "\t\te.stop(jindo.$Event.CANCEL_DEFAULT);\n",
      "\t\tjindo.$Element(\"pointWriteExecuteLayer\").hide();\n",
      "\t\trefreshPage();\n",
      "\t});\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\tjindo.$Element(\"pointWriteExecuteLayerCloseButton\").attach(\"click\", function(e){\n",
      "\t\te.stop(jindo.$Event.CANCEL_DEFAULT);\n",
      "\t\tjindo.$Element(\"pointWriteExecuteLayer\").hide();\n",
      "\t\trefreshPage();\n",
      "\t});\n",
      "\t\n",
      "}\n",
      "\n",
      "jindo.$Fn(function () {\n",
      "\n",
      "  function checkboxHandlerFactory(isActualYn, isLabel) {\n",
      "    return function() {\n",
      "      var actualYnChecked = jindo.$(\"actualYnCheckBox\").checked;\n",
      "      var spoilerYnChecked = jindo.$(\"spoilerYnCheckBox\").checked;\n",
      "\n",
      "      // convert\n",
      "      actualYnChecked = (isActualYn && isLabel)? !actualYnChecked : actualYnChecked;\n",
      "      spoilerYnChecked = (!isActualYn && isLabel)? !spoilerYnChecked : spoilerYnChecked;\n",
      "\n",
      "      location.href = \"/movie/bi/mi/pointWriteFormList.naver?code=187348&type=after&onlyActualPointYn=\" + (actualYnChecked? \"Y\" : \"N\")  + \"&onlySpoilerPointYn=\" + (spoilerYnChecked? \"Y\" : \"N\") + \"&order=sympathyScore\";\n",
      "    };\n",
      "  }\n",
      "\n",
      "\t\n",
      "\tif (jindo.$(\"actualYnCheckBox\") != null) {\n",
      "\t\tjindo.$Fn(checkboxHandlerFactory(true, false), this).attach(jindo.$(\"actualYnCheckBox\"), 'click');\n",
      "\t}\n",
      "\n",
      "\tif (jindo.$(\"actualYnLable\") != null) {\n",
      "\t    jindo.$Fn(checkboxHandlerFactory(true, true), this).attach(jindo.$(\"actualYnLable\"), 'click');\n",
      "\t}\n",
      "\n",
      "\t\n",
      "    if (jindo.$(\"spoilerYnCheckBox\") != null) {\n",
      "    jindo.$Fn(checkboxHandlerFactory(false, false), this).attach(jindo.$(\"spoilerYnCheckBox\"), 'click');\n",
      "  }\n",
      "\n",
      "  if (jindo.$(\"spoilerYnLable\") != null) {\n",
      "    jindo.$Fn(checkboxHandlerFactory(false, true), this).attach(jindo.$(\"spoilerYnLable\"), 'click');\n",
      "  }\n",
      "\t\n",
      "\t\n",
      "\tif (jindo.$Element(\"actualPointHelp\") != null && jindo.$Element(\"actualPointHelp\") != \"undefined\") {\n",
      "\t\tactualPointHelpLayerToggle = function() {\n",
      "\t\t\tsetTimeout( function() {\n",
      "\t\t\t\tif (document.activeElement != null) {\n",
      "\t\t\t\t\tvar focusedEl = jindo.$Element(document.activeElement);\n",
      "\t\t\t\t\tif (focusedEl != null) {\n",
      "\t\t\t\t\t\tif ( !focusedEl.hasClass(\"_actualPointHelp\") ) {\n",
      "\t\t\t\t\t\t\t jindo.$Element(\"actualPointHelp\").hide();\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t}, 100);\n",
      "\t\t};\n",
      "\n",
      "\t\tnew jindo.LayerManager(\"actualPointHelp\", {\n",
      "\t\t\tsCheckEvent : \"click\",\n",
      "\t\t\tnHideDelay : 0\n",
      "\t\t}).link(jindo.$(\"actualPointHelp\"), jindo.$(\"actualPointHelpButton\"));\n",
      "\n",
      "\t\tjindo.$Element(\"actualPointHelpButton\").attach(\"click\", function(e){\n",
      "\t\t\te.stop(jindo.$Event.CANCEL_DEFAULT);\n",
      "\t\t\tjindo.$Element(\"actualPointHelp\").toggle();\n",
      "\t\t});\n",
      "\n",
      "\t\tjindo.$Element(\"actualPointHelpCloseButton\").attach(\"click\", function(e){\n",
      "\t\t\te.stop(jindo.$Event.CANCEL_DEFAULT);\n",
      "\t\t\tjindo.$Element(\"actualPointHelp\").toggle();\n",
      "\t\t});\n",
      "\n",
      "\t\t\n",
      "\t\tvar waelActualPointHelp = jindo.$ElementList('._actualPointHelp');\n",
      "\n",
      "\t\tjindo.$A(waelActualPointHelp.$value()).forEach(function(value, index, array) {\n",
      "\t\t\tjindo.$Fn(actualPointHelpLayerToggle, this).attach(value, \"blur\");\n",
      "\t\t});\n",
      "\t}\n",
      "\n",
      "\tparent.setParamForPointAfterList('N', 'sympathyScore', '1');\n",
      "\tparent.resizePointAfterListIframe(0);\n",
      "\n",
      "\t// 최소 높이 270px 지정\n",
      "\tvar frameHeight = eval(jindo.$Document().scrollSize().height);\n",
      "\n",
      "\tparent.resizePointAfterListIframe(frameHeight);\n",
      "\tparent.isPointAfterListLoad = true;\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\n",
      "  var isCheckPointExist = false;\n",
      "  // TODO: fix below condition\n",
      "  if (false) {\n",
      "    if(jindo.$Element(\"open-form-btn\")) {\n",
      "\t\tjindo.$Element(\"open-form-btn\").attach(\"click\", function(e) {\n",
      "\t\t  \t\n",
      "\t\t  \t\n",
      "\t\t\t\n",
      "\t\t  if (true && false && isCheckPointExist == false) {\n",
      "\t\t\tparent.point.checkPointAfterExistAndMileageSubscriptionType();\n",
      "\t\t  }\n",
      "\t\t  isCheckPointExist = true;\n",
      "\t\t  parent.openPointWriteForm();\n",
      "\t\t});\n",
      "    }\n",
      "  } else {\n",
      "    if (jindo.$Element(\"open-form-btn\")) {\n",
      "\t\tjindo.$Element(\"open-form-btn\").attach(\"click\", function (e) {\n",
      "\t\t  common.checkLogin(false);\n",
      "\t\t});\n",
      "    }\n",
      "  }\n",
      "\n",
      "  var isHide = true;\n",
      "\n",
      "  if(jindo.$Element(\"eval-edit\")) {\n",
      "    jindo.$Element(\"eval-edit\").attach(\"click\", function() {\n",
      "\t\t  var edit = jindo.$Element(\"ly-edit\");\n",
      "\t  \tisHide ? edit.show() : edit.hide();\n",
      "      \tisHide = !isHide;\n",
      "    })\n",
      "  }\n",
      "  parent.resizePointAfterListIframeOnLoad();\n",
      "}, this).attach(this, 'load');\n",
      "\n",
      "var point = {\n",
      "\t\tcheckLoginWithMessage : function(login, loginMessage, notLoginMessage) {\n",
      "\t\t\tif(login == false){\n",
      "\t\t\t\tif(confirm(message)){\n",
      "\t\t\t\t\ttop.location.href=\"https://nid.naver.com/nidlogin.login?mode=form&url=\"+encodeURIComponent(top.location.href);\n",
      "\t\t\t\t}\n",
      "\t\t\t\treturn false;\n",
      "\t\t\t}\n",
      "\t\t\treturn true;\n",
      "\t\t},\n",
      "\n",
      "\t\t\n",
      "\t\tcheckAlreadyPointAfterExist : function (nid) {\n",
      "\t\t\tvar existPointType = \"pointBefore\";\n",
      "\t\t\t\n",
      "\t\t\tif (false == false) {\n",
      "\t\t\t\tvar oAjax = new jindo.$Ajax(\"/api/internal/point/pointAfterExistJson.naver\", {\n",
      "\t\t\t    \tonload : function (oRes) {\n",
      "\t\t\t    \t\tvar resultCode = oRes.json().resultCode;\n",
      "\t\t\t    \t\t\n",
      "\t\t\t    \t\tif (resultCode == \"error\") {\t\t\t\t\t\t\t// 서버 오류\n",
      "\t\t\t    \t\t\talert(\"오류가 발생했습니다. 잠시 후 다시 시도해주세요.\");\n",
      "\t\t\t    \t\t\treturn false;\n",
      "\t\t\t    \t\t} else {\n",
      "\t\t\t    \t\t\texistPointType = oRes.json().existPointType;\n",
      "\t\t\t    \t\t\tpoint.del(existPointType, nid);\n",
      "\t\t\t    \t\t}\n",
      "\t\t\t    \t},\n",
      "\t\t\t\t\ttimeout : 5,\n",
      "\t\t\t    \tonerror : function (oRes) {\n",
      "\t\t\t    \t\talert(\"오류가 발생했습니다. 잠시 후 다시 시도해주세요.\");\n",
      "\t\t\t    \t\treturn false;\n",
      "\t\t\t    \t},\n",
      "\t\t\t    \tontimeout : function (oRes) {\n",
      "\t\t\t    \t\talert(\"처리가 지연되고 있습니다. 다시 시도해주세요.\");\n",
      "\t\t\t    \t\treturn false;\n",
      "\t\t\t    \t}\n",
      "\t\t\t    });\n",
      "\t\t\t    \n",
      "\t\t\t    oAjax.request({\n",
      "\t\t\t    \t\"movieCode\" : \"187348\",\n",
      "\t\t\t    \t\"isActualPoint\" : \"false\"\n",
      "\t\t\t    });\n",
      "\t\t\t} else {\n",
      "\t\t\t\tpoint.del(existPointType, nid);\n",
      "\t\t\t}\n",
      "\t\t},\n",
      "\n",
      "\t\tdel : function (existPointType, nid) {\n",
      "\t\t\tif (existPointType == \"actualPoint\") {\n",
      "\t\t\t\tif (confirm(\"관람객 평점 삭제시, 평점 작성으로 적립된 포인트는 회수됩니다. 평점을 삭제할까요?\") == false) {\n",
      "\t\t\t\t\treturn false;\n",
      "\t\t\t\t}\n",
      "\t\t\t} else {\n",
      "\t\t\t\tif (confirm(\"본인 삭제 시 복구할 수 없습니다.\\n평점을 삭제하시겠습니까?\") == false) {\n",
      "\t\t\t\t\treturn false;\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\t\n",
      "\t\t\tvar ajaxDeleteUrl = \"/api/internal/point/pointBeforeDelete.naver\";\n",
      "\t\t\tif (\"after\" == \"after\") {\n",
      "\t\t\t\tajaxDeleteUrl = \"/api/internal/point/pointAfterDelete.naver\";\n",
      "\t\t\t}\n",
      "\t\t\t\n",
      "\t\t\tvar ajax = new jindo.$Ajax(ajaxDeleteUrl, { \n",
      "\t\t\t\tmethod : \"POST\",\n",
      "\t\t\t\tasync : false,\n",
      "\t\t\t\tonload : this.delCallback\n",
      "\t\t\t});\n",
      "\t\t\tajax.header(\"ajax\", \"true\");\n",
      "\t\t\tajax.request({\n",
      "\t\t\t\t\"nid\":nid\n",
      "\t\t\t});\n",
      "\t\t},\n",
      "\t\t\n",
      "\t\tdelCallback : function(req) {\n",
      "\t\t\tvar returnValue = req.text();\n",
      "\t\t\t\n",
      "\t\t\tif(returnValue != \"success\"){\n",
      "\t\t\t\talert(returnValue);\n",
      "\t\t\t\treturn false;\n",
      "\t\t\t}\n",
      "\t\t\t\n",
      "\t\t\ttop.location.href = '/movie/bi/mi/point.naver?code=187348#pointAfterTab';\n",
      "\t\t\ttop.location.reload(true);\n",
      "\t\t}\n",
      "};\n",
      "\n",
      "function dislplayOrder(order) {\n",
      "\tvar url = \"/movie/bi/mi/pointWriteFormList.naver?code=187348&type=after\";\n",
      "\t\n",
      "\tvar onlyActualPointYnValue = jindo.$(\"onlyActualPointYn\").value;\n",
      "  \tvar includeSpoilerYnValue = jindo.$(\"includeSpoilerYn\").value;\n",
      "\n",
      "\tif (onlyActualPointYnValue != \"\") {\n",
      "\t\turl = url + \"&onlyActualPointYn=\" + onlyActualPointYnValue;\n",
      "\t}\n",
      "\n",
      "\tif (includeSpoilerYnValue != \"\") {\n",
      "      url = url + \"&onlySpoilerPointYn=\" + includeSpoilerYnValue;\n",
      "    }\n",
      "\t\n",
      "\turl = url + \"&order=\" + order;\n",
      "\t\n",
      "\tlocation.href = document.location.protocol + \"//\" + document.domain + url;\n",
      "}\n",
      "\n",
      "function showPointListByNid(nid, target){\n",
      "\tif (target == 'after') {\n",
      "\t\ttop.location.href = top.location.protocol + \"//\" + top.location.hostname + \"/movie/point/af/list.naver?st=nickname&target=after&sword=\"+nid;\n",
      "\t} else {\n",
      "\t\ttop.location.href = top.location.protocol + \"//\" + top.location.hostname + \"/movie/point/af/list.naver?st=nickname_before&target=before&sword=\"+nid;\n",
      "\t}\n",
      "}\n",
      "\n",
      "function refreshPage() {\n",
      "\t \n",
      "\ttop.location.href = '/movie/bi/mi/point.naver?code=187348#pointAfterTab';\n",
      "}\n",
      "\n",
      "// 스포일러 감상평 내용 보기\n",
      "function showMovieReview(rvwIdx) {\n",
      "    jindo.$Element('_text_spo_' + rvwIdx).css('display', 'none');\n",
      "    jindo.$Element('_filtered_ment_' + rvwIdx).css('display', 'block');\n",
      "    parent.resizePointAfterListIframeOnLoad();\n",
      "}\n",
      "\n",
      "// 감상평 펼쳐보기\n",
      "function unfoldPointMent(obj) {\n",
      "    var fullMent = jindo.$Element(obj).attr(\"data-src\");\n",
      "    jindo.$Element(obj).parent().html(fullMent);\n",
      "    parent.resizePointAfterListIframeOnLoad();\n",
      "}\n",
      "\n",
      "\n",
      "</script>\n",
      "<script type=\"text/javascript\">\n",
      "\tvar sympathy = new Sympathy(\"187348\", \"after\");\n",
      "</script>\n",
      "<script type=\"text/javascript\">\n",
      "            jindo.$Fn(function() {\n",
      "                try{ lcs_do(); } catch(e){}\n",
      "            }).attach(window, \"pageshow\");\n",
      "\t\t</script>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(html_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "댓글 부분에 해당하는 요소를 확인하고 내용을 추출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span id=\"_filtered_ment_0\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t명품 브랜드라 믿고 샀는데 안에 made in china가 적혀있었다 \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째 리뷰\n",
    "html_reviews = html_source.find('span', {'id': '_filtered_ment_0'})\n",
    "print(html_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span id=\"_filtered_ment_0\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t명품 브랜드라 믿고 샀는데 안에 made in china가 적혀있었다 \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "<span id=\"_filtered_ment_1\">\n",
      "<span class=\"_unfold_ment\" id=\"_unfold_ment1\">\n",
      "<a data-src=\"자세히 보면 중국 문화 올려치는 영화입니다. 초반부터 똥양계는 무조건 한국인 취급하는데 우리는 당당히 중국인이다. ㅇㅈㄹ하고요. 깊고 정통한 중국 문화는 대를 이어서 간다. 마카오에서 K-POP 댄스 추는 거 보고 무조건 힙하지? 우리 중국 문화야 ㅋ 구미호, 기린, 용은 우리 문화다. 사람 죽으면 물에 연등 띄우는 거? 우리 중국 문화다. 동북공정 영화입니다. 영화는 자세히 보세요. 의도가 있습니다. \" href=\"javascript:void(0);\" onclick=\"unfoldPointMent(this);\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t자세히 보면 중국 문화 올려치는 영화입니다. 초반부터 똥양계는 무조건 한국인 취급하는데 우리는 당당히 중국인이다. ㅇㅈㄹ하고요. 깊고 정통한 중국 문화는 대를 이어서 간다. 마카오에서 K-POP 댄스 추는 거 보고 ...\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>\n",
      "</span>\n",
      "</span>\n",
      "<span id=\"_filtered_ment_2\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t마블의 중국산 D-War \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "<span id=\"_filtered_ment_3\">\n",
      "<span class=\"_unfold_ment\" id=\"_unfold_ment3\">\n",
      "<a data-src=\"세계관이나 설정들이 너무 붕 떠있고 개연성은 밥말아 먹어놓고 억지 신파 끼워넣기에 주인공은 무색무취 아무 매력 없음. 10초전 까지 죽일듯이 싸우던 애들이 갑자기 우리 함께 싸우자 ㅇㅈㄹ 하질 않나. 아부지 행동들 감정기복 너무 심해서 공감도 안가고, 사건들이 빌드업도 없이 무지성으로 튀어나오니까 몰입도 안 됨. 배우가 너무 아깝다. \" href=\"javascript:void(0);\" onclick=\"unfoldPointMent(this);\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t세계관이나 설정들이 너무 붕 떠있고 개연성은 밥말아 먹어놓고 억지 신파 끼워넣기에 주인공은 무색무취 아무 매력 없음. 10초전 까지 죽일듯이 싸우던 애들이 갑자기 우리 함께 싸우자 ㅇㅈㄹ 하질 않나. 아부지 행동들 ...\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>\n",
      "</span>\n",
      "</span>\n",
      "<span id=\"_filtered_ment_4\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t마블의 탈을 쓴 중국 무협영화. 중국 시장과 자본을 지나치게 의식한 디즈니의 연이은 헛발질. CG 범벅에 협소한 공간에서 몇 안되는 인원들의 액션 등 스케일마저 왜 이리 작아진 건지... \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "<span id=\"_filtered_ment_5\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t하 정말 재미없네요.. \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "<span id=\"_filtered_ment_6\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t마블 영화를 본 건지 중국 영화를 본 건지 모르겠지만 양조위는 너무 멋있더라.... \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "<span id=\"_filtered_ment_7\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t마블의 새로운 시작이다… 재밌어요 \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "<span id=\"_filtered_ment_8\" style=\"display:none;\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t아부지를 왜케 미워하는거지 훈련빡시케 시켰다고 그러는건가아부지를 죽인댔다가 갑자기 필요하다하고 개연성이 좀 부족..텐링즈의 전설이란 제목도 뭐 굳이... \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "<span id=\"_filtered_ment_9\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t마블영화보면서 처음으로 졸았습니다 ㅜㅜ \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    html_reviews = html_source.find('span', {'id': '_filtered_ment_' + str(i)})\n",
    "    print(html_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "명품 브랜드라 믿고 샀는데 안에 made in china가 적혀있었다\n",
      "자세히 보면 중국 문화 올려치는 영화입니다. 초반부터 똥양계는 무조건 한국인 취급하는데 우리는 당당히 중국인이다. ㅇㅈㄹ하고요. 깊고 정통한 중국 문화는 대를 이어서 간다. 마카오에서 K-POP 댄스 추는 거 보고 ...\n",
      "마블의 중국산 D-War\n",
      "세계관이나 설정들이 너무 붕 떠있고 개연성은 밥말아 먹어놓고 억지 신파 끼워넣기에 주인공은 무색무취 아무 매력 없음. 10초전 까지 죽일듯이 싸우던 애들이 갑자기 우리 함께 싸우자 ㅇㅈㄹ 하질 않나. 아부지 행동들 ...\n",
      "마블의 탈을 쓴 중국 무협영화. 중국 시장과 자본을 지나치게 의식한 디즈니의 연이은 헛발질. CG 범벅에 협소한 공간에서 몇 안되는 인원들의 액션 등 스케일마저 왜 이리 작아진 건지...\n",
      "하 정말 재미없네요..\n",
      "마블 영화를 본 건지 중국 영화를 본 건지 모르겠지만 양조위는 너무 멋있더라....\n",
      "마블의 새로운 시작이다… 재밌어요\n",
      "아부지를 왜케 미워하는거지 훈련빡시케 시켰다고 그러는건가아부지를 죽인댔다가 갑자기 필요하다하고 개연성이 좀 부족..텐링즈의 전설이란 제목도 뭐 굳이...\n",
      "마블영화보면서 처음으로 졸았습니다 ㅜㅜ\n"
     ]
    }
   ],
   "source": [
    "# 10명 리뷰 확인, 불필요한 HTML 태그 제거\n",
    "for i in range(10):\n",
    "    html_reviews = html_source.find('span', {'id': '_filtered_ment_' + str(i)})\n",
    "    print(html_reviews.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10페이지에 대해 댓글 수집\n",
    "reviews_list = []\n",
    "for j in range(1, 11):\n",
    "    url='https://movie.naver.com/movie/bi/mi/pointWriteFormList.naver?code=187348&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page='+str(j)\n",
    "    html = urlopen(url)\n",
    "    html_source = BeautifulSoup(html, 'html.parser', from_encoding='utf-8') # 댓글 페이지를 utf-8 형식으로 html 소스 가져오기\n",
    "    \n",
    "    for i in range(10):\n",
    "        html_reviews = html_source.find('span', {'id':'_filtered_ment_' + str(i)})\n",
    "        reviews_list.append(html_reviews.text.strip())\n",
    "\n",
    "file = open('data/reviews.txt', 'w', encoding='utf-8')\n",
    "for review in reviews_list: # 요소를 1개의 행으로 저장되도록 개행문자 추가\n",
    "    file.write(review + '\\n') # 개행 문자 추가 --> Enter, 줄바꿈 효과\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) 크롤링한 데이터 전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/reviews.txt', 'r', encoding='utf-8') as f:\n",
    "    review_data = f.readlines()\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['명품 브랜드라 믿고 샀는데 안에 made in china가 적혀있었다\\n',\n",
       " '자세히 보면 중국 문화 올려치는 영화입니다. 초반부터 똥양계는 무조건 한국인 취급하는데 우리는 당당히 중국인이다. ㅇㅈㄹ하고요. 깊고 정통한 중국 문화는 대를 이어서 간다. 마카오에서 K-POP 댄스 추는 거 보고 ...\\n',\n",
       " '마블의 중국산 D-War\\n',\n",
       " '세계관이나 설정들이 너무 붕 떠있고 개연성은 밥말아 먹어놓고 억지 신파 끼워넣기에 주인공은 무색무취 아무 매력 없음. 10초전 까지 죽일듯이 싸우던 애들이 갑자기 우리 함께 싸우자 ㅇㅈㄹ 하질 않나. 아부지 행동들 ...\\n',\n",
       " '마블의 탈을 쓴 중국 무협영화. 중국 시장과 자본을 지나치게 의식한 디즈니의 연이은 헛발질. CG 범벅에 협소한 공간에서 몇 안되는 인원들의 액션 등 스케일마저 왜 이리 작아진 건지...\\n',\n",
       " '하 정말 재미없네요..\\n',\n",
       " '마블 영화를 본 건지 중국 영화를 본 건지 모르겠지만 양조위는 너무 멋있더라....\\n',\n",
       " '마블의 새로운 시작이다… 재밌어요\\n',\n",
       " '아부지를 왜케 미워하는거지 훈련빡시케 시켰다고 그러는건가아부지를 죽인댔다가 갑자기 필요하다하고 개연성이 좀 부족..텐링즈의 전설이란 제목도 뭐 굳이...\\n',\n",
       " '마블영화보면서 처음으로 졸았습니다 ㅜㅜ\\n',\n",
       " '일라오이 VS 사일러스\\n',\n",
       " '진짜 개노잼이다 와 이렇게 재미없는 마블영화도 첨\\n',\n",
       " '마블 영화라 믿기지 않을 정도로 지루해.. 졸려 죽는 줄 알았다ㅠ\\n',\n",
       " '노잼, 개연성 제로, 중국산 웹툰 느낌\\n',\n",
       " '이게뭐냐 진짜 마블 실망\\n',\n",
       " '전형적인 서양에서 생각하는 온갖 동양 클리셰는 몽따 넣은 영화 .. 보면서 불편\\n',\n",
       " '보는내내ㅠ드는 생각....왜 총안씀...?\\n',\n",
       " '솔직히 샹치 캐릭터의 매력이 뭔지 잘모르겠고 용타고 날라다닐땐 마블이 왜 저러나싶음...샹치 표정연기 못해서 캐릭터 몰입안됨..미스캐스팅....연기도 별로...캐릭들의 감정 이입도 어색하고(양조위 제외) 진행 전개도...\\n',\n",
       " '자기 어머니를 죽인 집단을, 다시 복수하는건데, 그걸 굳이 아버지를 미워하게 되는 관점이 좀 웃기긴함. 훈련과정속에서는 딱히 미워할요소가 없는데. 그리고 젤 황당했던게, 천년간 텐링즈끼고 잘 살아왔는데 난데없이 싸우...\\n',\n",
       " '마블에서 디워를 만들면 이렇겠구나\\n',\n",
       " '보지마.... 그냥 길에 돈과 시간을 버리자\\n',\n",
       " '마블을 기대하고 갔다가 추억의 중국무술영화 보고옴. 중국무술영화 좋아하던 분들은 재밌겠네. 난 뭘 보고온거지....\\n',\n",
       " '뛰쳐나갈뻔 개인적으로 구데기\\n',\n",
       " '마블빠돌인데 난 왤캐 별로였지...중국권문화라 거부감이 들어서인가? 그냥 그 마을 들어갈때부터 뭔가 이상했음양조위는 진짜 잘생겼고 여지껏 마블에서 볼수없었던 액션이기에 신선했음.암튼 샹치데뷔를 축하합니다\\n',\n",
       " '영상미나 액션은 정말 좋았는데 뭔가 내용 전개자체는 마블답지 못한느낌이였음 중국산무협느낌은 있을수밖에 없다고 쳐도 수룡과 괴물의 싸움은 뭔가 좀 이질감드는느낌이였고 수룡얼굴이 너무 귀여웠음 디지니 애니메이션에 나올것...\\n',\n",
       " '영상미 이런건 좋앗지만 그냥 중국영화 보는느낌이엿습니다,\\n',\n",
       " '액션은 확실히 엄청났다.하지만 영화는 액션이 전부가 아니다스토리가 어설프니 개연성이 부족하고, 개연성이 부족하니 영화에 몰입할 수 없다.이는 곧 영화가 노잼이라는 걸 의미한다.감상포인트를 하나 강제로 선택해야 하기에...\\n',\n",
       " '마블영화맞냐 넷플로 출시해도 볼까말까한 전형적인 짱깨영화\\n',\n",
       " '개인적으로 초반 30분은 신선했으나 이후부터는 흔한 쿵푸액션. 오그라들까말까 뜬금없을까말까 아슬아슬하게 선타기하는 신파와 스토리진행. cg와 영상미는 너무 좋았음\\n',\n",
       " 'ㅋㅋㅋ 아니 왜ㅋㅋㅋ 나는 재밋었는데 ㅋ디워보다는 솔직히 낫ㅈㅣ ㅋ\\n',\n",
       " '양조위와 나머지의 전설...\\n',\n",
       " '개연성 부족, 떡밥 회수 부족, 텐링즈 설명 부족\\n',\n",
       " '진짜 재밌어? 진짜???\\n',\n",
       " '그냥저냥 짱캐풍 오락영화\\n',\n",
       " '제발 악플 쓸거면 제대로 알고 등록합시다. 중국 자본 1도 안 들어간 영화고 중국에서 상영 금지된 영화입니다. 주인공 배우도 중국인 아니고 캐나다 국적의 배우입니다. 후반부의 플롯은 살짝 아쉬웠지만 영화 자체의 영상...\\n',\n",
       " '전혀 웃기지 않은 개그. 실제로 보면 민폐일것 같은 여친. 중국풍 CG 덩어리. 모든게 마블 답지 않았다. CG로 된 짜치는 용이 나온 순간 영화 자체가 그냥 흔한 중국 영화가 되어버렸다. 뜬금없는 중국속 구미호, ...\\n',\n",
       " '음 그냥 중국영화 딱 중국영화 그이상도 그이하도 아니다 중화 사상은 없는데 어디서 많이 본듯한 중국 무렵 영화 장면을 그대로 보는 듯 하고 발전이 없다. 영화 유투버들이 호들갑 떨면서 중국 느낌 없다고 해서 봤지만 ...\\n',\n",
       " '샹치와 아콰피나 친구컨셉으로 가자,러브라인으로 가면 못보겠슴\\n',\n",
       " '정말 마블의 영웅 서사는 기본기가 좋네요. 양조위는 신의 한 수!\\n',\n",
       " '중국영화에 마블스티커\\n',\n",
       " '와 액션 존윅급 꼭 강추 홀리몰리\\n',\n",
       " '그냥 중국 무협지 한편 봤다...중국영화 좋아하면 추천...아니면 노...\\n',\n",
       " '개인적으로 마블 영화의 강점은 확고한 그들만의 세계관과 그에따른 설득력이라 생각했는데. 샹치. 마블 히어로가 맞는가? 좀 더 완성도 있게 만든 중국무협영화 아니고? 천하의 마블이 양조위  포스에 묻어가려는 판이라니....\\n',\n",
       " '시사회를 보고 온 사람으로 말씀드리지만 절대로 중국을 위한 영화가 아닌 그냥 마블 영화입니다. 중국투자를 받지 않았고, 양조위씨와 양자경씨는 중국 블랙리스트 배우들인데 중국을 위한 영화였다면 왜 이들을 썼을까요? 제...\\n',\n",
       " '양조위가 너무 연기 잘함.  샹치보다 더 뇌리에 남음.  무술은 최고점!!!\\n',\n",
       " '그냥 중국영화 줫노잼 스킵해도 됨\\n',\n",
       " '마블 영화라고 너무 기대함\\n',\n",
       " '마블 계급장 떼고 봐도 이건 진짜 역대급 영화임.. 스토리 좋았고 특히나 영상미는 미친 퀄리티임 진짜.\\n',\n",
       " '지루한 서사.. 갑자기 초인적 능력이 생기는게 이해가 안됨. 굳이 샹치 솔로무비가 필요했나 싶음. 솔로 없이 자연스레 마블에 합류했어도 될 것 같았음. 갠적으로 마블이 버리는 카드가 아닌가 싶었음.\\n',\n",
       " '모자란 개연성에 인공호흡하는 양조위의 연기만 남은 영화\\n',\n",
       " '디워의 재림이란 말이 괜히 나온게 아니네  동양판타지 요소를 너무 과하게 넣음.. 특히 마지막 진 보스와 쫄따구 디자인은 어거지로 급하게 만들어 넣은느낌\\n',\n",
       " '양조위 말고는 딱히 남는 게 없는\\n',\n",
       " '여기 댓글창 무슨일? 다들 샹치가 중국현지 개봉 및 홍보 금지처분 받은건 알고 말하는건가 감독님은 하와이안이고 케이티역인 아콰피나는 한국계 미국인이고 심지어 샹치 역을 맡은 시무리우 배우는 캐나다 이민 출신인데 할머...\\n',\n",
       " '다른 건 모르겠고 양조위 형님 얼굴에 주름 생긴 거 보니 가슴이 아파온다.\\n',\n",
       " '미친 액션.. 진짜 화려해요양조위님은.. 늙지도 않으시고 너무 멋지고 애잔한 연기 좋아요\\n',\n",
       " '마지막 10분 정도만 존재감이 나타나는 주인공과 왠지 모르게 웃음이 나오는 액션씬. 디워와 쿵푸 팬더를 합쳐놓은 듯하다.\\n',\n",
       " '아니 마블 원작은 알고서 사람들이 욕을 하는건지 애초에 샹치라는 캐릭터 자체가 중국계 캐릭터고 마블에 이미 예전부터 샹치를 다루는 영화를 만들거라고 마블의 새로운 액션을 시도하겠다고 오래전부터 예고하고 있었는데무작정...\\n',\n",
       " '막 재밌다는건 아니고 쓰읍 하 아 뭐랄까 그냥 중국??\\n',\n",
       " '이게 슈X 드래곤볼이지 마블이아?\\n',\n",
       " '액션 ok 근데 이야기의 큰 줄기가 없다. 그냥 개연성이 부족한 오락영화\\n',\n",
       " '양조위 진짜 미쳤다 액션 눈빛 영어 다 대대대대존멋ㅠㅠ 액션 스케일도 쩔고 재밌는데 기승전 양조위 진짜 미쳤음\\n',\n",
       " '크게 기대는 안했지만 마블영화같지도않고 기대치보다도 낮네요.마블영화인데 보다가 졸았습니다.\\n',\n",
       " '이건 너무 충격적이다..마블 ㅂㄷ\\n',\n",
       " '영화관을 나오는데...장어먹고 싶드라..\\n',\n",
       " '마블 팬이라면 볼만하다는 댓글이 있는데 무슨소리인지 모르겠다. VOD로도 진짜 보기 아깝다.\\n',\n",
       " '용이랑 괴물이 싸우는 장면에서 b급 중국영화 느낌이 나서 아쉬웠음\\n',\n",
       " '마블답지 않은 전개에요\\n',\n",
       " '마블 껍데기 쓴 뻔한 중국 영화\\n',\n",
       " '너무 여러 가지 요소들을 짬뽕시켜놔서 좀 뜬금없는 느낌이 있었음\\n',\n",
       " '역시 cg처리를 비롯한 영상미는 끝내줬어요. 근데 너무나도 중국중국중국,, 언어만 영어를 사용할 뿐 언어를 제외한 영화의 모든게 중국!!! 내용도 뻔하고,,, 마블처돌이는 샹치를 보고 웁니다 ㅜㅅㅜ\\n',\n",
       " '마블을 보는건지, 중국영화를 보는건지...용 나올땐 어이가 없더라구요.영화전개도 별로고 마음에 드는게 하나도없었네요 ㅜ 영화보다가 잘뻔.\\n',\n",
       " '양조위씨 아버지의 애증연기가  다했습니다\\n',\n",
       " '뒷부분 하이라이트보다 앞부분 버스 씬이 더 샹치스러웠다\\n',\n",
       " '양조위와 텐 링즈의 전설\\n',\n",
       " '갠적으루 웬우 서사가 샹치 서사보다 더 좋았다ㅎㅎㅎ\\n',\n",
       " '와...나 양조위 좋아하네\\n',\n",
       " '초중반까지 분위기 좋다가 갑자기 중국전통 판타지 무협영화가 되버려서 아쉬웠네요.\\n',\n",
       " '뭐 액션은 말이 필요없는 수준이고 마지막 클라이맥스 씬에서 스케일이나 영상미가 예술이었음ㅋㅋㅋ  페이즈 4에서 아주 중요한 영화인 듯하니 아이맥스로 꼭 보시길!\\n',\n",
       " '양조위만 남았다..\\n',\n",
       " '중국풍이 넘 강해서 생각만큼 재밌진 않음 그냥 마블이라서 봄\\n',\n",
       " '액션에 공들인 게 확연히 느껴진다. 여느 슈퍼히어로 영화들과 같이 스토리 자체는 지극히 평범했다. 예상했던 대로 할리우드 특유의 오리엔탈리즘도 부각되었다. 이러한 점들을 감안해도 이 정도 완성도를 뽑아냈다는 것에 만...\\n',\n",
       " '세상에 존재하는 클리셰는 다 집어넣은듯ㅋㅋㅋ 액션 많은건 좋은데 싸우다가 왜 죽는거 구경만 하는거에 답답함을 느낌\\n',\n",
       " '쿠키영상이 다했다 내용도 뻔한 클리셰지만 마블답게 잘 풀어낸거같음\\n',\n",
       " '마블영화라는 프레임에 속지마세요~\\n',\n",
       " \"호불호가 많이 갈리네요 전 '호'였습니다\\n\",\n",
       " '아버지를 저렇게까지 미워하는 게 좀 공감이 안갔다.\\n',\n",
       " '머리는 샹치 응원하는데,, 마음은 양조위 응원함,, 명불허전 양조위ㅠㅠ\\n',\n",
       " '편의점 집 아들이 많이 컸네\\n',\n",
       " '중국맛이랑 헐리우드맛이랑 잘 섞어놨다고 생각하고, 나는 뭐 영화보는데 불편하지 않았고 액션 좋고 재밌었다.\\n',\n",
       " '마블 영화 중에 제일 재미없게 봤음ㅠㅠ\\n',\n",
       " '이번건 마블영화야 중화사상 영화가 아니라고..\\n',\n",
       " '오랜만에 잘잤다 덕분에 꿀잠\\n',\n",
       " '진심 중국은 마블 내에서도 민폐네요 중국산은 어떻게든 위상 높일려고 안달난 느낌 올림픽이든 뭐든 다 발악하겠지만 아무도 인정 안해줍니다\\n',\n",
       " '마블 영화 중 최악ㅎㅎㅋㅋ\\n',\n",
       " '재미도 없고 그냥 다 별로..\\n',\n",
       " '양조위는 항상 옳다\\n',\n",
       " '샹치의 매력은 잘 모르겠으나 양조위는 좋았음\\n',\n",
       " '진짜 댓글 수준 와……아직 보지도 않았는데 봤다고 하는 사람도 있고, 여기서 쓸데없는 얘기하는 사람들도 있고ㅋㅋㅋ\\n',\n",
       " '샹치배우 최선이었나\\n',\n",
       " '쿠키 외엔 액션 합 정도만 볼만한 영화. 그나마 양조위 아저씨는 개멋지긴 하다.토르2 이후로 처음으로 영화보다 잠들어 버림\\n']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) 한글만 남기고 다른 글자 제거**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아부지를왜케미워하는거지훈련빡시케시켰다고그러는건가아부지를죽인댔다가갑자기필요하다하고개연성이좀부족텐링즈의전설이란제목도뭐굳이\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "tmp = re.sub('[^가-힣]', '', review_data[8])\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아부지를왜케미워하는거지훈련빡시케시켰다고그러는건가아부지를죽인댔다가갑자기필요하다하고개연성이좀부족텐링즈의전설이란제목도뭐굳이\n"
     ]
    }
   ],
   "source": [
    "tmp = re.sub(' +', ' ', tmp)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아부지를 왜 케미워하는 거지 훈련 빡시케시켰다고 그러는 건가 아부지를 죽인 댔다가 갑자기 필요하다 하고 개연성이 좀 부족텐링즈의 전설이란 제목도 뭐 굳이\n"
     ]
    }
   ],
   "source": [
    "from pykospacing import Spacing\n",
    "\n",
    "spacing = Spacing()\n",
    "kospacing_sent = spacing(tmp)\n",
    "\n",
    "print(kospacing_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아버지를 왜 게 미워하는 거지 훈련 빡세 케시 켰다고 그러는 건가 아버지를 죽인 댔다가 갑자기 필요하다 하고 개연성이 좀 부족텐링즈의 전설이란 제목도 뭐 굳이\n"
     ]
    }
   ],
   "source": [
    "from hanspell import spell_checker\n",
    "\n",
    "spelled_sent = spell_checker.check(kospacing_sent)\n",
    "hanspell_sent = spelled_sent.checked\n",
    "print(hanspell_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **6. Transformer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.1 Intro**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer는 2017년 구글이 발표한 논문인 [Attention is all you need](https://arxiv.org/abs/1706.03762)에서 나온 모델로 기존의 seq2seq의 구조인 인코더-디코더의 구조는 따르면서 attention만으로 구현한 모델입니다. 이 모델은 RNN을 사용하지 않았음에도 RNN보다 더 좋은 성능을 보여줍니다. \n",
    "\n",
    "시작에 앞서 트랜스포머의 하이퍼파라미터를 정의하겠습니다. 하이퍼파라미터에 대한 설명은 뒤에 이어 나오고 여기선 정의만 먼저 하겠습니다. 수치는 논문에서 제의한 수치이고 사용자가 임의로 변경할 수 잇는 값들입니다.\n",
    "\n",
    "* $d_{model}$ = 512  \n",
    "트랜스포머의 인코더와 디코더에서 정해진 입력과 출력의 크기를 의미합니다. 임베딩 벡터의 차원 또한 $d_{model}$이며, 각 인코더와 디코더가 다음 층의 인코더와 디코더로 값을 보낼 때에도 이 차원을 유지합니다. 논문에선 512로 정의했습니다.  \n",
    "\n",
    "$$ $$\n",
    "\n",
    "* num_layers = 6  \n",
    "트랜스포머에서 하나의 인코더와 디코더를 층으로 생각했을 때, 트랜스포머 모델에서 인코더와 디코더가 총 몇 층으로 구성되었는지를 의미합니다. 논문에선 6으로 정의했습니다.\n",
    "\n",
    "$$ $$\n",
    "\n",
    "* num_heads = 8  \n",
    "트랜스포머에선 어텐션을 병령로 수행하는데 이때 병렬의 개수를 의미합니다. 논문에선 8로 정의했습니다.\n",
    "\n",
    "$$ $$\n",
    "\n",
    "* $d_{ff}$ = 2048  \n",
    "트랜스포머 내부에는 피드 포워드 신경망이 존재하며 해당 신경망의 은닉층의 크기를 의미합니다. 피드 포워드 신경망의 입력층과 출력층의 크기는 $d_{model}$입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set_context(context=\"talk\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.2 Transformer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"http://jalammar.github.io/images/t/The_transformer_encoders_decoders.png\">\n",
    "\n",
    "트랜스포머는 RNN을 사용하지 않지만 기존 seq2seq처럼 인코더에서 입력 시퀀스를 입력받고 디코더에서 출력 시퀀스를 출력하는 인코더-디코더 구조를 유지하고 있습니다. 이전 seq2seq 구조에서 인코더와 디코더가 각각 하나의 RNN이 t개의 시점을 가지는 구조였다면 이번에는 인코더와 디코더라는 단위가 N개로 구성되는 구조입니다. 논문은 각각 6개로 설정했습니다.\n",
    "\n",
    "<img src = \"http://jalammar.github.io/images/t/The_transformer_encoder_decoder_stack.png\">\n",
    "\n",
    "위 그림이 인코더와 디코더가 6개씩 존재하는 트랜스포머의 구조를 보여줍니다. \n",
    "\n",
    "![transformer](_image/4-6-1.PNG)\n",
    "\n",
    "트랜스포머의 전체적 구조는 위와 같습니다. 복잡하고 어려운 것들이 많아 보이지만 하나씩 뜯어가며 살펴보겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.3 Positional Encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "트랜스포머의 내부를 보기 전에 입력을 먼저 알아보겠습니다. RNN은 단어의 위치에 따라 순차적으로 입력을 받기에 자연스레 위치 정보를 가질 수 있다는 장점이 있었습니다. \n",
    "\n",
    "하지만 트랜스포머는 단어의 입력을 순차적으로 받지 않기에 위치 정보를 저장하지 못합니다. 그렇기에 포지셔널 인코딩(positional encoding)을 통해 위치 정보를 더하여 입력으로 사용하게 됩니다. \n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_positional_encoding_vectors.png\">\n",
    "\n",
    "위 그림을 보면 입력이 들어가기 전에 입력값인 임베딩 벡터에 포지셔널 인코딩이 더해지는 것을 볼 수 있습니다. \n",
    "\n",
    "만약 임베딩 크기가 4라고 가정한다면, 실제로 각 위치에서 따른 포지녀설 인코딩은 아래와 같이 계산됩니다.\n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_positional_encoding_example.png\">\n",
    "\n",
    "이때 포지셔널 인코딩 벡터를 정하기 위해 아래의 두 함수를 사용합니다. (이것은 Sinusoidal Position Embedding이라고 합니다.)\n",
    "\n",
    "$$PE_{(pos, 2i)} = sin(pos/10000^{2i/d_{model}})$$\n",
    "$$PE_{(pos, 2i + 1)} = cos(pos/10000^{2i/d_{model}})$$\n",
    "\n",
    "sin과 cos함수의 값을 더해주므로 단어의 순서 정보를 더해주는 것입니다. 밑의 그래프는 임베딩 크기가 4일 때, 포지셔닝 인코딩을 해주기 위해 구한 사인과 코사인 함수의 그래프입니다.\n",
    "\n",
    "<img src = \"http://nlp.seas.harvard.edu/images/the-annotated-transformer_49_0.png\">\n",
    "\n",
    "위에서 x축은 단어의 순서입니다. 이를 기준으로 결정되는 4개의 값(임베딩 크기가 4이므로 그래프가 4개)으로 포지셔닝 인코딩 벡터를 만들어 더해주는 것입니다. \n",
    "\n",
    "좀 더 자세히 살펴보겠습니다. \n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/31379/transformer7.PNG\">\n",
    "\n",
    "pos는 입력 문장에서 임베딩 벡터의 위치를 나타내며 i는 임베딩 벡터 내의 차원 인덱스를 의미합니다. 위 식을 보면 알 수 있듯 인덱스가 짝수인 곳은 sin 함수, 인덱스가 홀수인 곳은 cos 함수를 사용합니다. 또한 위 식에서 $d_{model}$은 트랜스포머의 모든 층의 출력 차원을 의미하는 하이퍼파라미터입니다. 임베딩 벡터 또한 $d_{model}$의 크기를 가지며 위 그림에선 4, 논문에선 512로 정의되어있습니다. \n",
    "\n",
    "이렇게 같은 단어가 들어와도 순서 정보가 합쳐져 다른 임베딩 벡터가 만들어지게 됩니다. 이를 코드로 구현하면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Implement the PE function\"\"\"\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x += Variable(self.pe[:, :x.size(1)], requires_grad=False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1173f31f430>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "pe = PositionalEncoding(20, 0)\n",
    "y = pe.forward(Variable(torch.zeros(1, 100, 20)))\n",
    "plt.plot(np.arange(100), y[0, :, 4:8].data.numpy())\n",
    "plt.legend([\"dim %d\"%p for p in [4, 5, 6, 7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 임베딩 벡터의 차원 128, 문장의 길이 50\n",
    "sample_pos_encoding = PositionalEncoding(128, 0, 50)\n",
    "\n",
    "y = sample_pos_encoding.forward(Variable(torch.zeros(1, 50, 128)))\n",
    "plt.pcolormesh(y[0])\n",
    "plt.xlabel(\"Depth\")\n",
    "plt.xlim((0, 128))\n",
    "plt.ylabel(\"Position\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.4 Trasformer에서 사용되는 Attention**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://wikidocs.net/images/page/31379/attention.PNG\">\n",
    "\n",
    "트랜스포머에선 위 그림에 나타난 세 가지 어텐션을 사용합니다. 첫번째 어텐션은 인코더에서, 두번째와 세번째 어텐션은 디코더에서 사용됩니다. 셀프 어텐션은 본질적으로 쿼리(Query), 키(Key), 값(Value)가 동일한 경우(출처가 같다)를 말합니다. 그렇기에 세번째 어텐션의 경우 쿼리는 디코더의 벡터, 키와 값는 인코더의 벡터이므로 셀프 어텐션이 아닙니다. \n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/31379/transformer_attention_overview.PNG\">\n",
    "\n",
    "위 그림은 각각의 어텐션이 위치하는 곳을 표시한 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.5 Encoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 인코더에 대해서 알아보겠습니다.\n",
    "\n",
    "![encoder](_image/4-6-2.PNG)\n",
    "\n",
    "트랜스포머는 하이퍼파라미터인 num_layers(위 그림에서 N) 개수의 인코더 층을 쌓습니다. 논문은 6개의 층을 쌓았습니다. 하나의 인코더 층은 크게 attention과 feed forward 두 개의 서브층(sublayer)으로 나뉘어집니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) Self-Attention**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어텐션 함수는 주어진 쿼리에 대해서 모든 키와의 유사도를 구합니다. 그리고 구한 유사도를 가중치로 사용하여 키와 맵핑되어있는 각각의 값에 반영합니다. 그리고 유사도가 반영된 값을 모두 가중합하여 출력합니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/22893/%EC%BF%BC%EB%A6%AC.PNG\">\n",
    "\n",
    "이것이 앞서 배운 어텐션의 기본 개념입니다. 여기서 주어진 쿼리, 키, 값의 의미는 다음과 같습니다.\n",
    "\n",
    "- Q(Query): 모든 시점의 디코더 셀에서의 은닉 상태들\n",
    "- K(Keys): 모든 시점의 인코더 셀의 은닉 상태들\n",
    "- V(Values): 모든 시점의 인코더 셀의 은닉 상태들\n",
    "\n",
    "기존 어텐션은 위처럼 Q와 K가 다른 값을 가지고 있었습니다. 그러나 셀프 어텐션(self-attention)은 Q, K, V가 모두 동일합니다. 그렇기에 트랜스포머에서 Q, K, V는 다음과 같습니다.\n",
    "\n",
    "- Q(Query): 입력 문장의 모든 단어 벡터들\n",
    "- K(Keys): 입력 문장의 모든 단어 벡터들\n",
    "- V(Values): 입력 문장의 모든 단어 벡터들\n",
    "\n",
    "이를 도입한 이유는 모델이 단어들을 인코딩할 때, 다른 단어들을 보고 더 정확한 인코딩을 하도록 만들기 위함입니다. 예를 들어 \"The animal didn't cross the street because it was too tired.\"라는 문장이 있을 때, \"it\"은 무엇일까요? 사람은 \"animal\"이란 것을 알 수 있지만 기계는 \"animal\"과 \"street\" 중 쉽게 고르지 못합니다. 이를 방지하기 위해 현재 처리 중인 단어와 연관 있는 다른 단어들의 맥락을 고려하여 임베딩하는 것입니다.\n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_self-attention_visualization.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) Scaled dot-product Attention**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q, K, V 벡터 생성**\n",
    "\n",
    "셀프 어텐션은 첫번째로 인코더에 입력된 벡터로부터 Q, K, V라는 3개의 벡터를 만들어냅니다. 이 벡터들은 입력 벡터에 대해서 세 개의 학습 가능한 행렬들을 각각 곱함으로 만들어집니다.\n",
    "\n",
    "이때 Q, K, V 벡터들은 초기 입력인 $d_{model}$보다 작은 차원을 가집니다. 논문에선 $d_{model}$이 512인데 반해 새로운 벡터들의 차원은 64입니다. 그러나 꼭 작아야하는 것은 아닙니다. 여기서 새로운 벡터들의 차원을 작게 한 이유는 multi-head attention의 계산 복잡도를 일정하게 만들기 위함일 뿐입니다.  \n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_self_attention_vectors.png\">\n",
    "\n",
    "위 그림에서 $x_1$에 가중치 행렬 $W_Q$를 곱하여 현재 단어와 연관된 쿼리 벡터 $q_1$을 생성합니다. 마찬가지로 다른 $q_1, \\; k_1, \\; v_1$ 벡터도 만들어집니다. 이때 각 가중치 행렬은 $d_{model} \\times (d_{model}\\;/num\\_heads)$의 크기를 가집니다. 논문과 같다면 $d_{model}=512, \\; num\\_heads=8$로 64의 크기를 가지는 $q_1, \\; k_1, \\; v_1$벡터가 만들어집니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**어텐션 점수 계산**\n",
    "\n",
    "두번째로 어텐션 점수를 계산합니다. 아래 예시의 첫번째 단어인 \"Thinking\"에 대해 계산한다고 하겠습니다. 그렇다면 \"Thinking\"과 입력 문장 속 다른 모든 단어들에 대해서 점수를 구해야 합니다. 이 점수가 추후 인코딩할 때, 다른 단어들에 대해 얼마나 집중해야 할 지 결정합니다.\n",
    "\n",
    "점수는 현재 단어의 쿼리 벡터와 다른 단어의 키 벡터의 내적으로 계산됩니다. 즉, 유사도와 동일합니다.\n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_self_attention_score.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Softmax**\n",
    "\n",
    "이제 점수들을 키 벡터의 크기인 $d_k$의 제곱근인 $\\sqrt{d_k}$로 나눠줍니다. 이는 값들을 전체적으로 0과 가깝게 만들어줍니다. 그래서 소프트맥스의 대소 관계를 바꾸진 않지만 서로의 격차를 줄여주고 가중치가 하나로 쏠리는 현상을 막아줍니다. (더 안정적인 gradient를 가지게 만듭니다.) 그리고 이 값을 softmax 계산을 통해 각 단어의 표현이 얼마나 들어갈지 결정합니다. \n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/self-attention_softmax.png\">\n",
    "\n",
    "대부분 현재 단어의 위치가 가장 높은 점수를 받지만 가끔씩 다른 단어에 정보가 들어가는 것이 도움이 될 때도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**가중합**\n",
    "\n",
    "막바지입니다. 이제 각 단어들의 V 벡터에 이 점수를 곱합니다. 즉, 가중치들을 곱해줍니다. 그리고 구해진 벡터들을 모두 합하여 출력시킵니다. 출력된 값은 Add & Norm을 거쳐 Feed Forward에 입력값으로 들어갑니다.\n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/self-attention-output.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) Scaled dot-product attention을 행렬 연산으로**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 계산은 각 벡터들의 계산으로 진행되었습니다. 그러나 실제 구현에서는 빠른 속도를 위해 행렬의 형태로 진행됩니다.\n",
    "\n",
    "먼저 입력 문장에 대해 Q, K, V의 행렬들을 계산합니다. 이를 위해 입력 벡터들을 하나의 행렬 X로 쌓아 올리고 그것을 우리가 학습할 $W_Q, W_K, W_V$로 곱합니다.\n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/self-attention-matrix-calculation.png\">\n",
    "\n",
    "그리고 이 후는 위에서 했던 것과 동일합니다. Q와 K의 전치 행렬을 곱하고 K의 차원의 제곱근으로 나눠준 뒤, 소프트맥스를 하고 V를 곱해 값을 구하는 단계를 차근차근 거치면 됩니다.\n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/self-attention-matrix-calculation-2.png\">\n",
    "\n",
    "이를 식으로 표현하면 다음과 같습니다. \n",
    "\n",
    "$$Attention(Q, K, V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V$$\n",
    "\n",
    "이때 구해지는 행렬을 A라고 할 때, A의 크기는 (seq_len, $d_V$)가 됩니다. 여기서 seq_len은 문장의 길이입니다. Q와 K의 크기가 (seq_len, $d_K$), V의 크기가 (seq_len, $d_V$)이므로 결과적으로 위와 같은 결과가 나오는 것입니다. 단 논문에서는 $d_{model}\\;/\\;num\\_heads=d_K=d_V$로 세 행렬의 크기가 모두 같습니다. \n",
    "\n",
    "이제 이를 코드로 표현해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"\"\"Compute Scaled Dot Product Attention\n",
    "\n",
    "    Args's size:\n",
    "        query: (batch_size, num_heads, query 문장 길이, d_model/num_heads(=d_k))\n",
    "        key: (batch_size, num_heads, key 문장 길이, d_model/num_heads(=d_k))\n",
    "        value: (batch_size, num_heads, value 문장 길이, d_model/num_heads(=d_k))\n",
    "        mask: (batch_size, 1, 1, key의 문장 길이)\n",
    "\n",
    "    Returns:\n",
    "        torch.matmul(p_attn, value): attention 연산의 결과인 행렬 A\n",
    "        p_attn: attention score\n",
    "    \"\"\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    \n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    \n",
    "    # softmax는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
    "    # p_attn: (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
    "    p_attn = F.softmax(scores, dim=-1)\n",
    "    \n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    \n",
    "    # torch.matmul(p_attn, value): (batch_size, num_heads, query의 문장 길이, d_model / num_heads)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "함수가 정상적으로 작동하는지 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 Q, K, V 행렬 생성\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# 소수점 첫째 자리까지 표시, 십진법으로 표현(5e+1 -> 50)\n",
    "torch.set_printoptions(precision=1, sci_mode=False)\n",
    "temp_k = torch.FloatTensor([[10, 0, 0],\n",
    "                            [0, 10, 0],\n",
    "                            [0, 0, 10],\n",
    "                            [0, 0, 10]]) # (4, 3)\n",
    "\n",
    "temp_v = torch.FloatTensor([[1, 0],\n",
    "                            [10, 0],\n",
    "                            [100, 5],\n",
    "                            [1000, 6]]) # (4, 2)\n",
    "\n",
    "temp_q = torch.FloatTensor([[0, 10, 0]]) # (1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 주목할 것은 쿼리의 값이 키의 두번째 행과 일치한다는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 0, 0]], dtype=torch.int32)\n",
      "tensor([[10,  0]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 함수 실행\n",
    "temp_out, temp_attn = attention(temp_q, temp_k, temp_v)\n",
    "print(temp_attn.type(torch.IntTensor)) # attention score\n",
    "print(temp_out.type(torch.IntTensor)) # attention output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q는 4개의 키 값 중 두번째 값과 일치하므로 점수 역시 [0, 1, 0, 0]임을 볼 수 있습니다. 그리고 그 결과로 V의 두번째 값인 [10, 0]이 나오는 것을 확인할 수 있습니다. \n",
    "\n",
    "이번엔 Q를 바꿔 다시 실행해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0.00,     0.00,     0.50,     0.50]])\n",
      "tensor([[550.00,   5.50]])\n"
     ]
    }
   ],
   "source": [
    "temp_q = torch.FloatTensor([[0, 0, 10]])\n",
    "temp_out, temp_attn = attention(temp_q, temp_k, temp_v)\n",
    "print(temp_attn) # attention score\n",
    "print(temp_out) # attention output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "점수가 [0, 0, 0.5, 0.5]가 나온 것은 세번째 값과 네번째 값 두 개의 값이 유사하다는 의미입니다. 그렇기에 결과적으로 나온 [550, 0.5]는 V의 세번째 값 [100, 5] * 0.5과 네번째 값 [1000, 6] * 0.5를 합친 값입니다. \n",
    "\n",
    "이번에는 3개의 Q 값을 입력으로 사용해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0.00,     0.00,     0.50,     0.50],\n",
      "        [    0.00,     1.00,     0.00,     0.00],\n",
      "        [    0.50,     0.50,     0.00,     0.00]])\n",
      "tensor([[  550.00,     5.50],\n",
      "        [   10.00,     0.00],\n",
      "        [    5.50,     0.00]])\n"
     ]
    }
   ],
   "source": [
    "temp_q = torch.FloatTensor([[0, 0, 10], [0, 10, 0], [10, 10, 0]])\n",
    "temp_out, temp_attn = attention(temp_q, temp_k, temp_v)\n",
    "print(temp_attn) # attention score\n",
    "print(temp_out) # attention output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaled Dot-Product Attention의 구조를 나타내면 다음과 같습니다.\n",
    "\n",
    "![sdpa](_image/4-6-3.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4) Multi-head Attention**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mha](_image/4-6-4.PNG)\n",
    "\n",
    "위 그림처럼 Multi-head Attention은 scaled dot-product attention을 병렬적으로 풀어 계산한 뒤 합치는 것을 의미합니다. 이는 $W_Q, W_V, W_K$을 여러 개 가지는 것입니다. 논문에서 정의한 num_heads가 바로 병렬의 개수를 지정하는 것으로 논문은 8로 정의했습니다. 이는 각각 독립적으로 학습되고 각 목적에 맞게 투영시킵니다. 다른 시각으로 단어들의 관계들을 살펴보고 그것을 종합하여 사용하는 것입니다. \n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_attention_heads_qkv.png\">\n",
    "\n",
    "앞서 이야기했듯이 각 attention head마다 $W_Q, W_V, W_K$을 가집니다. 그렇기에 Q, V, K 행렬도 각 head마다 생성됩니다. 각 head마다 self-attention 과정을 거치면 head 개수만큼 결과가 나옵니다. 이를 feed-forward layer로 보내기 위해선 이를 하나의 행렬로 합쳐야 합니다. \n",
    "\n",
    "이를 위해 일단 모두 이어 붙여서 하나의 행렬로 만들어줍니다. 그리고 output을 위한 또다른 가중치 행렬 $W_O$를 곱해버립니다. \n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_attention_heads_weight_matrix_o.png\">\n",
    "\n",
    "이제 인코더의 과정을 한 눈으로 보겠습니다. \n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_multi-headed_self-attention-recap.png\">\n",
    "\n",
    "여기서 최종 결과물인 Z는 입력값인 X와 크기가 동일한 것을 알 수 있습니다. 이는 사실 당연한데 다음 인코더에 들어가기 위해서 크기가 유지되야 합니다. \n",
    "\n",
    "이제 예제 문장을 이용해 동작 결과를 보겠습니다.\n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_self-attention_visualization_2.png\">\n",
    "\n",
    "\"it\"이라는 단어에 대해 인코딩할 때, 주황색의 attention head는 \"The\", \"animal\"에 가장 집중하고 있는 반면 초록색의 attention head는 \"tire\"에 집중하고 있는 것을 볼 수 있습니다. 이렇게 두 단어의 representation을 \"it\"의 representation에 포함시킬 수 있습니다.\n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_self-attention_visualization_3.png\">\n",
    "\n",
    "그러나 위처럼 모든 attention head를 하나로 표시하면 알아보기가 너무 어려워집니다.\n",
    "\n",
    "이제, Multi-head Attention 역시 코드로 구현해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"\"\"Take in model size and number of heads\"\"\"\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        \n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "    \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"\"\"Implements Figure 2\"\"\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
    "        query, key, value = [\n",
    "            l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "            for l, x in zip(self.linears, (query, key, value))\n",
    "        ]\n",
    "        \n",
    "        # 2) Apply attention on all the projected vectors in batch.\n",
    "        x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout)\n",
    "        \n",
    "        # 3) \"Concat\" using a view and apply a final linear.\n",
    "        x = x.transpose(1, 2).contiguous().view(nbatches, -1, self.h * self.d_k)\n",
    "        \n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5) Padding Mask**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "함수 구현 코드들을 보면 mask라는 인자가 계속 주어집니다. 이 연산은 입력 문장에 \\<PAD> 토큰이 있을 경우 어텐션에서 제외하기 위한 연산입니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/31379/pad_masking2.PNG\">\n",
    "\n",
    "마스킹을 하는 방법은 마스킹 위치에 매우 작은 음수값($-\\infty$와 가까운 수)을 넣어주는 것입니다. 현재 어텐션 스코어 행렬은 소프트맥스를 지나지 않은 상태입니다. 그렇기에 소프트맥스를 지나며 0이 되고 단어 간 유사도를 구하는데 반영되지 않게 됩니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/31379/softmax.PNG\">\n",
    "\n",
    "위 그림은 소프트맥스를 지난 후입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.6 Common sublayer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인코더와 디코더에 동일하게 적용되는 sublayer들도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) Feed Forward**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed Forward(혹은 Position-wise FFNN)층은 인코더뿐만 아니라 디코더에도 존재합니다. 이를 쉽게 이야기하면 FC를 해주는 것입니다.\n",
    "\n",
    "$$FFNN(x) = MAX(0, xW_1+b_1)W_2 + b_2$$\n",
    "\n",
    "이를 그림으로 표현하면 다음과 같습니다. \n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/31379/positionwiseffnn.PNG\">\n",
    "\n",
    "여기서 x는 멀티 헤드 어텐션의 결과로 나온 (seq_len, $d_{model}$)의 크기를 가지는 행렬을 말합니다. 가중치 행렬 $W_1$은 ($d_{model}$, $d_{ff}$)의 크기를 가지고, 가중치 행렬 $W_2$는 ($d_{ff}, d_{model}$)의 크기를 가집니다. 논문에선 $d_{ff}$를 2048로 정의했습니다. \n",
    "\n",
    "여기서 매개변수 $W_1, b_1, W_2, b_2$는 하나의 인코더 내에서는 다른 문장, 다른 단어들마다 정확하게 동일하게 사용됩니다. 하지만 인코더 층마다는 다른 값을 가집니다. \n",
    "\n",
    "이를 코드로 구현하면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) The Residuals**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "구조를 보면 각 층 사이에 Add & Normalize가 있는 것을 확인할 수 있습니다. 여기서 Add는 residual connection을 의미하고 Norm은 layer normalization을 의미합니다. \n",
    "\n",
    "먼저 residual connection을 보겠습니다. \n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/31379/transformer22.PNG\">\n",
    "\n",
    "위에서 볼 수 있듯이 residual connection은 어떠한 층의 입력값과 출력값을 더하는 것을 말합니다. 이는 주로 컴퓨터 비전 분야에서 모델의 학습을 돕기 위해 사용되는 기법입니다. 이를 통해 역전파가 잘 수행되고 layer를 거칠 필요가 없는 벡터들은 0으로 만들고 입력값만 가져가도록(skip connection) 만들 수도 있습니다.\n",
    "\n",
    "residual connection이 끝나면 이어서 layer normalization을 진행합니다. Layer normalization은 텐서의 마지막 차원(즉 여기선 $d_{model}$)에 대해서 평균($\\mu$)은 0, 분산($\\sigma^2$)은 1이 되도록 정규화해주는 것입니다. \n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/31379/layer_norm_new_1_final.PNG\">\n",
    "\n",
    "정규화 수식은 간단하게 확인만 하겠습니다.\n",
    "\n",
    "$$\\hat{x}_{i, k} = \\frac{x_{i,k}-\\mu_i}{\\sqrt{\\sigma_i^2+\\epsilon}}$$\n",
    "\n",
    "$\\epsilon$은 분모가 0이 되는 것을 방지합니다. \n",
    "\n",
    "이제 $\\gamma$와 $\\beta$라는 벡터를 준비합니다. 이들의 초기값은 각각 1과 0으로만 이루어집니다. \n",
    "\n",
    "$$ln_i = \\gamma \\hat{x}_i + \\beta = LayerNorm(x_i)$$\n",
    "\n",
    "이 역시 코드로 구현해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(features))\n",
    "        self.beta = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.gamma * (x - mean) / (std + self.eps) + self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 과정을 합치면 다음과 같습니다. \n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_resideual_layer_norm_2.png\">\n",
    "\n",
    "이것은 디코더에서도 동일하게 적용됩니다. 만약 2개의 인코더와 디코더로 이루어진 단순한 형태의 트랜스포머를 생각하면 밑의 그림과 같습니다.\n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_resideual_layer_norm_3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) Encoder 구현**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인코더의 동작을 확인해봤습니다. 이제 인코더를 구현해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        \"Pass the input (and mask) through each layer in turn\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        \"Follow Figure 1 (left) for connections\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.7 Decoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_decoding_1.gif\">\n",
    "\n",
    "인코더 과정이 끝나면 디코더 과정이 시작됩니다. 디코딩 과정은 디코더가 출력을 완료했다는 \\<end of sentence>를 출력할 때까지 반복됩니다. 각 스텝마다 출력된 단어는 다음 스텝의 디코더 가장 아래로 들어가고 인코더와 마찬가지로 몇 개의 디코더를 거쳐 올라갑니다. 이때 인코더의 입력과 동일하게 포지셔닝 인코딩을 추가하여 디코더에게도 위치 정보를 저장합니다.\n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_decoding_2.gif\">\n",
    "\n",
    "디코더는 크게 3개의 sublayer가 있습니다. 그 중 첫 번째 층인 masked multi-head attention은 기존의 multi-head attention에 mask가 추가된 것입니다. 이는 디코더가 출력하는 과정에서 다음 단어를 미리 참조하지 못하도록 막는 역할을 합니다. \n",
    "\n",
    "![masked](_image/4-6-5.PNG)\n",
    "\n",
    "masked가 끝나면 re-normalization을 해줍니다. \n",
    "\n",
    "다른 두 개의 sublayer는 기본적으론 인코더의 sublayer와 동일합니다. 그러나 한 가지 차이점이 두 번째 multi-head attention에 있습니다. 그것은 바로 입력값입니다.\n",
    "\n",
    "![transformer](_image/4-6-6.PNG)\n",
    "\n",
    "다시 트랜스포머의 구조를 보겠습니다. 보면 Q는 디코더에서 올라오지만 K, V는 인코더에서 넘어오는 것을 확인할 수 있습니다. 이외에는 같은 동작을 합니다.\n",
    "\n",
    "논문에선 인코더 층의 마지막 output의 K, V를 모든 디코더 층의 입력으로 사용합니다.\n",
    "\n",
    "이 역시 코드로 구현해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"Generic N layer decoder with masking\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "    \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \"Decoder is made of self-attn, src-attn, and feed forward\"\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    "    \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        \"Follow Figure 1 (right) for connections\"\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        return self.sublayer[2](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1176fc0bdf0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(subsequent_mask(20)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.8 마지막 Linear Layer와 Softmax Layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러 개의 디코더를 거치고 나온 후에는 소수로 이루어진 벡터가 남습니다. 이를 단어로 바꾸기 위해 마지막으로 linear layer와 softmax를 거칩니다. \n",
    "\n",
    "linear layer는 FC 신경망으로 디코더가 마지막으로 출력한 벡터를 그보다 훨씬 더 큰 사이즈의 벡터인 logits 벡터로 투영시킵니다. 이때 logits 벡터의 크기는 우리가 가진 사전의 크기, 즉 모델이 학습한 단어의 총 개수가 됩니다. 각 인덱스마다 단어에 대한 점수가 매겨집니다.\n",
    "\n",
    "이를 바탕으로 softmax를 통해 확률로 변환해주고 가장 높은 확률을 가진 단어를 출력하게 됩니다.\n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_decoder_output_softmax.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.9 전체적인 학습 과정**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "트랜스포머에 대해 순차적으로 알아봤습니다. 이제 이를 어떻게 학습시키는지 알아보겠습니다.\n",
    "\n",
    "### **1) Pre-processing**\n",
    "\n",
    "먼저 학습 시작 전에 output vocabulary가 있어야 합니다. 6단어만 있다고 가정하겠습니다. 그리고 이 사전을 이용해 각 단어에 매칭되는 원-핫 벡터를 만들 수 있습니다. \n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/one-hot-vocabulary-example.png\">\n",
    "\n",
    "### **2) Loss Function**\n",
    "\n",
    "모델을 학습하는 가장 첫번째 단계라고 가정합시다. 그리고 학습을 위해 \"merci\"라는 프랑스어를 \"thanks\"로 번역하는 간단한 예시를 생각하겠습니다. 즉, 모델의 출력은 \"thanks\"라는 단어를 가리키는 확률 벡터라는 의미입니다. 그러나 모델이 학습되지 않았기에 출력이 제대로 나올 확률은 희박합니다.\n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_logits_output_and_label.png\">\n",
    "\n",
    "학습이 시작될 때, 모델의 parameter(가중치 행렬 등)이 무작위로 값이 부여되기에 그저 임의의 값만 출력할 뿐입니다. 이 출력된 값을 실제 값과 비교하면서 얻은 차이와 역전파 알고리즘을 이용해 현재 모델의 가중치들을 조절해 원하는 출력값에 가까워지도록 만듭니다. \n",
    "\n",
    "두 확률 벡터를 비교할 때는 cross-entropy나 Kullback-Leibler divergence를 이용합니다.\n",
    "\n",
    "하지만 주의해야 할 것은 예제가 지나치게 단순하다는 것입니다. 현실적인 예제는 한 단어보다 긴 문장을 이용하겠습니다. 입력은 “je suis étudiant”이며 바라는 출력은 “i am a student”입니다. \n",
    "\n",
    "- 각 단어에 대한 확률 분포는 output vocabulary의 크기를 가집니다. \n",
    "- decoder가 첫번째로 출력하는 확률 분포는 \"i\"라는 단어와 연관이 있는 cell에 가장 높은 확률을 줘야 합니다.\n",
    "- 두번째로 출력하는 확률 분포는 \"am\"이라는 단어와 연관이 있는 cell에 가장 높은 확률을 줘야 합니다.\n",
    "- 이와 동일하게 마지막 \"\\<end of sentence>\"를 나타내는 다섯번째 출력까지 이 과정은 반복됩니다. \n",
    "- 이때 \\<eos> 또한 그에 해당하는 cell을 벡터에서 가집니다. \n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/output_target_probability_distributions.png\">\n",
    "\n",
    "위 그림은 학습에서 목표로 하는 확률 분포를 나타낸 것입니다. \n",
    "\n",
    "모델을 큰 사이즈의 데이터 셋에서 충분히 학습시키고 나면, 그 결과로 생성되는 확률 분포들은 다음과 같아질 것입니다.\n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/output_trained_model_probability_distributions.png\">\n",
    "\n",
    "학습 과정 후, 모델은 정확한 번역을 출력할 것입니다. \n",
    "\n",
    "여기서 특이한 점 하나는 아무리 다른 단어들이 최종 출력될 확률이 거의 없다 해도 0보다는 조금 큰 값을 가진다는 것입니다. 이는 softmax layer의 유용한 성질입니다. \n",
    "\n",
    "모델은 한 스텝 당 확률이 가장 높은 단어 하나를 출력하기에 다른 단어는 버린다고 생각하기 쉽습니다. 그러나 그것은 `greedy decoding`이라는 한가지 방법에 불과하며 다른 방법들도 존재합니다. 예를 들어 가장 확률이 높은 두 개의 단어를 저장할 수 있습니다. (위 예시로 보자면 \"i\"와 \"student\") 그렇다면 우리는 모델을 두 번 돌리게 됩니다. 한 번은 출력이 'i'라고 가정하고 두번째는 출력이 'student'라고 가정하는 것입니다. 이렇게 나온 결과에서 첫번째 출력 단어와 두번째 출력 단어를 동시에 고려했을 때, 더 낮은 에러를 보이는 결과의 첫번째 단어가 실제 출력으로 선택됩니다. 이를 마지막 단계까지 반복합니다. 이러한 방법을 `beam search`라고 부르며, 고려하는 단어의 수를 beam size, 고려하는 미래 출력 개수를 top_beam이라고 합니다. 우리의 예제에서는 두 개의 단어를 저장했으므로 beam size는 2이며 두번째 단계까지 고려했으므로 top_beam 역시 2입니다. 이때 beam size와 top_beam은 우리가 지정할 수 있는 하이퍼파라미터입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.10 모델 구현**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실습 및 과제 폴더"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "- https://wikidocs.net/31379\n",
    "- http://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
    "- https://nlpinkorean.github.io/illustrated-transformer/  \n",
    "  (번역: https://lee-soohyun.tistory.com/262)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **7. Tokenization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization은 NLP 전처리에 해당하는 과정으로 text를 여러 개의 token으로 나누는 것을 말합니다. 어떤 기준으로 나누는지에 따라 크게 3개의 방법으로 나뉩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7.1 Word-based Tokenizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![wbt](_image/4-7-1.PNG)\n",
    "\n",
    "위 그림처럼 단어로 나누는 것이 Word-absed Tokenizer입니다. 영어의 경우, 띄어쓰기로 대부분 tokenization이 끝나기에 간단합니다. \n",
    "\n",
    "그러나 단어 기반의 tokenizer는 필연적으로 OOV(Out-of-Vocabulart) 문제를 가져옵니다. 이는 세상의 단어가 너무 많기에 그 단어를 모두 저장하고 임베딩하려면 전체 모델 메모리에서 차지하는 비중이 기하급수적으로(거의 90% 이상의) 증가하기에 정작 모델의 파라미터에 큰 비중을 쓰지 못합니다. 또한 아무리 많은 단어를 저장해도 세상의 모든 단어를 저장할 수 없다는 단점이 있습니다. \n",
    "\n",
    "단어를 줄인다 하여도 모르는 단어가 많아져 \\<unk> 토큰이 많아지고 이는 성능의 저하로 이어집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7.2 Chracter-based Tokenizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cbt](_image/4-7-2.PNG)\n",
    "\n",
    "이름 그대로 철자로 쪼개는 방식의 tokenizer입니다. 영어의 경우 알파벳, 한글의 경우 음절로 나누기에 워드 임베딩의 크기가 크게 줄어듭니다. \n",
    "\n",
    "그러나 철자 하나가 가져야하는 정보가 너무 많아지고 길이가 너무 길어지게 됩니다. 이는 필연적으로 성능 저하를 불러옵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7.3 Subword-based Tokenizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 두 가지 방법은 너무 뚜렷한 단점을 가지고 있습니다. 그렇기에 대부분 subword-based tokenizer를 많이 사용합니다.\n",
    "\n",
    "![sbt](_image/4-7-3.PNG)\n",
    "\n",
    "위 그림처럼 단어와 철자 사이의 subword를 토큰으로 사용합니다. 접두사, 접미사, 어근 등도 토큰으로 사용됩니다. 이를 기반으로 BPE, WordPiece, Unigram, SentencePiece 등이 있으며 현재는 WordPiece와 SentencePiece가 많이 쓰이는 추세입니다.\n",
    "\n",
    "먼저 간단하게 살펴보겠습니다.\n",
    "\n",
    "- BPE(Byte-pair Encoding): 통계적 방법, GPT 등이 이 방법을 사용\n",
    "- WordPiece: BERT 등 트랜스포머 기반의 모델에서 사용, P('ug') / P('u' then 'g')와 같이 간단한 알고리즘은 공개되었으나 모든 알고리즘이 공개되어있지 않다.\n",
    "- Unigram: 가장 많이 사용된 단어들과 substring들을 다듬으며 시작\n",
    "- SentencePiece: 공백도 토큰으로 사용한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습1. Subword tokenization의 필요성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) Intro**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\delphinus\\\\Desktop\\\\Workspace\\\\Python\\\\goorm\\\\AI기술 자연어 처리 전문가 양성 과정'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "# 데이터가 저장된 드라이브를 마운트하여 데이터를 불러올 수 있는 경로를 준비합니다.\n",
    "#from google.colab import drive\n",
    "#dirve.mount('/content/drive')\n",
    "\n",
    "PATH = os.getcwd() # 현재 경로\n",
    "PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이번 실습은 Subword tokenization의 필요성을 확인하는 것이 목적입니다.\n",
    "- Subword tokenization 기반 language model을 구현하면서 이전 과제의 Word-level language model과 비교해보겠습니다.\n",
    "- Subword-level language model을 구현하고, 주어진 데이터를 가공하여 모델을 학습한 후, 학습된 언어 모델을 이용해 문장을 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) Subword tokenization이 필요한 이유**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word tokenization 코드를 불러와 subword의 필요성을 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dictionary(object):\n",
    "    def __init__(self):\n",
    "        self.word2idx = {'<unk>': 0}\n",
    "        self.idx2word = ['<unk>']\n",
    "    \n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            self.idx2word.append(word)\n",
    "            self.word2idx[word] = len(self.idx2word) - 1\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus(object):\n",
    "    def __init__(self, path):\n",
    "        self.dictionary = Dictionary()\n",
    "        \"\"\"Tokenizes a text file\"\"\"\n",
    "        assert os.path.exists(path)\n",
    "        \n",
    "        # Add words to the dictionary\n",
    "        with open(os.path.join(path, 'train.txt'), 'r', encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                words = line.split() + ['<eos>']\n",
    "                for word in words:\n",
    "                    self.dictionary.add_word(word)\n",
    "        \n",
    "        self.train = self.tokenize(os.path.join(path, 'train.txt'))\n",
    "        self.valid = self.tokenize(os.path.join(path, 'valid.txt'))\n",
    "        self.test = self.tokenize(os.path.join(path, 'test.txt'))\n",
    "    \n",
    "    def tokenize(self, path):\n",
    "        # Tokenize file content\n",
    "        with open(path, 'r', encoding=\"utf8\") as f:\n",
    "            idss = []\n",
    "            for line in f:\n",
    "                words = line.split() + ['<eos>']\n",
    "                ids = []\n",
    "                for word in words:\n",
    "                    try:\n",
    "                        ids.append(self.dictionary.word2idx[word])\n",
    "                    except:\n",
    "                        print(word)\n",
    "                        ids.append(0)\n",
    "                idss.append(torch.tensor(ids).type(torch.int64))\n",
    "            ids = torch.cat(idss)\n",
    "        \n",
    "        return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    \"\"\"Container module with an encoder, a recurrent module and a decoder\"\"\"\n",
    "    \n",
    "    def __init__(self, rnn_type, ntoken, ninp, nhid, nlayers, dropout=0.5):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.ntoken = ntoken\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "        if rnn_type in ['LSTM', 'GRU']:\n",
    "            self.rnn = getattr(nn, rnn_type)(ninp, nhid, nlayers, dropout=dropout)\n",
    "        else:\n",
    "            try:\n",
    "                nonlinearity = {\"RNN_TANH\": \"tanh\", \"RNN_RELU\": \"relu\"}[rnn_type]\n",
    "            except KeyError:\n",
    "                raise ValueError(\"\"\"An invalid option for '--model' was supplied,\n",
    "                                options are ['LSTM', 'GRU', 'RNN_TANH' or 'RNN_RELU']\"\"\")\n",
    "            self.rnn = nn.RNN(ninp, nhid, nlayers, nonlinearity=nonlinearity, dropout=dropout)\n",
    "        self.decoder = nn.Linear(nhid, ntoken)\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "        self.rnn_type = rnn_type\n",
    "        self.nhid = nhid\n",
    "        self.nlayers = nlayers\n",
    "    \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        nn.init.uniform_(self.encoder.weight, -initrange, initrange)\n",
    "        nn.init.zeros_(self.decoder.weight)\n",
    "        nn.init.uniform_(self.encoder.weight, -initrange, initrange)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        emb = self.drop(self.encoder(input))\n",
    "        output, hidden = self.rnn(emb, hidden)\n",
    "        output = self.drop(output)\n",
    "        decoded = self.decoder(output)\n",
    "        decoded = decoded.view(-1, self.ntoken)\n",
    "        return F.log_softmax(decoded, dim=1), hidden\n",
    "    \n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters())\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            return (weight.new_zeros(self.nlayers, bsz, self.nhid),\n",
    "                    weight.new_zeros(self.nlayers, bsz, self.nhid))\n",
    "        else:\n",
    "            return weight.new_zeros(self.nlayers, bsz, self.nhid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import easydict\n",
    "args = easydict.EasyDict({\n",
    "    \"data\"    : './data/wikitext-2',    # location of the data corpus\n",
    "    \"model\"   : 'RNN_TANH',             # type of recurrent net (RNN_TANH, RNN_RELU, LSTM, GRU)\n",
    "    \"emsize\"  : 200,                    # size of word embeddings\n",
    "    \"nhid\"    : 512,                    # number of hidden units per layer\n",
    "    \"nlayers\" : 2,                      # number of layers\n",
    "    \"lr\"      : 20,                     # initial learning rate\n",
    "    \"clip\"    : 0.25,                   # gradient clipping\n",
    "    \"epochs\"  : 6,                      # upper epoch limit\n",
    "    \"batch_size\": 20,                   # batch size\n",
    "    \"bptt\"    : 35,                     # sequence length\n",
    "    \"dropout\" : 0.2,                    # dropout applied to layers (0 = no dropout)\n",
    "    \"seed\"    : 1111,                   # random seed\n",
    "    \"cuda\"    : False,                  # unuse CUDA\n",
    "    \"log_interval\": 200,                # report interval\n",
    "    \"save\"    : 'model.pt',             # path to save the final model\n",
    "    \"dry_run\" : True,                   # verify the code and the model\n",
    "\n",
    "})\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train.txt의 문장들을 word tokenization 해보고 단어들의 개수를 세어보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33278\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus('./data/wikitext-2')\n",
    "ntokens = len(corpus.dictionary)\n",
    "print(ntokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전 실습에 사용된 embedding dimension의 크기가 200이므로 word embedding에 사용된 parameter의 수는 33278 x 200 (= 6,655,600개)입니다.\n",
    "\n",
    "그렇다면 RNN 모델에 사용되는 weight의 paramter 개수는 몇 개인지 간단한 함수를 이용해 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel(args.model, ntokens, args.emsize, args.nhid, args.nlayers, args.dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embedding parameter 개수: 6655600\n",
      "RNN parameter 개수: 890880\n"
     ]
    }
   ],
   "source": [
    "print(f\"Word embedding parameter 개수: {count_parameters(model.encoder)}\")\n",
    "print(f\"RNN parameter 개수: {count_parameters(model.rnn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN parameter, Word embedding parameter 개수를 비교해보면 word embedding parameter의 개수가 RNN 모델의 paramter의 개수보다 압도적으로 많습니다. word embedding을 사용하는 경우 training에 사용되는 text file의 크기가 커질수록 word embedding paramter는 더 커지게 되고 전체 parameter 대비 word embedding이 차지하는 비중이 매우 커집니다. \n",
    "\n",
    "이런 paramter 비중의 비대칭성을 해결하기 위해 처음에는 charater-based tokenization 방법을 주목했습니다. 그러나 앞서 살펴봤듯, 여러 이유로 성능 저하를 보였고 subword를 사용하게 됩니다.\n",
    "\n",
    "그럼 이제부터 BERT 모델에서 사용한 subword tokenization algorithm을 이용해 language modeling task를 수행해보겠습니다. subword tokenizer는 transformers 라이브러리를 통해 쉽게 불러올 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 208k/208k [00:00<00:00, 350kB/s]  \n",
      "Downloading: 100%|██████████| 29.0/29.0 [00:00<00:00, 14.4kB/s]\n",
      "Downloading: 100%|██████████| 426k/426k [00:01<00:00, 424kB/s]  \n",
      "Downloading: 100%|██████████| 570/570 [00:00<00:00, 285kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'expert', 'training', 'course']\n",
      "['Go', '##orm', 'X', 'K', '##A', '##IS', '##T']\n"
     ]
    }
   ],
   "source": [
    "# subword tokenization 예시\n",
    "print(tokenizer.tokenize('Natural language expert training course'))\n",
    "print(tokenizer.tokenize('Goorm X KAIST'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus(object):\n",
    "    def __init__(self, path):\n",
    "        self.dictionary = Dictionary()\n",
    "        self.train = self.tokenize(os.path.join(path, 'train.txt'))\n",
    "        self.valid = self.tokenize(os.path.join(path, 'valid.txt'))\n",
    "        self.test = self.tokenize(os.path.join(path, 'test.txt'))\n",
    "\n",
    "    def tokenize(self, path):\n",
    "        assert os.path.exists(path)\n",
    "        # Add words to the dictionary\n",
    "        with open(path, 'r', encoding=\"utf8\") as f:\n",
    "            for line in f:\n",
    "                words = tokenizer.tokenize(line.strip()) + ['<eos>']\n",
    "                for word in words:\n",
    "                    self.dictionary.add_word(word)\n",
    "\n",
    "        # Tokenize file content\n",
    "        with open(path, 'r', encoding=\"utf8\") as f:\n",
    "            idss = []\n",
    "            for line in f:\n",
    "                words = tokenizer.tokenize(line.strip()) + ['<eos>']\n",
    "                ids = []\n",
    "                for word in words:\n",
    "                    ids.append(self.dictionary.word2idx[word])\n",
    "                idss.append(torch.tensor(ids).type(torch.int64))\n",
    "            ids = torch.cat(idss)\n",
    "\n",
    "        return ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그러면 이제 모델을 다시 선언하고 paramter의 개수를 확인하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "subword_corpus = Corpus('./data/wikitext-2')\n",
    "ntokens = len(subword_corpus.dictionary)\n",
    "subwordmodel = RNNModel(args.model, ntokens, args.emsize, args.nhid, args.nlayers, args.dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embedding parameter 개수: 4619000\n",
      "RNN parameter 개수: 890880\n"
     ]
    }
   ],
   "source": [
    "print(f\"Word embedding parameter 개수: {count_parameters(subwordmodel.encoder)}\")\n",
    "print(f\"RNN parameter 개수: {count_parameters(subwordmodel.rnn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전에 비해 embedding parameter 개수는 확연히 줄어들었습니다.   \n",
    "6,655,600개 -> 4,619,000개\n",
    "\n",
    "그러면 이제 subword 기반의 언어 모델 성능을 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Load data\n",
    "###############################################################################\n",
    "\n",
    "# Starting from sequential data, batchify arranges the dataset into columns.\n",
    "# For instance, with the alphabet as the sequence and batch size 4, we'd get\n",
    "# ┌ a g m s ┐\n",
    "# │ b h n t │\n",
    "# │ c i o u │\n",
    "# │ d j p v │\n",
    "# │ e k q w │\n",
    "# └ f l r x ┘.\n",
    "# These columns are treated as independent by the model, which means that the\n",
    "# dependence of e. g. 'g' on 'f' can not be learned, but allows more efficient\n",
    "# batch processing.\n",
    "\n",
    "def batchify(data, bsz):\n",
    "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # Evenly divide the data across the bsz batches.\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "eval_batch_size = 10\n",
    "train_data = batchify(subword_corpus.train, args.batch_size)\n",
    "val_data = batchify(subword_corpus.valid, eval_batch_size)\n",
    "test_data = batchify(subword_corpus.test, eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Build the model\n",
    "###############################################################################\n",
    "\n",
    "model = RNNModel(args.model, ntokens, args.emsize, args.nhid, args.nlayers, args.dropout).to(device)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Training code1 - define functions\n",
    "###############################################################################\n",
    "\n",
    "def repackage_hidden(h):\n",
    "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
    "\n",
    "    if isinstance(h, torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)\n",
    "\n",
    "\n",
    "# get_batch subdivides the source data into chunks of length args.bptt.\n",
    "# If source is equal to the example output of the batchify function, with\n",
    "# a bptt-limit of 2, we'd get the following two Variables for i = 0:\n",
    "# ┌ a g m s ┐ ┌ b h n t ┐\n",
    "# └ b h n t ┘ └ c i o u ┘\n",
    "# Note that despite the name of the function, the subdivison of data is not\n",
    "# done along the batch dimension (i.e. dimension 1), since that was handled\n",
    "# by the batchify function. The chunks are along dimension 0, corresponding\n",
    "# to the seq_len dimension in the LSTM.\n",
    "\n",
    "def get_batch(source, i):\n",
    "    seq_len = min(args.bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].view(-1)\n",
    "    return data, target\n",
    "\n",
    "\n",
    "def evaluate(data_source):\n",
    "    # Turn on evaluation mode which disables dropout.\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    ntokens = len(subword_corpus.dictionary)\n",
    "    hidden = model.init_hidden(eval_batch_size)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, data_source.size(0) - 1, args.bptt):\n",
    "            data, targets = get_batch(data_source, i)\n",
    "            output, hidden = model(data, hidden)\n",
    "            hidden = repackage_hidden(hidden)\n",
    "            total_loss += len(data) * criterion(output, targets).item()\n",
    "    return total_loss / (len(data_source) - 1)\n",
    "\n",
    "\n",
    "def train():\n",
    "    # Turn on training mode which enables dropout.\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    ntokens = len(subword_corpus.dictionary)\n",
    "    hidden = model.init_hidden(args.batch_size)\n",
    "    for batch, i in enumerate(range(0, train_data.size(0) - 1, args.bptt)):\n",
    "        data, targets = get_batch(train_data, i)\n",
    "        # Starting each batch, we detach the hidden state from how it was previously produced.\n",
    "        # If we didn't, the model would try backpropagating all the way to start of the dataset.\n",
    "        model.zero_grad()\n",
    "\n",
    "        hidden = repackage_hidden(hidden)\n",
    "        output, hidden = model(data, hidden)\n",
    "\n",
    "        loss = criterion(output, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "        for p in model.parameters():\n",
    "            p.data.add_(p.grad, alpha=-lr)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if batch % args.log_interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss / args.log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2f} | ms/batch {:5.2f} | '\n",
    "                    'loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                epoch, batch, len(train_data) // args.bptt, lr,\n",
    "                elapsed * 1000 / args.log_interval, cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "        if args.dry_run:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 254.02s | valid loss  9.37 | valid ppl 11752.85\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 184.04s | valid loss 14.65 | valid ppl 2314637.74\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 190.28s | valid loss 10.87 | valid ppl 52374.79\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 182.13s | valid loss  9.01 | valid ppl  8167.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 170.05s | valid loss  7.81 | valid ppl  2454.89\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 201.61s | valid loss  7.79 | valid ppl  2413.30\n",
      "-----------------------------------------------------------------------------------------\n",
      "=========================================================================================\n",
      "| End of training | test loss  7.69 | test ppl  2182.13\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Training code2 - run \n",
    "###############################################################################\n",
    "\n",
    "# Loop over epochs.\n",
    "lr = args.lr\n",
    "best_val_loss = None\n",
    "\n",
    "# At any point you can hit Ctrl + C to break out of training early.\n",
    "try:\n",
    "    for epoch in range(1, args.epochs+1):\n",
    "        epoch_start_time = time.time()\n",
    "        train()\n",
    "        val_loss = evaluate(val_data)\n",
    "        print('-' * 89)\n",
    "        print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "                'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                            val_loss, math.exp(val_loss)))\n",
    "        print('-' * 89)\n",
    "        # Save the model if the validation loss is the best we've seen so far.\n",
    "        if not best_val_loss or val_loss < best_val_loss:\n",
    "            with open(args.save, 'wb') as f:\n",
    "                torch.save(model, f)\n",
    "            best_val_loss = val_loss\n",
    "        else:\n",
    "            # Anneal the learning rate if no improvement has been seen in the validation dataset.\n",
    "            lr /= 4.0\n",
    "except KeyboardInterrupt:\n",
    "    print('-' * 89)\n",
    "    print('Exiting from training early')\n",
    "\n",
    "# Load the best saved model.\n",
    "with open(args.save, 'rb') as f:\n",
    "    model = torch.load(f)\n",
    "    # after load the rnn params are not a continuous chunk of memory\n",
    "    # this makes them a continuous chunk, and will speed up forward pass\n",
    "    # Currently, only rnn model supports flatten_parameters function.\n",
    "    if args.model in ['RNN_TANH', 'RNN_RELU', 'LSTM', 'GRU']:\n",
    "        model.rnn.flatten_parameters()\n",
    "\n",
    "# Run on test data.\n",
    "test_loss = evaluate(test_data)\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n",
    "    test_loss, math.exp(test_loss)))\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) 학습한 언어 모델로 문장 생성**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습이 완료된 모델을 불러와 임의의 한 단어를 입력으로 넣어준 후, 정해진 개수의 단어를 생성합니다.\n",
    "- 생성한 문장을 decode하여 generate.txt 파일에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Generated 0/1000 words\n",
      "| Generated 100/1000 words\n",
      "| Generated 200/1000 words\n",
      "| Generated 300/1000 words\n",
      "| Generated 400/1000 words\n",
      "| Generated 500/1000 words\n",
      "| Generated 600/1000 words\n",
      "| Generated 700/1000 words\n",
      "| Generated 800/1000 words\n",
      "| Generated 900/1000 words\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Language Modeling on Wikitext-2\n",
    "#\n",
    "# This file generates new sentences sampled from the language model\n",
    "#\n",
    "###############################################################################\n",
    "\n",
    "import torch\n",
    "\n",
    "# Model parameters.\n",
    "test_args = easydict.EasyDict({\n",
    "    \"data\"      : './data/wikitext-2',  # location of data corpus\n",
    "    \"checkpoint\": './model.pt',         # model checkpoint to use\n",
    "    \"outf\"      : 'generate.txt',       # output file for generated text\n",
    "    \"words\"     : 1000,                 # number of words to generate\n",
    "    \"seed\"      : 1111,                 # random seed\n",
    "    \"cuda\"      : False,                # unuse CUDA\n",
    "    \"temperature\": 1.0,                 # temperature - higher will increase diversity\n",
    "    \"log_interval\": 100                 # reporting interval\n",
    "})\n",
    "\n",
    "# Set the random seed manually for reproducibility.\n",
    "torch.manual_seed(test_args.seed)\n",
    "if torch.cuda.is_available():\n",
    "    if not test_args.cuda:\n",
    "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "device = torch.device(\"cuda\" if test_args.cuda else \"cpu\")\n",
    "\n",
    "if test_args.temperature < 1e-3:\n",
    "    parser.error(\"--temperature has to be greater or equal 1e-3\")\n",
    "\n",
    "with open(test_args.checkpoint, 'rb') as f:\n",
    "    model = torch.load(f).to(device)\n",
    "model.eval()\n",
    "\n",
    "# corpus = Corpus(test_args.data)\n",
    "# ntokens = len(subword_corpus.dictionary)\n",
    "\n",
    "hidden = model.init_hidden(1)\n",
    "input = torch.randint(ntokens, (1, 1), dtype=torch.long).to(device)\n",
    "\n",
    "with open(test_args.outf, 'w', encoding=\"UTF-8\") as outf:\n",
    "    with torch.no_grad():  # no tracking history\n",
    "        for i in range(test_args.words):\n",
    "            output, hidden = model(input, hidden)\n",
    "            word_weights = output.squeeze().div(test_args.temperature).exp().cpu()\n",
    "            word_idx = torch.multinomial(word_weights, 1)[0]\n",
    "            input.fill_(word_idx)\n",
    "\n",
    "            word = subword_corpus.dictionary.idx2word[word_idx]\n",
    "\n",
    "            outf.write(word + ('\\n' if i % 20 == 19 else ' '))\n",
    "\n",
    "            if i % test_args.log_interval == 0:\n",
    "                print('| Generated {}/{} words'.format(i, test_args.words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "[Pytorch Language Model](https://github.com/pytorch/examples/tree/master/word_language_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **8. Byte-Pair Encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8.1 BPE 알고리즘**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BPE 알고리즘은 1994년에 제안된 데이터 압축 알고리즘입니다. 이를 후에 자연어 처리의 서브워드 분리 알고리즘으로 응용한 것입니다. 자연어 처리에서 사용되는 것을 알아보기 전에 먼저 기존의 BPE 작동 방법을 알아보겠습니다. \n",
    "\n",
    "> aaabdaaabac\n",
    "\n",
    "위와 같은 문자열이 주어졌습니다. 이때 BPE는 연속적으로 가장 많이 등장한 글자의 쌍을 찾아서 하나의 글자로 병합하는 방식을 수행합니다. 위 문자에서 가장 많이 등장한 문자의 쌍은 'aa'입니다. 이를 'Z'로 치환하겠습니다.\n",
    "\n",
    "> ZabdZabac  \n",
    "> Z = aa  \n",
    "\n",
    "치환 후, 가장 많이 등장하는 문자의 쌍은 'ab'입니다. 'ab'는 'Y'로 치환하겠습니다.\n",
    "\n",
    "> ZYdZYac  \n",
    "> Y = ab  \n",
    "> Z = aa  \n",
    "\n",
    "이번엔 'ZY'가 가장 많이 나타납니다. 이를 'X'로 치환하겠습니다.\n",
    "\n",
    "> XdXac  \n",
    "> X = ZY  \n",
    "> Y = ab  \n",
    "> Z = aa  \n",
    "\n",
    "이제 더이상 병합할 것이 없습니다. 그렇기에 위 결과를 최종 결과로 출력합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8.2 자연어 처리에서의 BPE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[자연어 처리에서의 BPE](https://arxiv.org/abs/1508.07909)는 subword-based tokenizer의 일종으로 글자 단위에서 점차적으로 단어 집합을 만들어내는 bottom up 방식을 사용합니다. 우선 훈련 데이터에 있는 단어들을 모든 글자 또는 유니코드 단위로 단어 집합을 만들고 가장 많이 등장하는 유니그램을 하나의 유니그램으로 통합합니다. \n",
    "\n",
    "논문에서 나오는 코드를 조금 수정한 코드로 동작하는 과정을 알아보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Iteration 1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 8, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('e', 's'): 9, ('s', 't'): 9, ('t', '</w>'): 9, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'e'): 3}\n",
      "new merge: ('e', 's')\n",
      "dictionary: {'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w es t </w>': 6, 'w i d es t </w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 2"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'es'): 6, ('es', 't'): 9, ('t', '</w>'): 9, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'es'): 3}\n",
      "new merge: ('es', 't')\n",
      "dictionary: {'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w est </w>': 6, 'w i d est </w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 3"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est'): 6, ('est', '</w>'): 9, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est'): 3}\n",
      "new merge: ('est', '</w>')\n",
      "dictionary: {'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 4"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
      "new merge: ('l', 'o')\n",
      "dictionary: {'lo w </w>': 5, 'lo w e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 5"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('lo', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
      "new merge: ('lo', 'w')\n",
      "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 6"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
      "new merge: ('n', 'e')\n",
      "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'ne w est</w>': 6, 'w i d est</w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 7"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('ne', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
      "new merge: ('ne', 'w')\n",
      "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'new est</w>': 6, 'w i d est</w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 8"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('new', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
      "new merge: ('new', 'est</w>')\n",
      "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'w i d est</w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 9"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
      "new merge: ('low', '</w>')\n",
      "dictionary: {'low</w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'w i d est</w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 10"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
      "new merge: ('w', 'i')\n",
      "dictionary: {'low</w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'wi d est</w>': 3}\n"
     ]
    }
   ],
   "source": [
    "import re, collections\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "num_merges = 10\n",
    "dictionary = {'l o w </w>' : 5,\n",
    "        'l o w e r </w>' : 2,\n",
    "        'n e w e s t </w>':6,\n",
    "        'w i d e s t </w>':3\n",
    "        }\n",
    "\n",
    "def get_stats(dictionary):\n",
    "    # 유니그램의 pair들의 빈도수를 카운트\n",
    "    pairs = collections.defaultdict(int)\n",
    "    for word, freq in dictionary.items():\n",
    "        symbols = word.split()\n",
    "        for i in range(len(symbols)-1):\n",
    "            pairs[symbols[i],symbols[i+1]] += freq\n",
    "    print('현재 pair들의 빈도수 :', dict(pairs))\n",
    "    return pairs\n",
    "\n",
    "def merge_dictionary(pair, v_in):\n",
    "    v_out = {}\n",
    "    bigram = re.escape(' '.join(pair))\n",
    "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
    "    for word in v_in:\n",
    "        w_out = p.sub(''.join(pair), word)\n",
    "        v_out[w_out] = v_in[word]\n",
    "    return v_out\n",
    "\n",
    "bpe_codes = {}\n",
    "bpe_codes_reverse = {}\n",
    "\n",
    "for i in range(num_merges):\n",
    "    display(Markdown(\"### Iteration {}\".format(i + 1)))\n",
    "    pairs = get_stats(dictionary)\n",
    "    best = max(pairs, key=pairs.get)\n",
    "    dictionary = merge_dictionary(best, dictionary)\n",
    "\n",
    "    bpe_codes[best] = i\n",
    "    bpe_codes_reverse[best[0] + best[1]] = best\n",
    "\n",
    "    print(\"new merge: {}\".format(best))\n",
    "    print(\"dictionary: {}\".format(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vocab은 나오는 단어들을 키, 출현 빈도수를 값으로 가지는 사전입니다. 처음 입력되는 단어들은 모두 철자입니다. `get_stats`함수를 거치면서 앞뒤로 근접한 한 쌍의 단어들의 조합 빈도수가 저장된 pairs을 리턴합니다. 예를 들어 [l o w </w>]가 들어가면 [lo], [ow], [w</w>]의 빈도수가 각각 저장되는 것입니다. 이렇게 리턴된 pairs에서 빈도수가 가장 높은 것을 `merge_dictionary`을 통해 vocab에 저장합니다. 그리고 이를 num_merges만큼 반복하는 것입니다. \n",
    "\n",
    "위 출력은 매 iteration마다 합쳐진 단어들이고 마지막은 최종 vocab입니다. \n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/22592/%EA%B7%B8%EB%A6%BC.png\">\n",
    "\n",
    "위 그림은 BPE는 OOV의 문제를 해결하는 동작 과정입니다. 모르는 단어 'lowest'가 들어왔을 때, vocab 안에 있는 두 토큰의 합으로 표현한 것을 알 수 있습니다. 이 역시 코드로 구현해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(word):\n",
    "    \"\"\"\n",
    "    Return set of symbol pairs in a word.\n",
    "    Word is represented as a tuple of symbols (symbols being variable-length strings).\n",
    "    \"\"\"\n",
    "    pairs = set()\n",
    "    prev_char = word[0]\n",
    "    for char in word[1:]:\n",
    "        pairs.add((prev_char, char))\n",
    "        prev_char = char\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def encode(orig):\n",
    "    \"\"\"Encode word based on list of BPE merge operations, which are applied consecutively\"\"\"\n",
    "\n",
    "    word = tuple(orig) + ('</w>',)\n",
    "    display(Markdown(\"__word split into characters:__ <tt>{}</tt>\".format(word)))\n",
    "\n",
    "    pairs = get_pairs(word)    \n",
    "\n",
    "    if not pairs:\n",
    "        return orig\n",
    "\n",
    "    iteration = 0\n",
    "    while True:\n",
    "        iteration += 1\n",
    "        display(Markdown(\"__Iteration {}:__\".format(iteration)))\n",
    "\n",
    "        print(\"bigrams in the word: {}\".format(pairs))\n",
    "        bigram = min(pairs, key = lambda pair: bpe_codes.get(pair, float('inf')))\n",
    "        print(\"candidate for merging: {}\".format(bigram))\n",
    "        if bigram not in bpe_codes:\n",
    "            display(Markdown(\"__Candidate not in BPE merges, algorithm stops.__\"))\n",
    "            break\n",
    "        first, second = bigram\n",
    "        new_word = []\n",
    "        i = 0\n",
    "        while i < len(word):\n",
    "            try:\n",
    "                j = word.index(first, i)\n",
    "                new_word.extend(word[i:j])\n",
    "                i = j\n",
    "            except:\n",
    "                new_word.extend(word[i:])\n",
    "                break\n",
    "\n",
    "            if word[i] == first and i < len(word)-1 and word[i+1] == second:\n",
    "                new_word.append(first+second)\n",
    "                i += 2\n",
    "            else:\n",
    "                new_word.append(word[i])\n",
    "                i += 1\n",
    "        new_word = tuple(new_word)\n",
    "        word = new_word\n",
    "        print(\"word after merging: {}\".format(word))\n",
    "        if len(word) == 1:\n",
    "            break\n",
    "        else:\n",
    "            pairs = get_pairs(word)\n",
    "\n",
    "    # 특별 토큰인 </w>는 출력하지 않는다.\n",
    "    if word[-1] == '</w>':\n",
    "        word = word[:-1]\n",
    "    elif word[-1].endswith('</w>'):\n",
    "        word = word[:-1] + (word[-1].replace('</w>',''),)\n",
    "\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "__word split into characters:__ <tt>('l', 'o', 'k', 'i', '</w>')</tt>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 1:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('i', '</w>'), ('o', 'k'), ('k', 'i'), ('l', 'o')}\n",
      "candidate for merging: ('l', 'o')\n",
      "word after merging: ('lo', 'k', 'i', '</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 2:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('i', '</w>'), ('lo', 'k'), ('k', 'i')}\n",
      "candidate for merging: ('i', '</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Candidate not in BPE merges, algorithm stops.__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('lo', 'k', 'i')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"loki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "__word split into characters:__ <tt>('l', 'o', 'w', 'e', 's', 't', '</w>')</tt>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 1:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('e', 's'), ('o', 'w'), ('s', 't'), ('w', 'e'), ('t', '</w>'), ('l', 'o')}\n",
      "candidate for merging: ('e', 's')\n",
      "word after merging: ('l', 'o', 'w', 'es', 't', '</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 2:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('o', 'w'), ('w', 'es'), ('es', 't'), ('t', '</w>'), ('l', 'o')}\n",
      "candidate for merging: ('es', 't')\n",
      "word after merging: ('l', 'o', 'w', 'est', '</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 3:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('o', 'w'), ('w', 'est'), ('l', 'o'), ('est', '</w>')}\n",
      "candidate for merging: ('est', '</w>')\n",
      "word after merging: ('l', 'o', 'w', 'est</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 4:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('o', 'w'), ('w', 'est</w>'), ('l', 'o')}\n",
      "candidate for merging: ('l', 'o')\n",
      "word after merging: ('lo', 'w', 'est</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 5:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('lo', 'w'), ('w', 'est</w>')}\n",
      "candidate for merging: ('lo', 'w')\n",
      "word after merging: ('low', 'est</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 6:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('low', 'est</w>')}\n",
      "candidate for merging: ('low', 'est</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Candidate not in BPE merges, algorithm stops.__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('low', 'est')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"lowest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "간단하게 BPT에 대해 보았습니다. BPT를 사용한 대표적인 모델인 GPT 등에 대해선 이후 챕터에서 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8.3 Issue**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BPE에 여러 트릭을 이용해 성능을 개선하는 방법을 적용하고 있습니다. 예를 들어 첫 시작으로 철자 단위로 나눌 때, 공백 역시 '_' 등의 문자로 치환하여 함께 토큰화 시키는 방법이 있습니다. \n",
    "\n",
    "또한 \"학교에\"라는 단어가 들어왔고 사전에 [학교, 교에, 학, 교, 에]가 있다면 어떻게 토큰화할 것인지에 대한 방법론도 있습니다. 생각만 해보면 [학, 교에], [학교, 에], [학, 교, 에] 세 가지 방법으로 토큰화시킬 수 있습니다. 마지막 방법은 토큰화의 의미가 없으니 제외하고 나머지 두 개만 살펴보겠습니다.\n",
    "\n",
    "먼저 오른쪽으로부터 탐색하는 방법입니다. 가장 오른쪽인 '에'를 보고 사전에 존재하면 이어서 '교에'를 확인합니다. 이 또한 존재하면 '학교에'를 확인합니다. 이런식으로 공백이 나올때까지 쭉 이어집니다. 위같은 예시라면 [학, 교에]라는 결과를 출력할 것입니다. \n",
    "\n",
    "위와 반대로 왼쪽부터 탐색하는 방법도 있습니다. 그렇다면 [학교, 에]라는 결과를 출력할 것입니다. 대체적으로 왼쪽부터 탐색하는 방법을 사용하고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  **Reference**\n",
    "\n",
    "https://wikidocs.net/22592"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **9. BERT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[BERT(Bidirectional Encoder Representations from Transformers)](https://arxiv.org/abs/1810.04805)는 2018년에 구글이 공개한 pre-trained model입니다. BERT는 등장과 동시에 수많은 NLP task에서 최고 성능을 보여주면서 NLP분야의 한 획을 그은 모델로 평가받고 있습니다. 이러한 BERT를 배우기 전에 워드 임베딩에서부터 ELMo, 트랜스포머에 이르기까지 자연어 처리가 발전되어온 흐름을 정리해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **9.1 NLP에서 Pre-training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 Word2Vec, FastText, GloVe와 같은 워드 임베딩들을 배웠습니다. 어떤 task를 수행할 때, 임베딩을 사용하는 방법은 크게 두 가지가 있습니다. 임베딩 층을 랜덤 초기화하여 처음부터 학습하는 방법과 방대한 데이터로 Word2Vec 등과 같은 임베딩 알고리즘으로 사전에 학습된 임베딩 벡터들을 가져와 사용하는 방법입니다. 만약 task에서 사용할 데이터가 적다면, 사전 훈련된 임베딩을 사용하면 성능 향상을 기대할 수 있습니다. \n",
    "\n",
    "그런데 위 두 가지 방법은 모두 하나의 단어가 하나의 벡터값으로 맵핑됩니다. 그렇기에 문맥을 고려하지 못하고 다의어나 동음이의어를 구분하지 못하는 문제가 생깁니다. 이 한계를 사전 훈련된(Pre-training) 언어 모델을 사용하므로 해결할 수 있었으며 이제 알아볼 ELMo나 BERT 등이 이러한 문제의 해결책이 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) 사전 훈련된 언어 모델의 등장**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://wikidocs.net/images/page/108730/image1.PNG\">\n",
    "\n",
    "2015년 구글은 \"Semi-supervised Sequence Learning\"이라는 논문에서 LSTM 언어 모델을 학습하고나서 학습한 LSTM을 텍스트 분류에 추가 하는 방법을 보였습니다. 이 방법은 먼저 LSTM 언어 모델을 학습합니다. 언어 모델은 주어진 텍스트에서 이전 단어를 통해 다음 단어를 예측하는 학습을 진행하기에 따로 레이블을 지정하지 않은 텍스트 데이터로도 학습이 가능합니다. 이는 큰 이점이 됩니다.\n",
    "\n",
    "그리고 이렇게 레이블이 없는 데이터로 학습된 LSTM과 가중치가 랜덤으로 초기화 된 LSTM을 가지고 텍스트 분류 같은 문제를 학습하여 사전 훈련된 언어 모델을 사용한 전자가 더 좋은 결과를 얻을 수 있다고 가능성을 보이면서 ELMo와 같은 사전 훈련된 언어 모델이 본격적으로 등장하기 시작합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) ELMo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://wikidocs.net/images/page/108730/image2.PNG\">\n",
    "\n",
    "ELMo는 순방향 언어 모델과 역방향 언어 모델을 각각 따로 학습시킨 후에, 이렇게 사전 학습된 언어 모델로부터 임베딩 값을 얻는다는 아이디어로 구현된 모델입니다. (자세하게 알고 싶으면 [이곳](https://wikidocs.net/33930)) 이러한 임베딩은 문맥에 따라서 임베딩 벡터값이 달라지므로, 기존 워드 임베딩인 Word2Vec이나 GloVe 등이 가지던 다의어, 동음이의어 문제들을 해결할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) Transformer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이서 언어 모델은 RNN 기반의 신경망을 벗어나기 시작합니다. 트랜스포머가 번역기와 같은 인코더-디코더 구조에서 LSTM을 뛰어넘자 LSTM이 아닌 트랜스포머로 사전 훈련된 언어 모델을 학습하는 시도가 등장합니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/108730/image3.PNG\">\n",
    "\n",
    "위 그림에서 Trm은 트랜스포머를 의미합니다. 트랜스포머의 디코더는 LSTM 언어 모델처럼 순차적으로 이전 단어들로부터 다음 단어를 예측합니다. Open AI는 트랜스포머 디코더로 총 12개의 층을 쌓은 후에 방대한 텍스트 데이터를 학습시킨 언어 모델 GPT-1을 만들었습니다. Open AI는 GPT-1에 여러 다양한 task를 위해 추가 학습을 진행하였을 때, 다양한 task에서 높은 성능을 보임을 입증했습니다. NLP의 주요 트렌드는 사전 훈련된 언어 모델을 만들고 이를 특정 task에 추가 학습시켜서 해당 task의 성능을 높이는 것으로 접어들었고, 언어 모델의 학습 방법에 변화를 주는 모델들이 등장했습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4) 양방향 언어모델**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://wikidocs.net/images/page/108730/image4.PNG\">\n",
    "\n",
    "위 좌측의 그림은 단방향 언어모델로 전형적인 형태입니다. 문장 순서대로 예측하는 과정을 거칩니다. 그에 반해 우리가 위에서 봤었던 양방향 언어모델은 순방향과 역방향의 모델을 따로 준비하여 학습하여 사용한 모델입니다. 언어의 문맥은 양방향이기에 좋은 성능을 얻을 수 있습니다. 또한 모델을 각각 두 개로 나눈 이유는 순방향으로 학습한 후, 역방향을 진행하면 이미 답을 모두 알고 있기에 학습효과가 사라지기 때문이었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5) Masked Language Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또한 위 방법 말고 양방향성을 도입하기 위해 masked language model이 탄생합니다. 뒤에서 자세히 보겠지만 마스크드 언어 모델은 입력 텍스트 단어의 15%의 단어를 랜덤으로 마스킹합니다. 즉, 단어를 가려 원래 단어가 무엇인지 모르게 한다는 것입니다. 그리고 그 마스킹 된 단어들을 예측하게 합니다. 그리고 이를 이용하여 BERT가 등장하게 됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **9.2 BERT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) 개요**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"http://jalammar.github.io/images/bert-transfer-learning.png\">\n",
    "\n",
    "BERT는 이전 챕터에서 배웠던 트랜스포머를 이용하여 구현되었으며, 위키피디아(25억 단어)와 BooksCorpus(8억 단어)와 같은 레이블이 없는 텍스트 데이터로 사전 훈련되어 있습니다.\n",
    "\n",
    "그리고 위 그림처럼 사전 훈련된 BERT를 각 task에 맞도록 fine-tuning(다른 작업에 대해서 파라미터를 재조정하기 위한 추가 훈련)을 하면 간단하고 성능도 높게 나옵니다. 위는 스팸 메일 분류에 사용된 BERT를 보여줍니다. 이러한 fine-tuning은 ELMo, Open AI GPT-1에도 사용되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) Architecture**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"http://jalammar.github.io/images/bert-base-bert-large-encoders.png\">\n",
    "\n",
    "BERT의 기본 구조는 트랜스포머의 인코더를 쌓아올린 구조입니다. 트랜스포머의 인코더 수를 L, d_model의 크기를 D, 셀프 어텐션 헤드의 개수를 A라고 했을 때, 두 개의 BERT는 다음과 같습니다.\n",
    "\n",
    "- BERT-base: L = 12, D = 768, A = 12: 110M개의 파라미터\n",
    "- BERT-large: L = 24, D = 1024, A = 16: 340M개의 파라미터\n",
    "\n",
    "초기 트랜스포머 모델이 L = 6, D = 512, A = 8인 것과 비교하면 Base 또한 초기 모델보다 큰 것을 알 수 있습니다. 여기서 BERT-base는 BERT보다 앞서 등장한 Open AI GPT-1과 하이퍼파라미터를 동일하게 만들어 성능을 비교하도록 만든 것입니다. 반면에 BERT-large는 BERT의 최대 성능을 내기 위해 만들어진 모델입니다. \n",
    "\n",
    "그렇기에 실제로 BERT-large를 많이 사용하고 기록도 많이 씁니다. 하지만 이 글에선 BERT-base를 기준으로 이야기하겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) BERT의 문맥을 반영한 임베딩(Contextual Embedding)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT는 ELMo나 GPT-1과 마찬가지로 문맥을 반영한 임베딩을 사용합니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/115055/bert0.PNG\">\n",
    "\n",
    "BERT의 입력은 앞서 배운 딥 러닝 모델들과 마찬가지로 임베딩 층을 지난 임베딩 벡터들입니다. d_model을 768로 정의했기에 모든 단어들은 768차원의 임베딩 벡터가 되어 BERT의 입력으로 사용됩니다. BERT는 내부적 연산을 거친 후, 동일하게 각 단어에 대해서 768차원의 벡터를 출력합니다. 위 그림에서는 BERT가 각 768차원의 [CLS], I, love, you라는 4개의 벡터를 입력 받아서(입력 임베딩) 동일하게 768차원인 4개의 벡터를 출력하는 모습(출력 임베딩)을 보여줍니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/115055/%EA%B7%B8%EB%A6%BC2.PNG\">\n",
    "\n",
    "BERT의 연산을 거친 후, 출력 임베딩은 문장의 문맥을 모두 참고한 문맥을 반영한 임베딩이 됩니다. 위 좌측 그림의 [CLS] 벡터는 BERT의 초기 입력으로 들어갈 때는 단순히 임베딩 층을 지난 임베딩 벡터였지만, BERT를 지나면서 [CLS], I, love, you를 모두 참고한 후, 문맥 정보를 가진 벡터가 됩니다. 이는 다른 단어들도 모두 마찬가지입니다. \n",
    "\n",
    "하나의 단어가 모든 단어를 참고하는 연산은 BERT의 12개 층에서 전부 이루어집니다. 그렇게 12개 층을 모두 거치고 나서야 최종 출력 임베딩을 얻게 됩니다. 그리고 모든 단어들의 문맥을 참고하기 위해 BERT는 셀프 어텐션을 사용합니다. 사실 BERT가 기본적으로 트랜스포머를 사용하기에 각 층마다 multi-head self-attention과 FFNN을 거치고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4) BERT의 Subword tokenizer: WordPiece**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT는 tokenizer로 subword 기반인 WordPiece를 사용합니다. WordPiece는 토크나이저 파트에서 잠깐 나왔습니다. 이는 BPE와 유사합니다. \n",
    "\n",
    "BERT에서 토큰화를 수행하는 방식은 다음과 같습니다.\n",
    "\n",
    "> 이미 훈련된 데이터로부터 만들어진 단어 집합이 있을 때\n",
    "> $$$$\n",
    "> 1. 토큰이 단어 집합에 존재한다.  \n",
    "> => 해당 토큰을 분리하지 않는다.\n",
    "> $$$$\n",
    "> 2. 토큰이 단어 집합에 존재하지 않는다.  \n",
    "> => 해당 토큰을 서브워드로 분리한다.  \n",
    "> => 해당 토큰의 첫번째 서브워드를 제외한 나머지 서브워드들은 앞에 \"##\"를 붙인 것을 토큰으로 한다.\n",
    "\n",
    "예를 들어 embeddings란 단어가 입력으로 들어오고 단어집합에 없는 상황이라고 합시다. 그대신 단어 집합에 [em, ##bed, ##ding, #s]가 있습니다. 그렇다면 embeddings란 단어는 다음과 같이 토큰화됩니다.\n",
    "\n",
    "$$embeddings = em + \\#\\#bed + \\#\\#ding + \\#s$$\n",
    "\n",
    "이때, #은 단어의 중간부터 서브워드라는 것을 알려주는 기호입니다. 그렇기에 토큰들을 다시 embeddings로 되돌리는 것은 쉬울 것입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 226k/226k [00:01<00:00, 192kB/s]  \n",
      "Downloading: 100%|██████████| 28.0/28.0 [00:00<00:00, 14.0kB/s]\n",
      "Downloading: 100%|██████████| 455k/455k [00:02<00:00, 233kB/s]  \n",
      "Downloading: 100%|██████████| 570/570 [00:00<00:00, 285kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['em', '##bed', '##ding', '##s']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# BERT-base의 tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "result = tokenizer.tokenize(\"embeddings\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 코드는 transformers 패키지에 있는 BERT의 tokenizer로 embeddings 단어를 토큰화한 것입니다. 우리가 생각했던 것과 같은 결과를 출력하는 것을 볼 수 있습니다. 또한 tokenizer에 단어가 있는지 확인하려면 tokenizer.vocab['단어']를 사용하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14324\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'tokenizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DELPHI~1\\AppData\\Local\\Temp/ipykernel_7336/3987163026.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tokenizer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'tokenizer'"
     ]
    }
   ],
   "source": [
    "print(tokenizer.vocab['bert'])\n",
    "print(tokenizer.vocab['tokenizer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과를 보면 bert는 14324로 맵핑되어 있지만(우리가 소문자로 불러왔기에 BERT는 없다) tokenizer는 존재하지 않기에 KeyError가 발생합니다.\n",
    "\n",
    "밑에는 BERT에서 사용되는 특별 토큰과 맵핑되는 정수들입니다.\n",
    "\n",
    "- \\[PAD] - 0\n",
    "- \\[UNK] - 100\n",
    "- [CLS] - 101\n",
    "- [SEP] - 102\n",
    "- [MASK] - 103"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5) Position Embedding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "트랜스포머에서 Positional Encoding을 통해 단어의 위치를 저장했었습니다. 이와 유사하게 BERT에서도 위치 정보를 저장하기 위해 사용하는 Position Embedding 방법이 있습니다. 차이는 positional encoding은 sin, cos 함수로 만들지만 positiono embedding은 학습을 통해 얻습니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/115055/%EA%B7%B8%EB%A6%BC5.PNG\">\n",
    "\n",
    "위 그림은 포지션 임베딩이 사용되는 것을 보여줍니다. 포지션 임베딩의 아이디어는 굉장히 간단한데 위치 정보를 위한 임베딩 층을 하나 더 사용합니다. 만약 위 그림처럼 문장의 길이가 4라면 4개의 포지션 임베딩 벡터를 학습시킵니다. 그리고 BERT의 입력마다 다음과 같이 포지션 임베딩 벡터를 더해주는 것입니다. (위 0, 1, 2, 3은 0번 포지션 임베딩 벡터, 1번 포지션 임베딩 벡터...를 나타낸다.) \n",
    "\n",
    "실제 BERT에서 문장의 최대 길이를 512로 정하였기에 총 512개의 포지션 임베딩 벡터를 학습합니다. 결론적으로 지금까지 내용을 기준으로 BERT에서는 총 두 개의 임베딩 층을 사용합니다. 단어 집합의 크기가 30,522개인 단어 벡터를 위한 임베딩 층과 문장의 최대 길이가 512이므로 512개의 포지션 벡터를 위한 임베딩 층입니다. \n",
    "\n",
    "여기에 좀 더 뒤에 배울 Segment embedding 층까지 총 3개를 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6) BERT의 Pre-training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![4-9-1](_image/4-9-1.PNG)\n",
    "\n",
    "위 그림은 BERT 논문에 첨부된 그림으로 ELMo와 GPT-1, BERT의 구조적 차이를 보여줍니다. 오른쪽에 있는 ELMo는 정방향 LSTM과 역방향 LSTM을 각각 훈련시키는 양방향 언어 모델을 만들었습니다. 가운데 있는 GPT-1은 트랜스포머의 디코더를 이전 단어들로부터 다음 단어를 예측하는 방식으로 단방향 언어 모델을 만들었습니다. 이는 트랜스포머 챕터에서 배웠던 Maksed multi-head self attention과 같은 방법입니다. \n",
    "\n",
    "마지막으로 좌측에 BERT를 보면 트랜스포머를 사용하면서도 양방향성을 가지는 것을 볼 수 있습니다. 이러한 결과를 얻기 위해 BERT는 사전 훈련 방법으로 masked language model과 next sentence prediction을 사용합니다. \n",
    "\n",
    "<img src = \"https://blog.kakaocdn.net/dn/cX8Xdx/btq89NGpMkS/U8kfQiTnmMS2sy3CWsmKM0/img.png\">\n",
    "\n",
    "\n",
    "#### **Masked Language Model, MLM**\n",
    "\n",
    "MLM은 사전 훈련에서 인공 신경망으로 들어가는 입력 텍스트의 일정 비율(논문은 15%)을 가려서 예측하도록 하는 방법입니다. 이는 양방향 학습이 필연적으로 단어의 정답을 간접적으로 알게 되어 예측이 쉬워지는 것을 방지하기 위함입니다. (GPT-1은 각각 학습하는 방향으로 해결했습니다.) \n",
    "\n",
    "<img src = \"https://miro.medium.com/max/700/0*ViwaI3Vvbnd-CJSQ.png\">\n",
    "\n",
    "위 그림처럼 문장의 일부를 빈칸으로 처리하여 빈칸을 채울 수 있도록 학습하는 것입니다. \n",
    "\n",
    "이러한 MLM은 pre-training 과정에서만 존재합니다. 즉 실제로 사용하는 fine-tuning 과정에선 masked token이 따로 존재하지 않습니다. 이를 pre-training과 fine-tuning 사이에 mismatch가 존재한다고 이야기합니다. 그렇기에 masking을 하기로 정해진 토큰에 대하여 확률을 주어 이 문제를 해결합니다. 아래는 making하기로 결정한 토큰들, 즉 전체 토큰 중 선택된 15%의 토큰들을 다시 세 가지로 나눈 것을 보여줍니다.\n",
    "\n",
    "- 80%의 단어들은 [MASK]로 변경한다.  \n",
    "  EX) The man went to the store -> The man went to the [MASK]\n",
    "- 10%의 단어들은 무작위로 단어를 변경한다.  \n",
    "  EX) The man went to the store -> The man went to the dog\n",
    "- 10%의 단어들은 그대로 유지한다.\n",
    "  EX) The man went to the store -> The man went to the store\n",
    "\n",
    "이제 위 과정을 모두 거쳤다면 trnasformer를 지나며 올바른 답이 나오도록 학습합니다. 즉, softmax 함수를 통과한 i번째 토큰이 원래의 토큰이 되도록 croee-entropy loss를 사용하여 pre-training하는 것입니다.\n",
    "\n",
    "\n",
    "#### **Next Sentence Prediction, NSP**\n",
    "\n",
    "또한 문장 간의 관계를 학습하는 방법인 NSP도 사용합니다. 이를 위해서 50:50 비율로 실제 이어지는 두 개의 문장과 랜덤으로 이어붙인 두 개의 문장을 주고 훈련을 시킵니다. 이때 주어진 문장에도 MLM은 그대로 적용됩니다. \n",
    "\n",
    "![4-9-2](_image/4-9-2.PNG)\n",
    "\n",
    "여기선 위 그림처럼 [CLS]와 [SEP] 토큰이 같이 주어진다. [SEP]는 문장이 끝나는 지점에 붙는 토큰이고 [CLS]는 가장 앞에 붙으며 두 문장이 실제 이어지는 문장인지 아닌지를 판단하는 값이 저장된다. 예를 들어 위 그림의 문장은 서로 연결되기에 [CLS]토큰으로 예측하면 [IsNext] 토큰이 나와야 합니다. 만약 서로 관계가 없는 문장이라면 [NotNext]라는 값을 출력하게 됩니다.\n",
    "\n",
    "\n",
    "BERT는 MLM과 NSP의 loss를 합하여 동시에 학습합니다. 이는 QA(Question Answering)나 NLI(Natural Language Inference)와 같이 두 문장의 관계를 이해하는 것이 중요한 task에서도 큰 힘을 발휘합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7) Segment Embedding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://miro.medium.com/max/700/0*m_kXt3uqZH9e7H4w.png\">\n",
    "\n",
    "위 그림을 보면 우리가 앞서 보았던 WordPiece embedding과 Position embedding을 확인할 수 있습니다. 그리고 문장의 순서를 저장하는 Segment embedding이 추가된 것을 확인할 수 있습니다. 문장은 항상 두 개만 주어지기에 앞문장을 나타내는 A와 뒷문장을 나타내는 B, 두 개의 값만 사용됩니다.\n",
    "\n",
    "그렇기에 결론적으로 BERT는 총 3개의 임베딩을 사용합니다.\n",
    "\n",
    "- WordPiece Embedding: 실질적인 입력이 되는 워드 임베딩.  \n",
    "  -> 임베딩 벡터의 종류 = 단어 집합의 크기 = 30,522(BERT의 경우)\n",
    "- Position Embedding: 위치 정보를 학습하기 위한 임베딩.  \n",
    "  -> 임베딩 벡터의 종류 = 문장의 최대 길이 = 512(BERT의 경우)\n",
    "- Segment Embedding: 두 개의 문장을 구분하기 위한 임베딩.  \n",
    "  -> 임베딩 벡터의 종류 = 문장의 최대 개수 = 2\n",
    "\n",
    "이때 BERT가 문장 중간의 [SEP] 토큰과 두 종류의 세그먼트 임베딩을 통해서 두 개의 문장을 구분하여 입력받는다고 설명하지만, 우리가 아는 문장 단위와 다를 수도 있습니다. 예를 들어 QA 문제를 풀 때 [SEP]와 세그먼트 임베딩을 기준으로 구분되는 [질문(Question), 본문(Paragraph)] 두 종류의 입력을 받지만 본문은 실제 다수의 문장으로 구성될 수 있습니다. 그렇기에 [SEP]로 나눠지는 문장은 실제로 두 종류의 텍스트가 될 수도 있는 것입니다.\n",
    "\n",
    "반대로 두 개의 문장을 받을 필요가 없을 수도 있습니다. 영화 리뷰 분류 같은 것은 하나의 문장만 가지고 감정 분류를 해야하기에 A만 사용하여 하나의 문장으로 처리합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **8) BERT Fine-tuning하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdbDqWN%2Fbtq89eCYowg%2FBAbirOgLkPGi1xC70LiJQ1%2Fimg.png\">\n",
    "\n",
    "사전 학습된 BERT에 우리가 풀고자 하는 task의 데이터를 추가로 학습시켜서 테스트 하는 fine-tuning은 실제 task에 BERT를 사용하는 단계에 해당합니다. 트랜스포머의 self-attention을 사용하기에 입력되는 문장의 개수와 상관없이 input을 구성할 수 있으먀, 보통의 경우는 하나의 output layer만 추가하여 end-to-end로 fine-tuning합니다.\n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbZ0bLF%2Fbtq8939XD9J%2FryPrJtK7PVJxRkdCncne0k%2Fimg.png\">\n",
    "\n",
    "위 그림은 대표적으로 사용할 수 있는 네가지 경우를 나타낸 것입니다. entailment(a)와 감성 분석(b)와 같은 classification task는 NSP 방법 그대로 [CLS] 토큰의 representation을 output layer로 넘겨주며 학습합니다. 반대로 Sequence tagging(d)와 QA(c) 같은 토큰 단위의 down-stream task는 토큰의 representation을 output layer로 넘겨주는 형태로 학습이 가능합니다. 이를 조금만 자세히 살펴보겠습니다.\n",
    "\n",
    "여기서 따로 기재가 안되어 있어도 모든 BERT를 사용하는 task들은 공통적으로 사용할 출력층 위에 FC층(Dense layer)을 추가하여 사용합니다.\n",
    "\n",
    "\n",
    "#### **1) 텍스트의 쌍에 대한 분류 또는 회귀 문제(위 그림의 a)**\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/115055/apply3.PNG\">\n",
    "\n",
    "텍스트 쌍을 입력받는 task는 대표적으로 자연어 추론(Natural language inference)이 있습니다. 자연어 추론 문제는 두 문장이 주어졌을 때, 하나의 문장이 다른 문장과 어떤 관계에 있는지 분류하는 것을 말합니다. 이에 대한 결과는 모순(contradiction), 함의(entailment), 중립(natural) 세 가지 중 하나를 가집니다.\n",
    "\n",
    "이렇게 텍스트 쌍을 입력으로 받는 task의 경우, 텍스트 사이에 [SEP]를 집어넣고 두 종류의 세그먼트 임베딩을 모두 사용하여 문서를 구분합니다.\n",
    "\n",
    "\n",
    "#### **2) 하나의 텍스트에 대한 텍스트 분류 유형(위 그림의 b)**\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/115055/apply1.PNG\">\n",
    "\n",
    "이 유형은 영화 리뷰 분류 등 입력된 문서에 대해서 주어진 기준으로 분류하는 task에서 쓰입니다. 앞서 보았듯이 [CLS] 토큰을 문장 앞에 입력합니다. 그리고 구해진 [CLS] 토큰 위에 FC층(밀집층)을 추가하여 분류에 대한 예측을 하게 됩니다. \n",
    "\n",
    "\n",
    "#### **3) QA(위 그림의 c)**\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/115055/apply4.PNG\">\n",
    "\n",
    "QA는 풀기 위한 질문과 본문이 주어지고 이를 이용해 답을 출력하는 형태의 task입니다. 대표적으로 SQuAD(Stanford Question Answering Dataset) v1.1이 있습니다. 이는 wikipedia에서 지문을 가져와 클라우딩 소싱을 이용하여 생성한 데이터를 사용합니다. train 데이터만 공개하고 학습된 모델을 사이트에 올리면 비공개 test data에 의해 평가하고 순위가 매겨집니다. \n",
    "\n",
    "현재는 여기에 답이 없는 문제를 추가한 SQuAD v2.0을 많이 사용합니다. 이떄 BERT(현재 BERT 기반의 모델들이 상위권)는 총 세번의 예측을 하게 됩니다. 먼저 답이 답으로 예측되는 문장의 시작 단어와 끝 단어를 각각 예측하고 마지막으로 [CLS]를 이용하여 주어진 본문에 답이 있는지 예측합니다. \n",
    "\n",
    "\n",
    "#### **4) 하나의 텍스트에 대한 태깅 작업(위 그림의 d)**\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/115055/apply2.PNG\">\n",
    "\n",
    "앞서 RNN 계열의 신경망을 이용해 풀기도 했던 task입니다. 대표적으로 문장의 각 단어에 품사를 태깅하는 품사 태깅과 개체를 태깅하는 개체명 인식 작업 등이 있습니다. 출력층에서는 입력 텍스트의 각 토큰의 위치에 FC층을 사용하여 분류에 대한 예측을 하게 됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **9) BERT의 정보 정리**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 훈련 데이터는 위키피디아(단어 25억개)와 BookCorpus(단어 8억개) $\\approx$ 단어 33억개\n",
    "- WordPiece tokenizer로 토큰화 수행 후, 15% 비율로 MLM 진행\n",
    "- 두 문장의 합한 길이의 최대는 512로 제한\n",
    "- 100만 step 훈련 $\\approx$ 총 33억개의 단어 코퍼스에 대해 40 epoch 학습\n",
    "- optimizer: Adam\n",
    "- learnging rate: $10^{-4}$\n",
    "- weight decay(가중치 감소): L2 정규화로 0.01 적용\n",
    "- dropout: 모든 레이어에 대해 0.1 적용\n",
    "- activation function: GeLU 사용\n",
    "- batch size: 256 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **10) Attention Mask**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://wikidocs.net/images/page/115055/%EA%B7%B8%EB%A6%BC11.PNG\">\n",
    "\n",
    "BERT를 실제로 사용하면 어텐션 마스크라는 시퀀스 입력이 추가로 사용됩니다. 이는 BERT가 어텐션 연산을 할 때, 불필요하게 패딩 토큰에 대해서 어텐션을 하지 않도록 실제 단어와 패딩 토큰을 구분할 수 있도록 알려주는 입력입니다. 이 값은 0과 1 두가지만 가지는데 숫자 1은 마스킹을 하지 않는 실제 단어, 0은 마스킹을 할 패딩 토큰임을 의미합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "- https://wikidocs.net/115055\n",
    "- https://supkoon.tistory.com/24\n",
    "- https://nlpinkorean.github.io/illustrated-bert/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **10. GPT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT(Generative Pre-trained Transformer)는 Open AI에서 개발한 Semi-supervised language model입니다. 트랜스포머의 디코더만을 이용하여 구성되어 있고 이름 그대로 조금의 학습만으로 대부분의 task에서 사용이 가능하도록 사전학습한 모델입니다. \n",
    "\n",
    "현재 GPT-3(2022년 1월 기준)까지 나왔으며 세 모델의 차이는 데이터와 파라미터의 개수 차이 외에는 크게 있지는 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **10.1 GPT-1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GPT-1](https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf)은 크게 unsupervised pre-training과 supervised fine-tuning으로 나눌 수 있습니다. 이를 통해 사전 학습된 모델로 대부분의 task에서 fine-tuning만 거쳐 효과적인 모델을 얻을 수 있게 만듭니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) Unsuperviesd pre-training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised pre-training은 unlabeled token $u=\\{u_1, \\ldots, u_n\\}$을 통해 일반적인 언어모델의 목적함수 Likelihood $L_1(u)$를 최대화하는 과정입니다.\n",
    "\n",
    "$$L_1(u) = \\sum_i logP(u_i|u_{i-k}, \\ldots, u_{i-1};\\theta)$$\n",
    "\n",
    "$k$는 context window의 크기이며, 조건부 확률 $P$는 $\\theta$를 parameter로 갖는 신경망으로 모델링됩니다. \n",
    "\n",
    "이때 GPT-1은 transformer의 decoder block만을 사용하여 언어 모델을 구성합니다. \n",
    "\n",
    "![4-10-1](_image/4-10-1.PNG)\n",
    "\n",
    "여기서 transformer의 decoder block과 한 가지 차이점은 incoder-decoder attention이 없다는 것입니다. 이는 incoder를 가지지 않아 필요가 없기 때문입니다. 이 차이를 제외하면 전반적인 과정은 transformer의 decoder block과 동일하게 진행됩니다.\n",
    "\n",
    "우선 input token matrix $W_e$를 곱한 후, Position embedding $W_p$를 더해 masked self-attention을 위한 input $h_0$을 만들어줍니다.\n",
    "\n",
    "$$h_0 = UW_e + W_p$$\n",
    "\n",
    "GPT-1은 n개의 decoder가 stack된 형태인데 논문에선 12개의 decoder block를 사용했습니다. l번째 decoder block의 hidden state $h_l$은 이전 decoder block의 hidden state $h_{l-1}$를 입력받아 계산됩니다.\n",
    "\n",
    "$$h_l = transformer_block(h_{l-1})\\forall i \\in [1, n]$$\n",
    "\n",
    "마지막 n번째 decoder block의 hidden state $h_n$에 다시 transposed embedding matrix $W_e^T$를 곱하여 softmax 함수를 적용하면 output probability $P(u)$를 구할 수 있습니다.\n",
    "\n",
    "$$P(u) = softmax(h_n W_e^T)$$\n",
    "\n",
    "위 과정으로 모델링한 조건부 확률 $P(u)$를 통해 앞서 말한 일반적인 언어모델의 목적함수 Likelihood $L_1(u)$를 최대화하며 사전 학습을 진행합니다.\n",
    "\n",
    "$$L_1(u) = \\sum_i logP(u_i|u_{i-k}, \\ldots, u_{i-1};\\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) Supervised fine-tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised fine-tuning은 pre-training이 끝난 후, target task에 맞게 parameter를 조정하는 단계입니다. input token sequence $\\{x_1, \\ldots, x_m \\}$과 label $y$로 구성된 target task의 label dataset $C$를 통해 학습이 진행됩니다. \n",
    "\n",
    "우선 $C$의 input token에 대한 GPT의 마지막 decoder block hidden state $h_l^m$을 얻기 위해 앞선 단계에서 얻은 pre-trainded model에 input token을 통과시킵니다.\n",
    "\n",
    "그리고 파라미터 $W_y$를 갖는 하나의 linear layer에 $h_l^m$을 통과시켜 softmax probability $P(y|x^1, \\ldots, x^m)$를 계산합니다.\n",
    "\n",
    "$$P(y|x^1, \\ldots, x^m) = softmax(h_l^m W_y)$$\n",
    "\n",
    "이 결과로 token probability distribution을 얻을 수 있고, 따라서 label $y$에 대해서 지도학습을 진행할 수 있습니다. 지도학습의 목적함수 Likelihood $L_2(C)$ 또한 일련의 구조로 모델링된 조건부확률 $P$를 통해 계산됩니다.\n",
    "\n",
    "$$L_2(C) = \\sum_{(x, y)} log P(y|x^1, \\ldots, x^m)$$\n",
    "\n",
    "저자들은 또한 unsupervised pre-training의 목적함수 $L_1$을 supervised fine-tuning을 위한 auxiliary objective(보조 목표)로서 추가하였습니다. 이때 기존의 $L_1$은 unlabeled dataset $U$에 대한 $L_1(U)$로 계산되었지만, auxiliary objective로서 $L_1$은 labeled dataset $C$에 대해 $L_1(C)$로 계산됩니다. $\\lambda$는 $L_1(C)$의 반영 정도를 정하기 위한 weight 하이퍼 파라미터입니다.\n",
    "\n",
    "$$L_3(C) = L_2(C) + \\lambda L_1(c)$$\n",
    "\n",
    "이 방법은 가중치의 수렴을 도우며, 지도학습 모델의 일반화 성능을 향상시킨다고 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning할 때, 데이터의 양을 설정할 수 있습니다. 몇 개의 데이터가 사용되냐에 따라 세 가지로 나눕니다.\n",
    "\n",
    "- Zero-shot learning: 데이터를 주지 않음, 즉 fine-tuning없이 pre-training된 모델을 바로 사용\n",
    "- One-shot learning: 하나의 데이터 제공, fine-tuning을 하나의 데이터로만 수행\n",
    "- Few-shot learning: 소수(~32)의 데이터 제공, fine-tuning을 소수의 데이터로만 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) Task-specific input transformations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT는 최소한의 구조 변화로 target task에 적용 가능한 언어 모델입니다. 그렇기에 아래의 Classification, Entailment, Similarity, QA(Multiple choice) 등의 task들을 수행할 수 있습니다. 밑의 그림은 각각의 task에 대해 약간의 입출력 구조 변화만으로 GPT를 사용할 수 있음을 보여줍니다.\n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FCzK6I%2Fbtq88LfTmio%2FGSbQMvhVzjy4pvA8UI5O7k%2Fimg.png\">\n",
    "\n",
    "#### **Classification**\n",
    "단순한 classification에 대해선 기존의 방법 그대로 fine-tuning을 진행하면 됩니다. \n",
    "\n",
    "#### **Entailment**\n",
    "Entailment는 전체 Premise를 통해 가설 Hypothesis가 참인지 거짓인지 밝히는 task입니다. 따라서 Delimeter로 나눠진 Permise와 Hypothesis 토큰을 concatenate하여 fine-tuning을 진행하면 됩니다.\n",
    "\n",
    "#### **Similarity**\n",
    "Similarity task는 문장 간의 순서가 존재하지 않습니다. 따라서 가능한 두 가지 순서(위 그림에선 [문장1, 문장2]와 [문장2, 문장1])를 모두 고려합니다. 두 가지 경우를 입력하여 독립적으로 얻은 $h_l^m$을 최종적으로 행렬 간 더하여(element-wise addition) 나온 결과로 fine-tuning을 진행합니다.\n",
    "\n",
    "#### **QA, Multiple choice**\n",
    "QA task는 기본적으로 context document $z$에 대한 question $q$가 제시됩니다. 그리고 주어진 상황에서 가능한 다양한 Answer $\\{ a_k\\}$가 존재합니다. 따라서 QA task는 가능한 다양한 답변을 delimeter \\$와 함께 z + q + \\$ + $a_k$로 concatenate하여 입력합니다. 각각의 경우는 독립적으로 학습되며, 최종적으로 softmax 함수를 통해 답변의 distribution을 계산합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4) Result**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-1를 통한 semi-supervised의 효과를 증명하기 위해 저자들은 Natural language inference, QA, Similarity, Classification의 다양한 dataset을 사용하여 실험했습니다.\n",
    "\n",
    "**Natural language inference**\n",
    "\n",
    "![4-10-2](_image/4-10-2.PNG)\n",
    "\n",
    "NLI에서는 거의 대부분의 dataset에서 GPT-1이 큰 차이로 우수한 성능을 보였습니다. 유일하게 저조한 성능을 보인 RTE 는 크기가 작은 dataset입니다. 따라서 NLI task의 fine tuning은 상대적으로 dataset이 클수록 성능이 좋은 것을 알 수 있습니다. 이때 (3x)는 앙상블 모델을 의미합니다. \n",
    "\n",
    "\n",
    "**QA task**\n",
    "\n",
    "![4-10-3](_image/4-10-3.PNG)\n",
    "\n",
    "모든 dataset에서 성능이 좋은 것을 확인할 수 있습니다.\n",
    "\n",
    "\n",
    "**Classification & Similarity**\n",
    "\n",
    "![4-10-4](_image/4-10-4.PNG)\n",
    "\n",
    "역시 대부분의 실험에서 GPT가 좋은 성능을 보인 것을 확인할 수 있습니다. 이 당시 ELMO + attention의 성능을 대부분 넘은 것은 주목할 부분입니다. \n",
    "\n",
    "\n",
    "**Zero-shot Behaviors**\n",
    "\n",
    "![4-10-5](_image/4-10-5.PNG)\n",
    "\n",
    "왼쪽 그래프는 unsupervised pre-training에서 transformer layer 수에 따른 결과비교입니다. layer 수가 증가할수록 유의미한 성능 향상이 있음을 알 수 있습니다. \n",
    "\n",
    "오른쪽 그래프는 transformer 유무와 pre-training에 따른 각각 task의 zero-shot 성능 비교입니다. 실선은 transformer를 사용한 모델, 점선은 LSTM을 사용한 모델입니다. 대부분의 task가 transformer를 사용했을 때 더 좋은 성능을 보였으며, pre-training을 거듭할수록 그 차이는 커집니다. 특히 zero-shot에 대한 LSTM 성능의 분산이 더 커졌다는 결과를 통해, pre-training이 전반적인 일반화 능력을 제공한다는 것을 알 수 있습니다.\n",
    "\n",
    "\n",
    "**Ablation sudies**\n",
    "\n",
    "![4-10-6](_image/4-10-6.PNG)\n",
    "\n",
    "세 가지 조건변화(Ablation)에 따른 결과 분석입니다. \n",
    "\n",
    "- pre-training의 유무: 사전학습이 큰 성능개선(14.8%)을 가져옴\n",
    "- aux LM(auxiliary objective)의 유무: NLI, QQP task에 도움을 주었으며 특히 큰 dataset에 성능개선을 가져옴\n",
    "- transformer와 LSTM: LSTM에 비해 평균 5.6%의 성능개선을 가져옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "\n",
    "https://supkoon.tistory.com/23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **10.2 GPT-2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GPT-2](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)는 2018년 GPT-1에 이어 2019년에 Open AI에서 개발한 비지도학습 기반 언어 모델입니다. GPT-2는 flexible transfer가 가능하며, 지도학습 형태의 fine-tuning이 없는 zero-shot down-stream task가 가능합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) BERT와 차이점**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-2는 GPT-1이 그러했듯 transformer의 decoder block을 사용합니다. 그러나 BERT는 transformer의 encodr block을 사용합니다. 그러나 이 차이 말고 한 가지 차이가 더 있습니다. 이 차이는 GPT-2가 전통적인 language model처럼 한 번에 하나의 token을 출력한다는 것입니다. \n",
    "\n",
    "먼저 잘 훈련된 GPT-2가 로보틱스의 제 1원칙(\"A robot may not injure a human being or, through inaction, allow a human being to come to harm.\")을 출력하도록 해보겠습니다.\n",
    "\n",
    "<img src = \"https://chloamme.github.io/images/xlnet/gpt-2-output.gif\">\n",
    "\n",
    "이러한 모델들은 각 token이 생성된 후에 입력 시퀀스에 더해지는 방식으로 동작합니다. 그렇게 만들어진 새 시퀀스는 다음 단계에서 모델의 입력으로 들어가게 됩니다. 이를 auto-regression이라고 합니다. 이 방법은 RNN을 엄청나게 효과적으로 만든 방법 중 하나입니다.\n",
    "\n",
    "<img src = \"https://chloamme.github.io/images/xlnet/gpt-2-autoregression-2.gif\">\n",
    "\n",
    "GPT-2와 TransformerXL, XLNet과 같은 후속 모델들은 본질적으로 auto-regressive합니다. 그러나 BERT는 그렇지 않습니다. BERT는 auto-regression 특성을 잃는 대신에 더 좋은 결과를 얻기 위하여 단어의 양쪽 방향으로부터 context를 활용할 수 있는 능력을 취했습니다. 또한 XLNet은 양쪽 방향의 context를 활용하기 대한적 방법과 auto-regerssion을 모두 사용합니다.\n",
    "\n",
    "\n",
    "BERT와 또다른 차이점은 앞서 이야기한 구성 block의 차이입니다. BERT는 incoder block을 사용하고 GPT-2는 (encoder-decoder self-attention을 제거한) decoder block을 사용합니다. 이는 두 모델이 사용하는 self-attention이 다름을 의미합니다. \n",
    "\n",
    "<img src = \"https://chloamme.github.io/images/gpt2/self-attention-and-masked-self-attention.png\">\n",
    "\n",
    "BERT가 사용하는 일반적인 self-attention은 단어의 순서와 관계없이 모든 단어들을 attention합니다. 그러나 decoder block 첫번째에 들어가는 masked self-attention은 자신을 포함한 그 이전 단어만 attention할 수 있습니다. 이는 미리 답을 아는 것을 막기 위함인데 BERT는 미리 답을 아는 것을 NLM으로 막은 반면에 GPT-2는 masked self-attention으로 막은 것입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) GPT-1과 차이점**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FMdPwt%2Fbtq9fWbzKRi%2FZfDCzannYQdXgm15Y9v5R0%2Fimg.png\" width = \"400px\" height = \"450px\">\n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbwCXwR%2Fbtq9lUjBwfe%2Fn4u45rOI7OyqtE6FOhtKQ1%2Fimg.png\" width = \"200px\" height = \"450px\">\n",
    "\n",
    "왼쪽은 GPT-1의 decoder block이고 오른쪽은 GPT-2의 decoder block입니다. \n",
    "\n",
    "GPT-2의 한 가지 변경점은 Layer normalization이 sub block의 input 부분으로 옮겨졌다는 것입니다. 그리고 마지막 self-attention block 이후에 추가적인 layer normalization이 존재합니다. \n",
    "\n",
    "또 다른 변경점은 residual layer의 누적에 따른 initialization의 변화입니다. Residual layer의 깊이 N에 따라 $1/\\sqrt{N} * weight$를 사용하여 residual layer의 가중치를 설정하였습니다. \n",
    "\n",
    "또한 vocabulary의 크기가 50,257개로 증가하였고, 한 번에 입력 가능한 context size는 1024(원래는 512)로 증가하였습니다. \n",
    "\n",
    "이처럼 GPT-2는 GPT-1을 기반으로 하여 모델 자체는 큰 변경점이 없습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) GPT-2의 내부**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-2는 1024개의 token을 처리할 수 있습니다. 각 token은 각자의 경로를 따라 모든 decoder block으로 흘러갑니다. \n",
    "\n",
    "훈련된 GPT-2 모델을 실행하는 가장 간단한 방법은 그 자체가 rambling(패턴없이 되는 대로 퍼져나가는)을 하도록 만드는 것입니다. (기술적 용어로, generating unconditional samples라고 합니다.) 또는 prompt를 주고 특정 주체에 대해 말하도록 할 수도 있습니다. (이 방법은 interactive conditional samples 생성이라고도 합니다.) rambling에서 우리는 간단히 start token을 입력해서 단어들을 생성하기 시작할 수 있습니다. \n",
    "\n",
    "<img src = \"https://chloamme.github.io/images/gpt2/gpt2-simple-output-2.gif\">\n",
    "\n",
    "모델은 input token 하나를 가지고 있기에 경로가 1개만 활성화됩니다. token이 모든 레이어를 연속적으로 거쳐 처리되고 나면, 그 경로를 따라 vector가 생성됩니다. 그 vector에 모델의 vocab 전체(GPT-2는 50,000개 단어)에 대해 점수가 매겨질 수 있습니다. 위 경우 가장 확률이 높은 'The'를 택했습니다. 하지만 가끔 가장 높은 것만 택하면 루프에 빠지기도 합니다. 그렇기에 GPT-2는 top-k라는 parameter를 받아서 k번째 단어를 샘플링하게 할 수 있습니다. \n",
    "\n",
    "다음 단계에서, 첫번째 단계의 출력을 입력 시퀀스에 덧붙인 뒤, 모델이 다음 예측을 수행합니다. \n",
    "\n",
    "<img src = \"https://chloamme.github.io/images/gpt2/gpt-2-simple-output-3.gif\">\n",
    "\n",
    "이번 계산은 두 번째 경로만 활성화됩니다. GPT-2의 각 레이어는 첫번째 token의 interpretation을 유지하고, 두번째 token을 처리할 때에 사용합니다. (이는 self-attention을 다시 살펴보면서 자세히 알아보겠습니다.) GPT-2는 두번째 token에 비추어 첫번째 token을 재계산(re-interpret)하지 않습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 모델을 더 상세히 보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **입력 Encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력부터 시작합니다. GPT-2 모델은 다른 NLP 모델들처럼 embedding matrix에서 입력 단어의 embedding을 조회합니다. (이 embedding matrix는 학습된 모델의 일부로서 얻을 수 있는 구성 요소 중 하나입니다.)\n",
    "\n",
    "<img src = \"https://chloamme.github.io/images/gpt2/gpt2-token-embeddings-wte-2.png\">\n",
    "\n",
    "각 행은 단어 embedding입니다. 단어를 표현하고 그 의미를 포함(capture)하는 숫자형태의 표현(representation) 리스트입니다. 이 리스트의 크기는 GPT-2 모델의 크기마다 다르며 가장 작은 모델은 단어(token) 당 768 embedding입니다. \n",
    "\n",
    "처음에는 embedding matrix에서 시작 토큰 \\<s>의 embedding을 조회합니다. 모델의 첫번째 block에 이 정보를 전달하기 전에, positional encoding 정보를 합쳐서 단어의 순서 정보도 저장합니다. (position encoding은 transformer 챕터를 참고하세요.)\n",
    "\n",
    "<img src = \"https://chloamme.github.io/images/gpt2/gpt2-positional-encoding.png\">\n",
    "\n",
    "이로써 입력 단어들이 transformer의 첫번째 block에 전달되기 전에 거쳐야할 처리들을 수행했습니다. 또한 훈련된 GPT-2는 두 개의 weight matrix가 있다는 것도 확인할 수 있습니다. \n",
    "\n",
    "<img src = \"https://chloamme.github.io/images/gpt2/gpt2-input-embedding-positional-encoding-3.png\">\n",
    "\n",
    "word를 transformer block의 첫번째로 전달하는 것은 그 word의 embedding과 positional encoding vector를 더하는 것을 의미합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **상위 stack으로의 이동**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 첫번째 block은 token을 self-attention 프로세스를 통해 전달하고, neural network 레이어로 전달하여 처리할 수 있습니다. 첫번째 block이 token을 처리하면, 그 결과 vector를 다음 block에서 처리하도록 상위 stack으로 올립니다. 프로세스는 각 block마다 동일하지만 각 block은 각자의 self-attention 및 neural network 하위 레이어에 대한 가중치를 가지고 있습니다. \n",
    "\n",
    "<img src = \"https://chloamme.github.io/images/gpt2/gpt2-transformer-block-vectors-2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Self-Attention Recap**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "언어는 context(문맥)에 매우 의존적입니다. 예를 들어, 로보틱스 제 2원칙(A robot must obey the orders given it by human beings except where such orders would conflict with the First Law.)에 나오는 대명사들은 context로 보지 않고 문장만 보면 무엇을 말하는지 알 수 없습니다. 그렇기에 앞에서 나온 문장들을 토대로 대명사가 무엇을 의미하는지 알아야 합니다. 이를 수행하는 것이 self-attention입니다.\n",
    "\n",
    "단어를 처리하기 전에. 특정 단어의 context를 설명하는 관련 word들에 대한 모델의 이해를 만듭니다. segment에서 각 word가 얼마나 관련되어 있는지 점수를 할당하고, 그 vector representation을 합산하는 방식으로 동작합니다. \n",
    "\n",
    "예를 들어, 상단의 block에서 self-attention 레이어는 단어 \"it\"을 처리할 때, \"a robot\"에 attention을 줍니다. neural network로 전달하는 vector는 그 3개의 단어들의 vector에 각 점수들을 곱한 것의 합입니다. \n",
    "\n",
    "<img src = \"https://chloamme.github.io/images/gpt2/gpt2-self-attention-example-2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Self-Attention Process**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self-attention은 segment에서 각 token의 경로를 따라 처리됩니다. 중요한 요소들은 다음 세 가지 vector들입니다. \n",
    "\n",
    "- Query: Query는 다른 모든 단어들과 점수를 계산하는데(각 단어마다 고유한 key값을 사용하는데) 사용되는 현재 단어의 representation입니다. 우리는 현재 처리 중인 token의 Query 값만 고려합니다. \n",
    "- Key: Key vector는 segment에서 모든 단어들에 대한 레이블과 같습니다. 관련 단어를 검색할 때, 매칭해보는 항목입니다. \n",
    "- Value: Value vector는 실제 word representation입니다. 각 단어가 얼마나 관련이 있는지 점수를 매기고 나면, 현재의 단어를 representation하기 위해 합산한 값입니다. \n",
    "\n",
    "<img src = \"https://chloamme.github.io/images/gpt2/self-attention-example-folders-3.png\">\n",
    "\n",
    "대략적으로 비유하자면 서류 캐비넷 중에서 어떤 하나의 서류를 찾는 것과 같다고 생각할 수 있습니다. Query는 찾고자 하는 주제를 적은 메모지입니다. Key는 캐비넷 안의 서류 폴더들에 달린 레이블과 같습니다. 메모지와 레이블을 매칭시키면, 폴더에서 내용물을 꺼내는데 이것이 바로 value입니다. 단지 다른 점은, 하나의 value만 찾는 것이 아니라 여러 폴더들에서 여러 value들의 혼합을 찾는다는 것입니다.\n",
    "\n",
    "Query vector를 각 key vector에 곱해서, 각 폴더별 점수를 구합니다. 즉, 각 값을 내적한 뒤 softmax 연산을 하는 것입니다. \n",
    "\n",
    "<img src = \"https://chloamme.github.io/images/gpt2/self-attention-example-folders-scores-3.png\">\n",
    "\n",
    "각 value를 위에서 구한 점수와 곱한 뒤, 합산합니다. 그러면 self-attention 결과가 나오게 됩니다.\n",
    "\n",
    "<img src = \"https://chloamme.github.io/images/gpt2/gpt2-value-vector-sum.png\">\n",
    "\n",
    "결과를 보면 50%는 'robot', 30%는 'a', 19%는 'it'에 attention을 준 vector가 생성된 것을 알 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **모델 출력**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 최상위 block의 self-attention과 neural network 계산을 거친 output vector를 생성할 때, 모델은 그 vector와 embedding matrix를 곱합니다. \n",
    "\n",
    "<img src = \"https://chloamme.github.io/images/gpt2/gpt2-output-projection-2.png\">\n",
    "\n",
    "Embedding matrix의 각 행은 모델 vocab 단어들의 embedding에 해당합니다. 이 곱셈의 결과는 모델의 vocab에서 각 단어에 대한 점수로 해석됩니다. 즉, 단어를 선택하기 위한 점수로 사용할 수 있습니다. \n",
    "\n",
    "<img src = \"https://chloamme.github.io/images/gpt2/gpt2-output-scores-2.png\">\n",
    "\n",
    "가장 높은 점수를 갖는 token을 선택할 수 있지만(top_k=1) 모델이 다른 단어들도 고려한다면 더 좋은 결과를 얻을 수 있습니다. 그렇기에 더 좋은 방법은 전체 리스트에서 점수를 어떤 단어를 고르기 위한 확률값으로 사용하여 단어를 선택하는 것입니다. (이는 점수가 높으면 뽑힐 확률이 더 높다는 의미입니다.) 절충안은 top_k를 40으로 잡고 모델이 가장 높은 score를 갖는 40개의 word를 고려하도록 하는 것입니다.\n",
    "\n",
    "<img src = \"https://chloamme.github.io/images/gpt2/gpt2-output.png\">\n",
    "\n",
    "그렇게 해서, 모델은 하나의 word를 출력하면서 한 iteration을 종료합니다. 모델은 전체 context가 생성(1024개의 token)될 때까지나 EOS(end-of-sequence) token이 생성될 때까지 iteration을 계속 수행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **설명을 위해 단순화 된 것들**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \"word\"와 \"token\"이 같은 의미로 사용되었지만 실제로는 다릅니다. GPT-2는 vocab의 token들을 만들기 위해 BPE을 사용합니다. 이것은 일반적으로 token이 word의 일부임을 의미합니다. token이 subword가 되기 때문입니다.\n",
    "- 예로 든 GPT-2는 inference(추론)/evaluation(평가) 모드입니다. 그렇기에 한 번에 하나의 word만 처리합니다. Training(학습) 시에는, 모델은 더 긴 문자열 시퀀스에 대해 학습하며, 한 번에 여러 개의 token을 처리합니다. 또한 모델은 evaluation 때 사용하는 배치 사이즈보다 더 큰 배치 사이즈(512)를 처리합니다. \n",
    "- 그림에서 공간을 효율적으로 처리하기 위해 회전/치환을 자유롭게 사용했으나 구현 때는 정확하게 사용해야 합니다.\n",
    "- Transformer는 layer normalization을 많이 사용하며 꽤나 중요합니다. \n",
    "- Vector를 표현하기 위해 더 많은 box들로 표현해야 할 때가 있습니다. 위 그림에선 상자들을 \"zoom in\"하여 표시했습니다. 예를 들어 다음과 같습니다.\n",
    "\n",
    "<img src = \"https://chloamme.github.io/images/gpt2/zoom-in.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4) Self-Attention**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞선 주제였던 deep-learning과 transformer 챕터에서 공부했기에 건너뛰어도 괜찮습니다. \n",
    "\n",
    "*주말에 추가할 것*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5) Training Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-1과 GPT-2의 차이점을 몇 개 보았지만 가장 큰 차이는 training dataset에 있습니다. GPT-2의 가장 큰 목적은 zero-shot으로도 유의미한 결과를 얻을 수 있는 General language model을 개발하는 것이었습니다. 그렇기에 GPT-2는 기존의 연구와 다르게 하나의 Domain에 치우치치 않고, 최대한 다양한 데이터를 확보하기 위해 Web scraping dataset을 사용하였습니다. Common Crawl과 같은 기존의 Web scrap dataset이 존재하지만 논문 저자들이 품질이 떨어진다 판단하여 직접 만든 WebText dataset을 사용하였습니다. \n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbsFPwS%2Fbtq9kQCK7Cq%2FDmG2KEeaKGKGcHjnd2X7Kk%2Fimg.png\">\n",
    "\n",
    "WebText는 사람이 직접 필터링하였으며 reddit으로부터 최소 3개의 평가를 받은 외부 링크만을 사용하여 수집되었습니다. 또한 추가적인 중복제거 작업에 더하여 위키피디아와 같은 대중적인 문서를 제외하는 과정을 거쳤습니다. 이를 통해 학습, 검증 과정에서 중복을 최소한으로 줄일 수 있습니다. 최종적으로 얻은 40GB의 text로 구성된 WebText 데이터셋은 데이터셋의 품질과 크기, 다양성을 동시에 고려한 데이터셋이라고 말할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6) Input representation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 잠깐 이야기했듯 GPT-2는 BPE 방식의 토큰화를 사용했습니다. 이러한 BPE는 유니코드 시퀀스에서 주로 작동하고 있었기에 13만개 이상의 매우 큰 vocabulary가 필요했습니다. 그에 반해 byte 수준의 BPE는 256개의 vocabulary만을 필요로 합니다. 따라서 GPT-2는 BPE를 byte 수준의 string에 적용했습니다.\n",
    "\n",
    "물론 byte 수준의 BPE에도 문제점은 있습니다. {dog., dog?, dog!}과 같은 단어의 유의미하지 않은 variation을 추가하는 경향이 크다는 것입니다. 이는 vocabulary 크기를 효율적으로 사용하지 못하게 만듭니다. 그렇기에 여기선 문자 수준 이상의 병합을 막음으로 이 문제를 해결하였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7) Result**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 평가 기준\n",
    "- PPL(Perplexity): 모델이 헷갈리는 정도, 낮을수록 좋음\n",
    "- ACC(accuracy): 모델의 정확도, 높을수록 좋음\n",
    "\n",
    "\n",
    "#### **Language Modeling**\n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FSaPuf%2Fbtq9tHX6zr6%2Fk16U4GzYXxyjkHTEM4WvD0%2Fimg.png\">\n",
    "\n",
    "GPT-2는 byte 수준의 BPE를 사용하기에 기존에 존재하는 벤치마크 데이터셋에 자유롭게 적용할 수 있습니다. 위 결과를 보면 fine-tuning을 하지 않은 zero-shot 환경임에도 SOTA(모든 데이터를 사용하여 학습한 모델)에 거의 도달한 것을 확인할 수 있습니다. 그 중 크기가 작은 데이터셋인 PTB, wikiText-2에서 효과가 크게 나타납니다.\n",
    "\n",
    "\n",
    "#### **Children's Book Test(CBT)**\n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb8PtuQ%2Fbtq9jG1rjL4%2FOhtHVxXlZEhhgdGoaTjOa1%2Fimg.png\">\n",
    "\n",
    "CBT 데이터셋은 품사에 따른 성능 비교를 위한 벤치마크 데이터셋입니다. 모델 크기가 커질수록 성능이 급격히 올라가며 가장 큰 모델은 인간과 비슷한 수준까지 올라간 것을 볼 수 있습니다.\n",
    "\n",
    "\n",
    "#### **LAMBADA**\n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb2RvUb%2Fbtq9pDCzivX%2F99iKaBNkjyzPETkgxY9pY1%2Fimg.png\">\n",
    "\n",
    "LAMBADA 데이터셋은 언어모델의 long-term dependency를 측정할 수 있는 벤치마크 데이터셋입니다. GPT-2는 perplexity를 99.8에서 8.6으로 개선했으며 accuracy 또한 59%에서 63%로 향상시키며 SOTA를 넘었습니다. 이를 통해 긴 문장도 잊어버리지 않고 처리할 수 있음을 알 수 있습니다.\n",
    "\n",
    "\n",
    "#### **Winograd Schema Challenge**\n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdmG3Jx%2Fbtq9kP4TUvl%2FW8U1ikiHDhxJpBpuKod7sK%2Fimg.png\">\n",
    "\n",
    "Winograd Schema Challenge는 Text의 모호성(ambiguity)을 푸는 작업을 통해 언어모델의 추론능력을 평가하는 작업입니다. GPT-2는 기존의 SOTA 모델보다 7% 높은 정확도를 가지며 훌룡한 추론 능력을 보여줍니다.\n",
    "\n",
    "\n",
    "#### **Reading Comprehension**\n",
    "\n",
    "Conversation Question Answering dataset(CoQA)는 7개 도메인의 문서에 대한 QA를 포함하고 있는 데이터셋입니다. 따라서 CoQA는 언어모델의 문서 이해 능력과 QA 능력을 동시에 평가할 수 있습니다. SOTA 모델인 BERT에 미치지 못했지만, GPT-2는 fine-tuning 없이 55의 F1 score로 좋은 성능을 보였습니다. 이는 GPT-2가 127,000개의 지도학습 데이터를 사용하지 않은 결과이기에 더 고무적입니다. \n",
    "\n",
    "\n",
    "#### **Summarization**\n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FxxisU%2Fbtq9s29i6QD%2FXfWQsFqgrmoTRL1ahdq9B1%2Fimg.png\">\n",
    "\n",
    "Summarization은 CNN, Daily Mail dataset을 사용하여 진행되었습니다. task에 따른 특정한 결과를 유도하기 위해 문서 이후에 TL, DR 토큰을 추가하여 요약 결과를 유도했습니다. 처음 3개의 문장을 요약 결과로 하여 실험한 결과, table과 같이 적당한 수준의 결과를 보입니다. TL, DR 토큰이 없을 때 성능이 더 하락한 것을 보면 힌트를 통한 task 유도가 유의미한 결과를 냄을 알 수 있습니다.\n",
    "\n",
    "\n",
    "#### **Translation**\n",
    "\n",
    "번역 성능에 대한 실험은 WMT-14 English-French dataset을 활용하여, 영어-불어, 불어-영어 두가지 경우에서 비교가 진행되었습니다. 번역 성능은 다른 Task에 비해 좋지 상대적으로 좋지 못했습니다.\n",
    "\n",
    "불어-영어의 경우에는 SOTA를 달성하지는 못하였지만 기존의 모델보다는 좋은 성능을 보여준 데에 비해(BLEU = 11.5),\n",
    "\n",
    "영어-불어의 경우 word by word로 번역하는 모델보다도 좋지 못한 성능을 보여주었습니다. (BLEU = 5)\n",
    "\n",
    "\n",
    "#### **QA**\n",
    "\n",
    "QA task에서 일반적으로 사용하는 '정확히 일치 하는지' 여부(exact match metric)를 지표로 비교하였을 때에는 4.1%의 정확도로 기존의 모델들보다 5.3배 높은 정확도를 보였습니다.\n",
    "\n",
    "매우 작은 모델들은 대체로 1%를 넘지 못하는 성능을 보였는데, 아직까지는 모델의 크기가 QA에 있어서 매우 중요한 요인이라는 것을 확인할 수 있었습니다.\n",
    "\n",
    "GPT-2는 가장 자신있던 질문 1%에 대해 평균 63% 정도의 정확도를 보였습니다.\n",
    "\n",
    "아래의 표는 확률을 통해 가장 자신있던 30개의 질문에 대한 답변을 옮겨놓은 결과입니다.\n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcBhFQq%2Fbtq9pCDt0z6%2FlGVwPKHRbPw9R4GWNuARY0%2Fimg.png\">\n",
    "\n",
    "\n",
    "#### **Generalization vs Memorization**\n",
    "\n",
    "Train set과 Test set의 과도한 중복(Overlap)은 모델의 Memorization을 유도하고 Generalization 성능을 왜곡하여 나타낼 수 있습니다. 이러한 현상은 저자들이 생성한 WebText 데이터셋에서도 나타날 수 있습니다.\n",
    "\n",
    "다음 표는 벤치마크 데이터셋에서의 Overlap 정도를 보여줍니다.\n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FCNsEi%2Fbtq9pCwJ7ct%2FKRv0Ym50NE5MzSHsK6IQd1%2Fimg.png\">\n",
    "\n",
    "WebText 데이터셋과 기존 데이터셋이 크지 않은 overlap을 보였지만, 어느정도 영향이 있었음을 확인할 수 있습니다. 하지만 이는 기존 데이터셋이 Train,Test set 간에 가지고 있던 overlap에 비해서는 특별히 크지 않았다고 합니다.\n",
    "\n",
    "Memorization의 정도는 hold-out set과의 성능비교를 통해서도 확인해 볼 수 있습니다. 아래의 그래프에서 Test set과 Train set의 성능은 거의 비슷하며, 또한 모델 크기에 따라서 동시에 성능이 증가하고 있습니다. 이는 Memorization이 모델 성능개선에 큰 요인이 아니었으며, 모델이 아직 underfitting 되어 더 개선될 여지가 있음을 보여줍니다.\n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fk3iR9%2Fbtq9gqddVdF%2FgbQkriqHTVV2MbdgKWHR91%2Fimg.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference \n",
    "\n",
    "https://supkoon.tistory.com/25?category=871653  \n",
    "https://chloamme.github.io/translation/2021/12/08/illustrated-gpt2-korean.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **10.3 GPT-3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) Intro**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention과 Transformer가 등장하고 pre-training과 fine-tuning으로 근래의 언어모델은 대부분의 NLP task를 급격히 성장시켰습니다. 이러한 모델들을 대부분의 task에서 잘 작동하는 **task-agnostic** 모델이라고 합니다. 그러나 이 역시 한계점은 존재합니다. 바로 fine-tuning 과정에서 아직은 작게는 수천, 많게는 수만의 labeled supervised dataset을 필요로 한다는 것입니다. 이 한계점은 세 가지 관점에서 굉장히 중요합니다.\n",
    "\n",
    "1) 매번 새로운 target task에 대하여 **대용량의 labeled dataset을 확보하는 것** 은 실용적인 관점에서 **매우 비효율적** 이다. 특히 몇몇 고수준 NLP task는 labeling 비용이 매우 높습니다.  \n",
    "2) 매우 큰 모델에서 좁은 분포의 데이터를 학습하는 것은 **가짜 상관관계(spurious correlations)** 를 만들 가능성을 키웁니다. Pre-training을 위해 크게 설계된 모델을 좁은 task distribution에 fine-tuning하는 과정은 매우 큰 모델에 좁은 분포의 데이터를 학습하는 것과 같습니다. 더 큰 모델이라고 해서 작은 모델에 비해 Out-of-distribution에 대한 generalization 성능이 높은 것은 아니라는 연구가 존재합니다. 따라서 사전 학습에 적합한 모델을 다른 분포의 데이터에서 fine-tuning한 이전의 결과들은 과장되어 있을 가능성이 큽니다.\n",
    "3) **인간** 은 새로운 language task를 배우는데 많은 예시가 필요하지 않습니다. 즉, 실제 인간의 언어능력은 adaptability, fluidity, generality를 갖추고 있어 여러가지 작업을 자유자제로 합치며 바꿀 수도 있습니다.\n",
    "\n",
    "이러한 이슈들은 다룰 수 있는 한 가지 방법은 바로 **Meta-learning** 입니다. Meta-learning은 학습 과정에서 다양한 스킬과 패턴인식 능력을 동시에 키워, inference 단계에서 원하는 task에 빠르게 적응할 수 있도록 모델을 학습시키는 방법입니다. \n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FrhU45%2Fbtq9zE2Qkp5%2F64PdfSKcmJBTCbnu6VdJsK%2Fimg.png\">\n",
    "\n",
    "GPT-2는 Meta-learning의 한 가지 방법인 in-context learning을 통하여 학습되었습니다. in-context learning은 원하는 task에 대한 간단한 설명을 함께 input하여 주는 방법입니다. 하지만 GPT-2가 모든 task에서 잘 작동하지는 않았습니다. 특히 QA와 Reading Comprehension 등의 task에서 기존의 SOTA 모델에 비해 큰 차이로 한계를 보이며 fine-tuning이 아직 한계가 많음을 드러냈습니다. \n",
    "\n",
    "한편 최근 언어 모델의 트렌드는 Transformer를 기반으로 하여 모델의 크기를 아주 크게 늘리는 것이었습니다. 모델의 크기 증가가 down-stream task의 성능을 증가시킨다는 것은 어느정도 검증된 사실입니다. 그렇기에 in-context learning 또한 모델의 크기 증가에 따라 일반화 능력도 커질 것으로 생각하고 총 1,750억개의 파라미터로 만들어진 autoregressive language model **GPT-3** 를 만들었습니다. 이는 기존 15억개의 파라미터를 가지는 GPT-2의 100배가 넘는 파라미터 수를 가집니다. \n",
    "\n",
    "**In-context learning** 은 모델의 context window에 주어지는 예시의 개수에 따라 **One-shot, Zero-shot, Few-shot** 환경으로 구분할 수 있습니다. 본 논문에선 Meta-learner로서의 성능을 검증하기 위해 24개 이상의 데이터셋 환경에서 앞선 세 가지 조건으로 GPT-3를 검증했습니다. 다음의 그래프가 크기에 따른 다른 3개의 GPT 모델을 예시의 수에 따라 비교한 결과입니다. \n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbZxe7j%2Fbtq9BZsNM5c%2FTN7iO6n8P8Gx5jWamwOm2K%2Fimg.png\">\n",
    "\n",
    "Fine-tuning없이 pre-training만으로 진행된 다음의 실험은 모델의 크기와 예시의 수(K)에 따른 성능변화가 명확함을 보여줍니다. GPT-3는 zero-shot과 few-shot 환경에서도 매우 우수한 성능을 보여줍니다. 특히 few-shot의 경우 기존 SOTA 모델들보다 우수한 성능을 보이는 경우도 있습니다. 반대로, GPT-3의 크기에도 불구하고 few-shot 환경에서도 매우 고전하는 task 또한 존재합니다. \n",
    "\n",
    "[Language Models are Few-Shot Learners](https://arxiv.org/pdf/2005.14165.pdf)은 2020년 Open AI팀에서 발표한 논문으로, GPT-3의 장단점와 한계, 그리고 언어모델의 few-shot learning에 대한 전반적 연구를 다룹니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) Model Architecture**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-3는 GPT-2와 거의 유사합니다. 왜냐하면 GPT-2에서 모델의 크기, 데이터셋의 크기, 다양성, 학습 횟수를 전반적으로 늘린 모델에 불과하기 때문입니다. 한 가지 다른 점은 일정한 패턴을 두고 attention을 적용하는 sparse transformer를 사용했다는 정도입니다. \n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbDS5ie%2Fbtq9EiejAo6%2FPGhwqU20IvxpqNep14d5Y0%2Fimg.png\">\n",
    "\n",
    "개발자들은 모델 크기에 따른 성능 의존도를 확인하기 위해 1억 2,500만 ~ 1,750억 개의 파라미터에 이르기까지 3,000배에 이르는 8가지 크기의 모델을 훈련하였습니다. 마지막 1,750억개의 파라미터를 갖는 모델이 최종적인 GPT-3입니다. \n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FJsEtb%2Fbtq9HK8WEXA%2FMmZ416Sd2Th9GxECiNiFHk%2Fimg.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) Approach**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-3가 사용하는 in-context learning의 방법은 GPT-2와 비슷하지만, GPT-3는 zero-shot, one-shot, few-shot의 조건으로 in-context learning을 세분화합니다. In-context learning을 보기 전에 먼저 fine-tuning부터 살펴보겠습니다.\n",
    "\n",
    "#### **Fine-tuning**\n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FnUlbU%2Fbtq9GsHrfS0%2Fw27MyTin9LzeJ3lpyDYYJK%2Fimg.png\">\n",
    "\n",
    "Fine-tuning은 앞서 봤듯이 최근 가장 많이 사용되는 방법입니다. 이미 학습된 pre-trained language model에 labeled dataset을 사용하여 특정 task에 잘 맞도록 추가적으로 가중치를 조정합니다. 그러나 이 과정에서 수 천개 이상의 task-specific한 labeled dataset이 필요합니다. 이는 앞서 이야기한 3가지 문제점을 야기합니다.\n",
    "\n",
    "1) 매번 새로운 target task에 대하여 **대용량의 labeled dataset을 확보하는 것** 은 실용적인 관점에서 **매우 비효율적** 이다. 특히 몇몇 고수준 NLP task는 labeling 비용이 매우 높습니다.  \n",
    "2) 매우 큰 모델에서 좁은 분포의 데이터를 학습하는 것은 **가짜 상관관계(spurious correlations)** 를 만들 가능성을 키웁니다. Pre-training을 위해 크게 설계된 모델을 좁은 task distribution에 fine-tuning하는 과정은 매우 큰 모델에 좁은 분포의 데이터를 학습하는 것과 같습니다. 더 큰 모델이라고 해서 작은 모델에 비해 Out-of-distribution에 대한 generalization 성능이 높은 것은 아니라는 연구가 존재합니다. 따라서 사전 학습에 적합한 모델을 다른 분포의 데이터에서 fine-tuning한 이전의 결과들은 과장되어 있을 가능성이 큽니다.\n",
    "3) **인간** 은 새로운 language task를 배우는데 많은 예시가 필요하지 않습니다. 즉, 실제 인간의 언어능력은 adaptability, fluidity, generality를 갖추고 있어 여러가지 작업을 자유자제로 합치며 바꿀 수도 있습니다.\n",
    "\n",
    "\n",
    "#### **Few-shot learning**\n",
    "\n",
    "<img srg = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbWRvec%2Fbtq9DvLtl4i%2FezHeyYGGVLUhIbYuCfiXD1%2Fimg.png\">\n",
    "\n",
    "task description과 함께 모델의 context window에 K개의 예시를 보여줍니다. 하지만 예시를 사용하여 가중치를 업데이트하지는 않습니다. 보통 10~100개 사이의 예시를 이용하는 경우가 이에 해당합니다. \n",
    "\n",
    "Few-shot 환경은 labeled data 확보에 대한 부담이 감소한다는 거소가 fine-tuning dataset에서 지나치게 좁은 분포를 학습할 가능성이 줄어든다는 이점이 있습니다. 하지만 여전히 소량의 labeled data가 필요하다는 것과 최신 fine-tuning 방법들의 성능에 미치지 못한다는 단점이 존재합니다.\n",
    "\n",
    "\n",
    "#### **One-shot learning**\n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FXIT51%2Fbtq9E4T65qq%2FGKe4ZqKHN56lzZeQ5Ukw9k%2Fimg.png\">\n",
    "\n",
    "모델의 context window에 1개의 예시만을 사용한다는 것을 제외하고는 few-shot과 동일한 특징을 가지고 있습니다. 하지만 fine-tuning의 세번째 단점인 \"인간은 실제로 새로운 language task를 배우는데 많은 예시가 필요하지 않다.\"를 고려할 때, 인간의 학습 방법과 가장 흡사한 in-context learning 방법일 것입니다.\n",
    "\n",
    "\n",
    "#### **Zero-shot learning**\n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbSKMtR%2Fbtq9IDOZXHn%2FsKZBcU85Hgw42OsV6Ox5s0%2Fimg.png\">\n",
    "\n",
    "모델의 context window에 예시를 보여주지 않고, task에 대한 설명만을 넣어줍니다. 이 외에 특징은 one-shot learning과 동일합니다. Zero-shot learning은 극도의 편의성을 제공하는 동시에 robustness 능력을 제공하고, spurious correlation을 피할 수 있게 합니다.\n",
    "\n",
    "하지만 zero-shot 환경은 예시 없이 설명만으로 이루어지기에 성능을 내기 가장 어려운 조건입니다. 어떤 경우에는 인간에게 마저 어려운 작업이 됩니다. Fine-tuning에 비해서 성능은 저조할 수 있지만, 인간 능력과의 비교를 위해서 향후 one-shot이나 zero-shot에 대한 결과는 중요도가 높습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4) Training dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "언어 모델을 학습하기 위한 데이터셋은 web scrapping을 통해 급속도로 확장되어 1조개의 단어로 구성된 Common Crawl dataset에 이르렀습니다. 이는 GPT-3를 학습하기에 충분한 양입니다. 하지만 필터링되지 않은 Common Crawl dataset의 품질은 일반 데이터셋에 비해 현저히 떨어집니다. 따라서 개발자들은 3가지 단계를 거쳐 데이터셋의 평균 품질을 향상시켰습니다.\n",
    "\n",
    "1) 다양한 고품질 corpora와의 유사성을 고려하여 Common Crawl을 다운로드받고 필터링했습니다.\n",
    "2) 문서 수준에서 fuzzy deduplication을 진행하여 중복을 방지했습니다.\n",
    "3) GPT-2를 위해 생성한 web scrap 기반 고품질 데이터셋인 WebText dataset을 포함하여, 추가적인 dataset을 Common Crawl에 더하는 augmentation 방법으로 데이터셋의 다양성을 증가시켰습니다.\n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FZUrwd%2Fbtq9EgOkTw3%2F7VNSsZoSqKIO3WzfA9uqpk%2Fimg.png\">\n",
    "\n",
    "위 테이블은 GPT-3의 학습을 위해 사용된 최종 dataset의 구성 비율입니다. \n",
    "\n",
    "또한 학습과정에서는 구성 비율이 아닌 데이터셋의 품질에 비례한 확률로 샘플링을 진행하였습니다. table의 \"Weight in training mix\"가 바로 이 샘플링 가중치를 의미합니다. 가중치를 이용하여 샘플링한 결과, Common Crawl이 가장 큰 비율을 차지하고 있음에도 상대적으로 품질에 따른 가중치가 높지 않아 평균적으로 1회보다 적게 샘플링 외었습니다. 반면에 다른 데이터셋들은 상대적으로 작은 비율에도 2~3회 샘플링되었습니다. 이는 본질적으로 더 높은 품질의 훈련 데이터에 대한 대가로 소량의 과적합을 허용했음을 의미합니다.\n",
    "\n",
    "만약 학습데이터와 검증데이터 사이에 중복이 생긴다면 GPT-3와 같이 매우 큰 모델은 그것을 외워버립니다. 따라서 개발자들은 본 논문에 포함된 모든 벤치마크 데이터셋의 검증, 테스트셋 사이의 중복(overlap)을 고려하고 해소하려 했습니다. 하지만 학습이 한참 진행되던 와중에 버그가 발생하였고, 다시 학습하는 경제적 비용이 너무 크다고 판단하여 다시 학습을 진행하지는 않았다고 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5) Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본 논문의 절반 이상(그러니 최소 37.5페이지 이상)은 다양한 검증 과정에 대한 내용이 주를 이룹니다. 따라서 각 task에 대한 결과가 매우 많습니다. 각 task의 결과는 [논문을 리뷰한 블로그](https://supkoon.tistory.com/27)와 [논문](https://arxiv.org/pdf/2005.14165.pdf)을 참고하시기 바랍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6) Limitations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-3가 마주한 한계점들 또한 여러 개가 존재합니다.\n",
    "\n",
    "\n",
    "#### **성능적 한계**\n",
    "\n",
    "GPT-3는 양적, 질적으로 매우 큰 성능 향상을 보였지만, GPT-2와 비교하여 여전히 몇몇의 NLP task에선 성능적 한계를 보였습니다. 또한 텍스트 생성 시, 문단 수준에서 동일한 내용을 반복하는 경우도 있었습니다. \n",
    "\n",
    "또한 \"치즈가 냉장고에 있으면 녹을까?\"와 같은 간단한 물리학 상식 분야를 잘 풀지 못했습니다. (이는 글로만 세상을 배운 한계로 볼 수도 있을 것입니다.) 독해능력을 테스트하는 경우에도 in-context learning이 큰 효과를 가져오진 못한 것으로 보입니다. \n",
    "\n",
    "이러한 성능 저하는 다른 분야에서 GPT-3가 보여주는 few-shot in-context learning의 뛰어난 효과와 비교되며 더욱 두드러집니다. \n",
    "\n",
    "\n",
    "#### **구조와 알고리즘의 한계**\n",
    "\n",
    "GPT-3는 Auto-regressive 언어 모델입니다. 또한 GPT-3의 구조는 transformer의 decoder block으로 구성되기에, masked self-attention에 기반하고 있습니다. Maksed self-attention은 엄밀히 따지면 bi-directional한 구조가 아닙니다. 또한 본 모델은 de-noising을 고려하는 목적함수를 설정하지도 않았습니다.\n",
    "\n",
    "이러한 구조, 알고리즘적 문제가 일부 분야에서 성능적 한계를 크게 불러왔을 가능성이 있습니다. 기존의 연구들을 보면, 먄약 GPT-3와 비슷한 크기의 bi-directional 모델이 있다면 GPT-3보다 뛰어난 fine-tuning 성능을 보일 것으로 예상됩니다. 따라서 GPT-3 규모의 양방향 모델이나 few-shot, zero-shot 기반의 양방향 모델에 대한 향후 연구 가치가 존재한다고 저자들은 말합니다.\n",
    "\n",
    "\n",
    "#### **근본적인 한계**\n",
    "\n",
    "언어모델의 최근 트렌드는 Scaling up입니다. 언어모델 자체의 근본적 문제가 아닌, 모델과 데이터의 크기에 이목이 집중되고 있습니다. 하지만 pre-training 과정에서 기존의 목적함수는 본질적인 한계가 존재합니다. 현재의 목적함수는 모든 토큰에 동일한 가중치를 부여하며, 어떠한 토큰이 덜 중요하거나 더 중요한지 고려하지 못하고 있습니다. \n",
    "\n",
    "또한 현재의 pre-training 목적함수는 단순히 self-supervised 기반의 prediction에 불과합니다. 현실의 대부분의 문제들은 단순 예측과는 거리가 멉니다. 따라서 실제 상황에서 대규모의 언어모델을 적용하기 위해서는 언어모델이 단순한 예측보다는 조금 더 목적 지향적인 행동을 할 수 있어야 합니다.\n",
    "\n",
    "\n",
    "#### **훈련의 비 효율성**\n",
    "\n",
    "GPT-3는 pre-training동안 인간이 한 평생 보는 것보다 더 많은 양의 텍스트를 학습합니다. 테스트 과정에서는 few-shot으로 샘플링 효율성을 인간과 가깝게 맞출 수 있지만, 추가적인 정보나 알고리즘의 개선을 통해 사전훈련 과정의 샘플링 효율성을 개선할 필요가 있습니다.\n",
    "\n",
    "\n",
    "#### **Few-shot learning의 불확실성**\n",
    "\n",
    "GPT-3가 정말 새로운 작업을 빠르게 학습하기 때문에 정말로 few-shot 환경에서 잘 작동하는지 확신할 수 없습니다. 오히려 훈련 과정에서 해당 문제를 학습했을 가능성도 존재합니다. Synthetic task는 새롭게 접했을 가능성이 크지만, 번역과 같은 작업은 학습과정에서 접하였을 가능성이 높습니다.\n",
    "\n",
    "사실 이런 불확실성은 인간에게도 존재합니다. 예시를 통해 학습하였을지, 과거에 이미 학습하였을지는 대부분의 경우 불명확합니다. 따라서 few-shot learning의 효용성을 다방면에서 증명하는 것이 향후 연구에서 필요합니다.\n",
    "\n",
    "\n",
    "#### **비용**\n",
    "\n",
    "중간에 버그가 발견되었음에도 학습을 중단하지 못했던 것처럼 GPT-3의 훈련 비용은 매우 크며, 추론 시에도 적지 않은 비용이 발생합니다. 실 사용을 위해서는 각각의 task를 위한 구조로 증류하는(distilation) 과정이 필요할 것입니다. 하지만 이 정도의 대규모 모델을 task-specific하게 distilation한 연구는 아직 존재하지 않습니다. 따라서 향후 연구가 필요합니다.\n",
    "\n",
    "\n",
    "#### **설명 가능성**\n",
    "\n",
    "마지막으로 GPT-3 역시 기존의 딥러닝 시스템과 그 한계를 같이 합니다. \n",
    "\n",
    "우선 black box로서 결정에 대한 설명력이 떨어집니다. 또한 새로운 input에 대해 인간보다 큰 variance를 보입니다. 무엇보다 가장 큰 문제는 data 자체의 bias를 해결하지 못한다는 것입니다. Data의 bias를 해결하지 못한다면 세상에 존재하는 여러 사회적 문제를 그대로 반영하여 실사용할 시, 많은 문제를 야기할 수 있습니다. (종교, 인종 등에 편향적인 학습이 이루어질 수 있습니다.) 따라서 이 파트에 대해 저자들은 한 섹션을 할애하여 상세히 다룹니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7) Broader Impacts**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-3와 같은 언어모델은 코딩, 자동완성, 번역 등 사회 전반에 많은 도움을 가져다 줍니다. 하지만 너무나도 정교해진 성능을 바탕으로 언어모델이 악용되거나 사회에 악영향을 미칠 가능성 또한 증가하고 있습니다. 효용성보다 악용가능성이 큰 것은 아니지만 악용될 가능성이 존재하기에 다음의 문제점을 분석했습니다. \n",
    "\n",
    "\n",
    "#### **악용의 가능성**\n",
    "\n",
    "언어모델은 정교한 생성능력을 바탕으로 가짜뉴스, 스팸, 피싱, 가짜 에세이 등을 인간보다 쉽게 작성할 수 있습니다. 따라서 이러한 악용사례들이 증사할 가능성이 존재합니다. 또한 사회적인 선동을 위해 사용될 수도 있으며 최악의 경우 해커들에게 악용될 수 있습니다. 따라서 향후 다양한 연구개발을 통해 이러한 가능성을 차단할 필요가 있습니다.\n",
    "\n",
    "\n",
    "#### **편견과 공정성에 대한 우려**\n",
    "\n",
    "앞서 한계로 지적했듯, GPT-3는 기존 학습데이터에 존재하는 데이터의 bias를 필터링없이 학습합니다. 저자들이 진행한 분석에 따르면 인터넷의 데이터를 통해 학습된 모델은 인터넷에 존재하는 bias를 그대로 갖고 있었다고 합니다. \n",
    "\n",
    "먼저 **성별(Gender)** 에 대한 bias를 관찰하기 위해 저자들은 성별과 직업의 상관관계를 분석했습니다. \"The {occupation} was a {Gender identifier}\" 와 같은 문장을 통해 실험한 결과, 388개의 직업 중 83%의 경우 남성에 관련된 어휘를 선택했다고 합니다. 특히 신체적인 능력을 필요로 하는 목공, 보안관 같은 직업이나 고학력을 요구하는 국회의원, 교수 등에서는 더욱 남성에 편향된 단어들을 선택했습니다. 접수원, 가사도우미와 같은 직종에서 여성과 관련된 단어가 나타나는 것과 대조적이라고 할 수 있습니다.\n",
    "\n",
    "또한 저자들은 다음과 같은 두 가지 환경에서 수식을 통해 편견의 정도를 계산해보았습니다.\n",
    "\n",
    "$$\\text{\"The \\{occupation\\} was a \\{Gender identifier\\}\"} \\\\\n",
    "\\text{\"The incompetent \\{occupation\\} was a \\{Gender identifier\\}\"} \\\\\n",
    "\\text{\"The competent \\{occupation\\} was a \\{Gender identifier\\}\"}$$\n",
    "\n",
    "$$\\frac{1}{n_{jobs}} \\sum_{jobs} (\\frac{P(female|Context)}{P(male|Context)})$$\n",
    "\n",
    "수식어가 없는 경우, competent(유능한), incompetent(무능한)의 세가지 경우에서 -1.11, -2.14, -1.15로 모두 남성 편향적인 결과가 나왔습니다. 또한 유능한 항목에서 더욱 남성 편향적 결과가 나온 점에서 gender에 대한 bias가 존재함을 알 수 있었습니다. \n",
    "\n",
    "다음의 결과는 \"He was very\", \"He would be described as\"와 \"She was very\", \"She would be described as\"를 GPT-3에 제시했을 때, 모델이 가장 많이 생성한 단어들의 예시입니다. 그 결과, 여성의 경우 \"Beautiful\", \"Gorgeous\"와 같은 외모 지향적 단어가 주로 선택되었음을 알 수 있습니다.\n",
    "\n",
    "두번째로 **인종(Race)** 에 대한 bias도 있습니다. 이 역시 아래의 문장을 통해 확인해보았습니다.\n",
    "\n",
    "$$\\text{\"the \\{race\\} women was very \\{\\}\"} \\\\\n",
    "\\text{\"the \\{race\\} man was very \\{\\}\"} \\\\\n",
    "\\text{\"People would describe the \\{race\\} person as \\{\\}\"}$$\n",
    "\n",
    "위 세가지 문장을 통해 얻은 결과는 다음과 같습니다. 각 인종에 대한 결과 단어에 sentiment score를 적용한 결과, 인종에 따른 분명한 차이가 존재함을 확인할 수 있습니다. 아시안에 대해선 일관되게 긍정적으로 평가하지만, 흑인에 대해선 상대적으로 좋지 못한 평가가 주를 이루었습니다. \n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcC0Z96%2Fbtq9IDbTy0K%2FpVKukmoTcUCb7OKEpkdm9K%2Fimg.png\">\n",
    "\n",
    "마지막으로 **종교(Religion)** 에 대해서도 50개의 단어를 생성하여 편향에 대한 실험을 진행했습니다. 실험 결과, 인종과 유사하게 특정 종교에 특정 단어들이 연관되어 나타남을 확인할 수 있었습니다. 특히 \"폭력적\", \"테러리스트\"와 같은 단어가 상대적으로 이슬람에서 자주 등장했습니다.\n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FeaVTJP%2Fbtq9EOkovXv%2Fo13PrM6UmMQ41IpNAJi5L0%2Fimg.png\">\n",
    "\n",
    "\n",
    "#### **에너지 효율성 문제**\n",
    "\n",
    "일반적으로 딥러닝 모델들의 경우, 전력 소모량을 크게 고려하지 않습니다. 하지만 GPT-3의 경우, 사전학습 과정에서 하루에 GPT-2의 수백배에 해당하는 전력소비가 일어납니다. 모델의 사전학습에 따른 비용뿐만 아니라, 모델의 수명에 따른 감가상각(비용울 지출해서 구입한, 장기간 사용하는 자산의 비용화) 또한 고려한다면 엄청난 경제적 비용이 따른다고 할 수 있습니다. \n",
    "\n",
    "물론 GPT-3를 한 번 학습하면, 생성 과정에서는 큰 전력소비가 일어나지 않습니다. 하지만 추후에 모델과 알고리즘적인 개선을 통하여 보다 효율적인 모델을 만들 필요가 있다고 저자들은 말하고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **8) GPT3Mix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GPT3Mix](https://arxiv.org/pdf/2104.08826.pdf)는 GPT3로 task를 수행을 위한 학습에 드는 비용이 너무 비싸기에 GPT-3를 활용하여 지도학습을 위한 training data를 만들자는 아이디어를 제시합니다. 그리고 만든 데이터로 상대적으로 작은 모델을(BERT와 같은) 학습하여 task를 해결합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "\n",
    "https://supkoon.tistory.com/27  \n",
    "https://chloamme.github.io/translation/2021/12/18/how-gpt3-works-visualizations-animations-korean.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **11.**"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "168b3bbc19afd1ef550d68b948460bcb86336de7649712fa882c5012c218f57c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
