{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Deep Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Training Neural Networks\n",
    "2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Training Neural Networks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) Sigmoid activation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sigmoid](_image/sigmoid.png)\n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1 + e^{-x}}$$\n",
    "\n",
    "앞서 배웠듯이 0 ~ 1 사이 값을 가지는 함수입니다. 그러나 Neural Networks에서 사용하기엔 많은 문제점이 있습니다.\n",
    "\n",
    "- 기울기 소실\n",
    "- output의 중간값이 0이 아니다.\n",
    "- exp()의 연산이 너무 무겁다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) Softmax activation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P_i = \\frac{e^{z_i}}{\\sum_{j = 1}^k e^{z_j}}$$\n",
    "\n",
    "sigmoid가 두 개의 값으로 분류한다면 softmax는 여러 가지 값으로 분류한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) tanh activation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tanh](_image/tanh.png)\n",
    "\n",
    "$$tanh(x) = 2 \\times sigmoid(x) - 1$$\n",
    "\n",
    "-1 ~ 1의 범위를 갖고 있습니다. sigmoid의 문제점 중 하나인 output의 중간값을 0으로 만들었습니다. 그러나 기울기 소실 문제는 여전히 남아있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4) ReLU(Rectified Linear Unit)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ReLU](_image/ReLU.png)\n",
    "\n",
    "$$computes \\; f(x) = max(0, x)$$\n",
    "\n",
    "학습이 굉장히 빠르고 기울기 소실 문제가 사라집니다. output의 중간값이 0은 아니지만 많이 사용됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sigmoid나 tanh에서 중요한 것 중 하나는 기울기가 살아있는 범위에 input 데이터가 들어가야 유의미한 값이 나온다는 것입니다. 그걸 위해 사용하는 방법이 **Batch Normalization** 입니다. 이를 통해 기울기 소실 문제를 해결할 수 있습니다. \n",
    "\n",
    "$$\\hat{x}^{(k)} = \\frac{x^{(k)} - \\text{E}[x^{(k)}]}{\\sqrt{\\text{Var}[x^{(k)}]}}$$\n",
    "\n",
    "위 식을 통해 평균 0, 분산 1의 input data가 만들어집니다. \n",
    "\n",
    "그 후, Neural Network가 데이터에 말맞게 평균과 분산을 조절합니다.\n",
    "\n",
    "$$y^{(k)} = \\gamma^{(k)} \\hat{x}^{(k)} + \\beta^{(k)}$$\n",
    "\n",
    "이를 통해 $\\gamma$는 표준편차를, $\\beta$는 평균을 학습시킨다. 이렇게 $\\gamma , \\beta$의 최적값을 구하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Optimization Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimization을 위한 방법은 여러가지가 있습니다. 왜냐하면 gradient descent를 그대로 사용하면 변동폭이 너무 크게 일어나기 때문입니다. 이제 하나씩 살펴보겠습니다.\n",
    "\n",
    "여러 방식들이 어떻게 이루어지는지 gif로 보려면 다음 링크로 접속하여 확인하면 됩니다.\n",
    "http://www.denizyuret.com/2015/03/alec-radfords-animations-for.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = 5 # input data\n",
    "dx = 2 # gradient\n",
    "learning_rate = 0.1 # learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) Gradient Descent(SGD)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sgd](_image/sgd.png)\n",
    "\n",
    "일반적인 방법은 현재 자신의 위치에서 측정한 경사에 따라 움직입니다. 그렇기에 위 그림처럼 진동이 엄청나게 일어납니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla gradient descent update\n",
    "x -= learning_rate * dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) Momentum**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![momentum](_image/momentum.png)\n",
    "\n",
    "Momentum은 현재 위치에서 측정한 기울기만 사용하지 않습니다. 전에 지나온 기울기들을 계속해서 합산하여 사용합니다. 그렇기 때문에 진동이 큰 방향은 진동 크기를 줄이고 맞는 방향은 더욱 빠르게 가도록 해줍니다. \n",
    "\n",
    "기울기를 합산할 때, 예전 기울기의 영향력을 줄이기 위해서 0.8 등의 공비를 계속해서 곱해줍니다. \n",
    "\n",
    "<img src = \"https://miro.medium.com/max/1000/1*X9SaxFM6_sBOAMY9TaGsKw.png\">\n",
    "\n",
    "이름이 momentum이듯, 관성처럼 local minimum에 머물지 않고 global minimum으로 가도록 만들어줍니다.\n",
    "\n",
    "이를 코드로 보면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Momentum update\n",
    "mu = 0.8 # 공비\n",
    "v = 0\n",
    "\n",
    "v = mu * v - learning_rate * dx\n",
    "x += v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) Adagrad**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기울기들을 합산할 때, 기울기의 크기가 많이 차이나지 않도록 기울기를 제곱해서 합을 구한다음 루트를 취하여 기울기에 나눠줍니다. 코드를 통해 살펴보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adagrad update\n",
    "cache = 0\n",
    "\n",
    "cache += dx**2\n",
    "x -= learning_rate * dx / (np.sqrt(cache) + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이때 1e-7을 더해주는 이유는 cache가 너무 작아져서 0이 되어 error가 나는 것을 방지하기 위해서입니다.\n",
    "\n",
    "Adagrad는 방향을 잘 찾아가지만 목표에 도달할수록 나누는 값이 너무 커집니다. 그렇기에 한 번의 가는 거리가 점점 작아지고 속도가 느려지게 됩니다.\n",
    "\n",
    "그렇기에 Adagrad를 직접 사용하지 않고 이를 활용하는 방법들을 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4) RMSProp**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adagrad에서 decay_rate를추가하여 오래된 기울기들의 영향력을 제거하는 방식을 도입한 것이 RMSProp입니다. 코드로 구현하면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_rate = 0.1\n",
    "\n",
    "# RMSProp update\n",
    "cache += decay_rate * cache + (1 - decay_rate) * dx**2\n",
    "x -= learning_rate * dx / (np.sqrt(cache) + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5) Adam**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSProp와 Momentum 방식을 합쳐서 사용하는 방법이 Adam입니다. 기본적으로 beta1 = 0.9, beta2 = 0.999, eps = 1e-8을 추천됩니다. 코드로 나타내면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam upgrade\n",
    "m, v = 0, 0\n",
    "beta1, beta2 = 0.9, 0.999\n",
    "\n",
    "m = beta1 * m + (1 - beta1) * dx\n",
    "v = beta2 * v + (1 - beta2) * (dx**2)\n",
    "x -= learning_rate * m / (np.sqrt(v) + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate는 gradient descent에서 움직이는 보폭 비율이라고 생각하면 됩니다. 그렇기에 learning rate가 크면 크게크게 학습하고 작으면 차근차근 학습하게 됩니다. learning rate의 크기에 따라 학습 정도를 살펴보면 다음과 같습니다.\n",
    "\n",
    "![learning_rate](_image/learning_rate.png)\n",
    "\n",
    "하나씩 살펴보면 먼저 작은 값을 가지면 학습속도가 매우 느립니다. 만약 큰 값을 가진다면 학습속도가 빠르지만 어느 순간부터 학습이 진행되지 않습니다. 왜냐하면 현재 위치와 목표점의 거리보다 보폭이 더 크기 때문입니다. 그리고 만약 매우 큰 값을 가진다면 학습이 될 수 있지만 금방 발산해버립니다.\n",
    "\n",
    "그렇기 때문에 epoch가 진행될수록 learning rate를 줄이는 방법을 사용합니다.\n",
    "\n",
    "\n",
    "![learning_rate2](_image/learning_rate2.png)\n",
    "\n",
    "위 그림처럼 loss가 줄지 않을 때마다 learning rate를 줄여서 학습을 진행합니다. \n",
    "\n",
    "learning rate를 늘리거나 줄일 땐, 0.1, 1, 10, 100,... 등 10배씩 키우거나 줄이는 것이 일반적입니다. 또는 $\\sqrt{10} \\sim 3$을 이용해 3배씩 키우거나 줄입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ensemble](_image/ensemble.png)\n",
    "\n",
    "\n",
    "위 그림처럼 여러 가지 모델들의 결과를 합쳐서 하나의 평균값으로 예측하는 것을 Ensemble이라고 합니다. Ensemble은 대체적으로 2 ~ 3% 정도 정답률이 증가합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) L1, L2 Regularization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L1 : \\sum_k \\sum_l \\lvert W_{k, l} \\rvert \\quad (W : \\text{weight decay})$$\n",
    "$$L2 : \\sum_k \\sum_l (W_{k, l})^2$$\n",
    "$$Elastic net(\\text{L1 + L2}) : \\sum_k \\sum_l (\\beta W_{k, l}^2 + \\lvert W_{k, l} \\rvert)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) Dropout**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한 모델에 여러 뉴런이 있습니다. 이 중 임의로 몇 개의 뉴런을 무시하여 다양한 모델들을 사용하는 결과를 주는, 즉 ensemble 효과를 주는 방법을 Dropout이라고 합니다. \n",
    "\n",
    "![dropout](_image/dropout.png)\n",
    "\n",
    "위 그림처럼 임의의 뉴런을 무시하고 진행하는 방식입니다. 위 방식을 여러번 사용하여 ensemble처럼 모든 모델들의 예측값의 평균을 내서 결과를 예측합니다.\n",
    "\n",
    "주의할 점은 Dropout했던 모델을 테스트할 때는 모든 노드를 사용한다는 것입니다. 그렇기에 output이 학습할 때보다 크게 나오게 됩니다. 이를 방지하기 위해 학습 때 사용한 노드의 비중만큼만 output에서 가져옵니다.\n",
    "\n",
    "예를 들어 70%의 뉴런만 사용하여 학습을 진행했다면 실제 테스트할 때도 ouput의 70%를 실제 예측값으로 사용하게 됩니다.\n",
    "\n",
    "이를 코드로 나타내면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.5 # probability of keeping a unit active, higher = less dropout\n",
    "\n",
    "\n",
    "def train_step(X, W, b):\n",
    "    \"\"\"X contains the data\"\"\"\n",
    "    \n",
    "    # forward pass for example 3-layer neural network\n",
    "    H1 = np.maximum(0, np.dot(W[0], X) + b[0])\n",
    "    U1 = np.random.rand(*H1.shape) < p # first dropout mask\n",
    "    H1 *= U1 # drop\n",
    "    H2 = np.maximum(0, np.dot(W[1], H1) + b[1])\n",
    "    U2 = np.random.rand(*H2.shape) < p # second dropout mask\n",
    "    H2 *= U2 # drop\n",
    "    out = np.dot(W[2], H2) + b[2]\n",
    "    \n",
    "    # backward pass: compute gradients...(not shown)\n",
    "    # perform parameter update...(not shown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, W, b):\n",
    "    # ensemble forward pass\n",
    "    H1 = np.maximum(0, np.dot(W[0], X) + b[0]) * p # scale the activations\n",
    "    H2 = np.maximum(0, np.dot(W[1], H1) + b[1]) * p # scale the activations\n",
    "    out = np.dot(W[2], H2) + b[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) Data Augmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가진 데이터들이 적을 때나 더 많이 필요할 때, 데이터들을 변형, 회전, 늘림 등의 과정을 통해 데이터를 늘리는 것을 말합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습1. PyTorch Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) Tensor operation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서는 배열이나 행렬과 매우 유사한 자료구조입니다. PyTorch에서는 텐서를 사용하여 모델의 입력과 출력뿐만 아니라 모델의 파라미터를 나타냅니다.\n",
    "\n",
    "GPU나 다른 연산 가속을 위한 특수한 하드웨어에서 실행할 수 있다는 점을 제외하면, 텐서는 NumPy의 ndarray와 매우 유사합니다.\n",
    "\n",
    "이제 텐서에 대한 다양한 구현을 알아보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터로부터 직접 생성하기\n",
    "data = [[1, 2], [3, 4]]\n",
    "x = torch.tensor(data)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]], dtype=torch.int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy array로부터 생성하기\n",
    "np_array = np.array(data)\n",
    "x = torch.from_numpy(np_array)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor에서 numpy array로 변환하기\n",
    "x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]], dtype=torch.int32) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.0851, 0.0584],\n",
      "        [0.3296, 0.2676]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 다른 텐서와 같은 모양의 텐서 초기화하기\n",
    "x_ones = torch.ones_like(x) # x_data의 속성을 유지합니다.\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x, dtype=torch.float) # x_data의 속성을 덮어씁니다.\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.4402, 0.1129, 0.1370, 0.3384],\n",
      "        [0.3500, 0.0489, 0.0349, 0.6645],\n",
      "        [0.6792, 0.5942, 0.9422, 0.8516]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# 주어진 shape로 초기화하기\n",
    "shape = (3,4)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서의 속성은 텐서의 모양, 자료형 및 어느 장치에 저장되는지를 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 노트북은 gpu가 없다\n",
    "\n",
    "#device = torch.device('cuda')\n",
    "#tensor = tensor.to(device)\n",
    "#print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 텐서간의 연산도 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy 식의 인덱싱과 슬라이싱\n",
    "tensor = torch.ones(3, 4)\n",
    "tensor[:, 1] = 0\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 텐서 합치기, 행으로 길어지도록\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim=0)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 텐서 합치기, 열로 이어지도록\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.mul(tensor) \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor * tensor \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 텐서 곱하기\n",
    "\n",
    "# 요소별 곱(element-wise product)을 계산합니다\n",
    "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
    "\n",
    "# 다른 문법:\n",
    "print(f\"tensor * tensor \\n {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.matmul(tensor.T) \n",
      " tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.],\n",
      "        [3., 3., 3.]]) \n",
      "\n",
      "tensor @ tensor.T \n",
      " tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.],\n",
      "        [3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "# 텐서 간 행렬 곱셈\n",
    "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
    "# 다른 문법:\n",
    "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) Autograd**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch에는 torch.autograd라고 불리는 자동 미분 엔진이 내장되어 있습니다. autograd를 통해 입력 X, 파라미터 W , 그리고 cross-entropy loss를 사용하는 logistic regression model의 gradient를 구하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "tensor([0., 0., 0.])\n",
      "tensor([[ 0.6696, -1.1055,  0.7509],\n",
      "        [ 0.2827,  0.7063,  1.1959],\n",
      "        [ 0.4497,  0.8117,  0.0219],\n",
      "        [ 0.3535,  0.1437,  1.7595],\n",
      "        [-0.3871,  0.4001, -1.1086]], requires_grad=True)\n",
      "tensor([-1.2913,  0.2003,  0.2606], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 입력 및 파라미터 초기화\n",
    "x = torch.ones(5)  # input tensor\n",
    "y = torch.zeros(3)  # expected output\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "print(x)\n",
    "print(y)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0770, 1.1566, 2.8803], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward\n",
    "z = torch.matmul(x,w)+b\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch에서는 node를 크게 2가지 방법의 api를 활용해서 사용합니다.\n",
    "\n",
    "1. torch.nn\n",
    "2. torch.nn.functional\n",
    "\n",
    "torch.nn은 사전에 node를 초기화하고 해당 node에 텐서를 통과시켜 값을 받는 형태지만, torch.nn.functional은 사전에 초기화없이 바로 함수처럼 사용하는 방식입니다.\n",
    "\n",
    "코딩 스타일에 맞춰서 원하시는 api를 사용하시면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6991, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 비용 함수\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "loss = loss_fn(z, y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6991, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델에서 매개변수의 가중치를 최적화하려면 파라미터에 대한 loss function의 도함수(derivative)를 계산해야 합니다. \n",
    "이러한 도함수를 계산하기 위해, loss.backward() 를 호출한 다음 w.grad와 b.grad에서 값을 가져옵니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor([[0.1731, 0.2536, 0.3156],\n",
      "        [0.1731, 0.2536, 0.3156],\n",
      "        [0.1731, 0.2536, 0.3156],\n",
      "        [0.1731, 0.2536, 0.3156],\n",
      "        [0.1731, 0.2536, 0.3156]])\n",
      "tensor([0.1731, 0.2536, 0.3156])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(x.grad)\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본적으로, requires_grad=True인 모든 텐서들은 연산 기록을 추적하고 미분 계산을 지원합니다. 그러나 모델을 학습한 뒤 입력 데이터를 단순히 적용하기만 하는 경우와 같이 forward 연산만 필요한 경우에는, 미분 연산을 위한 값들을 저장해두는 것이 속력 및 메모리의 저하를 가져올 수 있습니다. 연산 코드를 torch.no_grad() 블록으로 둘러싸서 미분 추적을 멈출 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습2. LR vs MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 MNIS dataset을 활용하여 logistic regression model과 MLP model을 구현해보고 학습 파이프라인을 익혀보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) Import packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available is True else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) Preprocess Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "mnist = fetch_openml('mnist_784', cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mnist에 존재하는 각각의 사진은 28*28의 픽셀로 구성된 784차원짜리 벡터로 나타나져 있습니다. 각 픽셀은 0~255 사이의 값으로 흰색부터 검은색 사이의 값을 나타냅니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# preprocess dataset\n",
    "X = mnist.data.astype('float32')\n",
    "y = mnist.target.astype('int64')\n",
    "X = X.values\n",
    "y = y.values\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# scale\n",
    "X /= 255.0\n",
    "print(X.min(), X.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56000, 784)\n",
      "(56000,)\n",
      "(7000, 784)\n",
      "(7000,)\n",
      "(7000, 784)\n",
      "(7000,)\n"
     ]
    }
   ],
   "source": [
    "# split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5)\n",
    "print(X_train.shape) # 80%\n",
    "print(y_train.shape)\n",
    "print(X_val.shape) # 10%\n",
    "print(y_val.shape)\n",
    "print(X_test.shape) # 10%\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize dataset\n",
    "def plot_example(X, y):\n",
    "    \"\"\"Plot the first 5 images and their labels in a row.\"\"\"\n",
    "    for i, (img, y) in enumerate(zip(X[:5].reshape(5, 28, 28), y[:5])):\n",
    "        plt.subplot(151 + i)\n",
    "        plt.imshow(img)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(y)\n",
    "        \n",
    "\n",
    "plot_example(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) PyTorch Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch에서는 Custom Dataset을 사용하기 위해서는 torch.utils.data.Dataset의 형태로 dataset class를 정의해준 이후, torch.utils.data.DataLoader의 형태로 dataloader class를 정의하여 학습시에 model에 forwarding할 data를 sample해줍니다.\n",
    "\n",
    "(https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)\n",
    "\n",
    "\n",
    "가장 보편적으로 사용되는 map-style의 dataset class는 torch.utils.data.Dataset을 superclass로 받아 **getitem()**과 **len()**함수를 override해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        super(CustomDataset, self).__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.X[index]\n",
    "        y = self.y[index]\n",
    "        x = torch.from_numpy(x).float()\n",
    "        y = torch.from_numpy(np.array(y)).long()\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56000\n",
      "(56000, 784)\n",
      "7000\n",
      "(7000, 784)\n",
      "7000\n",
      "(7000, 784)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "val_dataset = CustomDataset(X_val, y_val)\n",
    "test_dataset = CustomDataset(X_test, y_test)\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(train_dataset.X.shape)\n",
    "print(len(val_dataset))\n",
    "print(val_dataset.X.shape)\n",
    "print(len(test_dataset))\n",
    "print(test_dataset.X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoader는 train 혹은 validation시 dataset에서 batch를 sampling하기 위한 API입니다 (https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader).\n",
    "\n",
    "필수적으로 사용하는 option들은 아래와 같습니다.\n",
    "- dataset: sampling할 dataset\n",
    "- batch_size: 한번에 sampling할 dataset의 개수\n",
    "- shuffle: 1 epoch를 기준으로 dataset을 shuffle할지\n",
    "\n",
    "더 자세한 option은 api를 참고해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875\n",
      "110\n",
      "110\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# shuffle the train data\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# do not shuffle the val & test data\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# dataset size // batch_size\n",
    "print(len(train_dataloader))\n",
    "print(len(val_dataloader))\n",
    "print(len(test_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4) Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch에서 model을 선언할 때는 torch.nn.Module class를 superclass로 받아 __init__()함수와 forward() 함수를 작성해줍니다.\n",
    "\n",
    "__init__()함수에는 모델의 파라미터들을 선언하고, forward함수에는 해당 파라미터들을 이용하여 data를 model에 통과시켜줍니다.\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Logistic Regression Model\n",
    "class LR(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LR, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MLP Model\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5) Train**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 선언한 model을 통해 학습을 진행하기 위해선 파라미터를 최적화할 optimizer가 필요합니다. 이번 실습에선 가장 보편적으로 사용되는 Adam optimizer를 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer\n",
    "class Trainer():\n",
    "    def __init__(self, trainloader, valloader, testloader, model, optimizer, criterion, device):\n",
    "        \"\"\"\n",
    "        trainloader: train data's loader\n",
    "        testloader: test data's loader\n",
    "        model: model to train\n",
    "        optimizer: optimizer to update your model\n",
    "        criterion: loss function\n",
    "        \"\"\"\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.testloader = testloader\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "        \n",
    "    def train(self, epoch = 1):\n",
    "        # 학습을 시작하기 위해 model을 train-mode로 변경\n",
    "        self.model.train()\n",
    "        for e in range(epoch):\n",
    "            running_loss = 0.0  \n",
    "            for i, data in enumerate(self.trainloader, 0): \n",
    "                inputs, labels = data \n",
    "                # model에 input으로 tensor를 gpu-device로 보낸다\n",
    "                inputs = inputs.to(self.device)  \n",
    "                labels = labels.to(self.device)\n",
    "                # zero the parameter gradients\n",
    "                # optimizer는 예전 기울기도 계속 저장하기에 기울기를 초기화해준다.\n",
    "                self.optimizer.zero_grad()    \n",
    "                # forward + backward + optimize\n",
    "                # get output after passing through the network\n",
    "                outputs = self.model(inputs) \n",
    "                # compute model's score using the loss function\n",
    "                loss = self.criterion(outputs, labels)  \n",
    "                # perform back-propagation from the loss\n",
    "                loss.backward() \n",
    "                # gradient descent를 통해 model의 output을 얻는다.\n",
    "                self.optimizer.step() \n",
    "                running_loss += loss.item()\n",
    "            \n",
    "            print('epoch: %d  loss: %.3f' % (e + 1, running_loss / len(self.trainloader)))\n",
    "            running_loss = 0.0\n",
    "        val_acc = self.validate()\n",
    "        return val_acc\n",
    "\n",
    "    def validate(self):\n",
    "        # 현재 model이 train-mode일 수 있기에 eval-mode로 바꿔 validate를 수행할 수 있도록 변경\n",
    "        self.model.eval() \n",
    "        correct = 0\n",
    "        for inputs, labels in self.valloader:\n",
    "            inputs = inputs.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "            output = self.model(inputs) \n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max \n",
    "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "        return correct / len(self.valloader.dataset)\n",
    "        \n",
    "    def test(self):\n",
    "        self.model.eval() \n",
    "        correct = 0\n",
    "        for inputs, labels in self.testloader:\n",
    "            inputs = inputs.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "            output = self.model(inputs) \n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max \n",
    "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "        return correct / len(self.testloader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1  loss: 1.166\n",
      "epoch: 2  loss: 1.194\n",
      "epoch: 3  loss: 1.261\n",
      "epoch: 4  loss: 1.297\n",
      "val_acc: 0.886\n",
      "epoch: 1  loss: 0.356\n",
      "epoch: 2  loss: 0.305\n",
      "epoch: 3  loss: 0.296\n",
      "epoch: 4  loss: 0.294\n",
      "val_acc: 0.919\n",
      "epoch: 1  loss: 0.555\n",
      "epoch: 2  loss: 0.325\n",
      "epoch: 3  loss: 0.295\n",
      "epoch: 4  loss: 0.281\n",
      "val_acc: 0.924\n",
      "epoch: 1  loss: 1.387\n",
      "epoch: 2  loss: 0.735\n",
      "epoch: 3  loss: 0.557\n",
      "epoch: 4  loss: 0.474\n",
      "val_acc: 0.893\n",
      "test_acc: 0.919\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "input_dim = 784\n",
    "output_dim = 10\n",
    "epoch = 4\n",
    "\n",
    "best_acc = 0.0\n",
    "lrs = [1e-1, 1e-2, 1e-3, 1e-4]\n",
    "for lr in lrs:\n",
    "    model = LR(input_dim=input_dim, output_dim=output_dim).to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    trainer = Trainer(train_dataloader, val_dataloader, test_dataloader, model, optimizer, criterion, device)\n",
    "    val_acc = trainer.train(epoch = epoch)\n",
    "    print('val_acc: %.3f' %(val_acc))\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'models/3-1_logistic_model')\n",
    "\n",
    "trainer.model.load_state_dict(torch.load('models/3-1_logistic_model'))\n",
    "test_acc = trainer.test()\n",
    "print('test_acc: %.3f' %(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1  loss: 0.930\n",
      "epoch: 2  loss: 0.956\n",
      "epoch: 3  loss: 1.004\n",
      "epoch: 4  loss: 1.003\n",
      "val_acc: 0.678\n",
      "epoch: 1  loss: 0.278\n",
      "epoch: 2  loss: 0.170\n",
      "epoch: 3  loss: 0.148\n",
      "epoch: 4  loss: 0.133\n",
      "val_acc: 0.956\n",
      "epoch: 1  loss: 0.472\n",
      "epoch: 2  loss: 0.254\n",
      "epoch: 3  loss: 0.206\n",
      "epoch: 4  loss: 0.173\n",
      "val_acc: 0.950\n",
      "epoch: 1  loss: 1.298\n",
      "epoch: 2  loss: 0.553\n",
      "epoch: 3  loss: 0.414\n",
      "epoch: 4  loss: 0.358\n",
      "val_acc: 0.911\n",
      "test_acc: 0.953\n"
     ]
    }
   ],
   "source": [
    "# MLP\n",
    "input_dim = 784\n",
    "hidden_dim = 32\n",
    "output_dim = 10\n",
    "epoch = 4\n",
    "\n",
    "best_acc = 0.0\n",
    "lrs = [1e-1, 1e-2, 1e-3, 1e-4]\n",
    "for lr in lrs:\n",
    "    model = MLP(input_dim=input_dim, \n",
    "                hidden_dim=hidden_dim,\n",
    "                output_dim=output_dim).to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    trainer = Trainer(train_dataloader, val_dataloader, test_dataloader, model, optimizer, criterion, device)\n",
    "    val_acc = trainer.train(epoch = epoch)\n",
    "    print('val_acc: %.3f' %(val_acc))\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'models/3-1_MLP_model')\n",
    "\n",
    "trainer.model.load_state_dict(torch.load('models/3-1_MLP_model'))\n",
    "test_acc = trainer.test()\n",
    "print('test_acc: %.3f' %(test_acc))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "168b3bbc19afd1ef550d68b948460bcb86336de7649712fa882c5012c218f57c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('nlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
